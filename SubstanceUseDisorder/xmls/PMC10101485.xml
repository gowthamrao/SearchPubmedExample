<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS One</journal-id><journal-id journal-id-type="pmc-domain-id">440</journal-id><journal-id journal-id-type="pmc-domain">plosone</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-title-group><journal-title>PLOS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>PLOS</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC10101485</article-id><article-id pub-id-type="pmcid-ver">PMC10101485.1</article-id><article-id pub-id-type="pmcaid">10101485</article-id><article-id pub-id-type="pmcaiid">10101485</article-id><article-id pub-id-type="pmid">37053155</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0284077</article-id><article-id pub-id-type="publisher-id">PONE-D-22-18053</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Data Management</subject><subj-group><subject>Data Visualization</subject><subj-group><subject>Infographics</subject><subj-group><subject>Graphs</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Computer Software</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Computer Software</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Network Analysis</subject><subj-group><subject>Centrality</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Mathematical and Statistical Techniques</subject><subj-group><subject>Statistical Methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical Methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Computer Software</subject><subj-group><subject>Open Source Software</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Computer Software</subject><subj-group><subject>Open Source Software</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Science Policy</subject><subj-group><subject>Open Science</subject><subj-group><subject>Open Source Software</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Eukaryota</subject><subj-group><subject>Plants</subject><subj-group><subject>Trees</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Graph-based machine learning improves just-in-time defect prediction</article-title><alt-title alt-title-type="running-head">Graph machine learning improves just-in-time defect prediction</alt-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name name-style="western"><surname>Bryan</surname><given-names initials="J">Jonathan</given-names></name><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1822-8885</contrib-id><name name-style="western"><surname>Moriano</surname><given-names initials="P">Pablo</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role><role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role><role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib></contrib-group><aff id="aff001">
<label>1</label>
<addr-line>AT&amp;T Cybersecurity, AT&amp;T, Atlanta, GA, United States of America</addr-line>
</aff><aff id="aff002">
<label>2</label>
<addr-line>Computer Science and Mathematics Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States of America</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Thinnukool</surname><given-names initials="O">Orawit</given-names></name><role>Editor</role><xref rid="edit1" ref-type="aff"/></contrib></contrib-group><aff id="edit1">
<addr-line>Chiang Mai University, THAILAND</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>jz699j@att.com</email> (JB); <email>moriano@ornl.gov</email> (PM)</corresp></author-notes><pub-date pub-type="collection"><year>2023</year></pub-date><pub-date pub-type="epub"><day>13</day><month>4</month><year>2023</year></pub-date><volume>18</volume><issue>4</issue><issue-id pub-id-type="pmc-issue-id">432629</issue-id><elocation-id>e0284077</elocation-id><history><date date-type="received"><day>24</day><month>6</month><year>2022</year></date><date date-type="accepted"><day>23</day><month>3</month><year>2023</year></date></history><pub-history><event event-type="pmc-release"><date><day>13</day><month>04</month><year>2023</year></date></event><event event-type="pmc-live"><date><day>14</day><month>04</month><year>2023</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2023-04-14 16:10:31.860"><day>14</day><month>04</month><year>2023</year></date></event></pub-history><permissions><copyright-statement>&#169; 2023 Bryan, Moriano</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Bryan, Moriano</copyright-holder><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="pone.0284077.pdf"/><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pdf" xlink:href="pone.0284077.pdf"/><related-article xmlns:xlink="http://www.w3.org/1999/xlink" related-article-type="editor-report" xml:lang="en" ext-link-type="doi" xlink:href="10.1371/journal.pone.0284077"><pub-id pub-id-type="doi">10.1371/journal.pone.0284077</pub-id></related-article><related-article xmlns:xlink="http://www.w3.org/1999/xlink" related-article-type="reviewed-article" xml:lang="en" ext-link-type="doi" xlink:href="10.1371/journal.pone.0284077"><pub-id pub-id-type="doi">10.1371/journal.pone.0284077</pub-id></related-article><abstract><p>The increasing complexity of today&#8217;s software requires the contribution of thousands of developers. This complex collaboration structure makes developers more likely to introduce defect-prone changes that lead to software faults. Determining when these defect-prone changes are introduced has proven challenging, and using traditional machine learning (ML) methods to make these determinations seems to have reached a plateau. In this work, we build contribution graphs consisting of developers and source files to capture the nuanced complexity of changes required to build software. By leveraging these contribution graphs, our research shows the potential of using graph-based ML to improve Just-In-Time (JIT) defect prediction. We hypothesize that features extracted from the contribution graphs may be better predictors of defect-prone changes than intrinsic features derived from software characteristics. We corroborate our hypothesis using graph-based ML for classifying edges that represent defect-prone changes. This new framing of the JIT defect prediction problem leads to remarkably better results. We test our approach on 14 open-source projects and show that our best model can predict whether or not a code change will lead to a defect with an F1 score as high as 77.55% and a Matthews correlation coefficient (MCC) as high as 53.16%. This represents a 152% higher F1 score and a 3% higher MCC over the state-of-the-art JIT defect prediction. We describe limitations, open challenges, and how this method can be used for operational JIT defect prediction.</p></abstract><funding-group><award-group id="award001"><funding-source><institution>UT-Battelle, LLC</institution></funding-source><award-id>DE-AC05-00OR22725</award-id></award-group><award-group id="award002"><funding-source><institution>Oak Ridge National Laboratory&#8217;s (ORNL&#8217;s) Laboratory Directed Research and Development</institution></funding-source></award-group><award-group id="award003"><funding-source><institution>DOE, Office of Science, Office of Workforce Development for Teachers and Scientists (WDTS) under the Scientific Undergraduate Laboratory Internship (SULI) program</institution></funding-source></award-group><award-group id="award004"><funding-source><institution>ORNL&#8217;s Artificial Intelligence initiative</institution></funding-source><principal-award-recipient><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1822-8885</contrib-id><name name-style="western"><surname>Moriano</surname><given-names>Pablo</given-names></name></principal-award-recipient></award-group><funding-statement>This manuscript has been authored by UT-Battelle, LLC under ContractNo. DE-AC05-00OR22725 with the U.S. Department of Energy. The publisher, by accepting the article for publication, acknowledges that the U.S. Government retains a non-exclusive, paid up, irrevocable, world-wide license to publish or reproduce the published form of the manuscript, or allow others to do so, for U.S. Government purposes. The DOE will provide public access to these results in accordance with the DOE Public Access Plan (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://energy.gov/downloads/doe-public-access-plan" ext-link-type="uri">http://energy.gov/downloads/doe-public-access-plan</ext-link>). This research was sponsored in part by Oak Ridge National Laboratory&#8217;s (ORNL&#8217;s) Laboratory Directed Research and Development program and by the DOE, Office of Science, Office of Workforce Development for Teachers and Scientists (WDTS) under the Scientific Undergraduate Laboratory Internship (SULI) program. Pablo Moriano acknowledges support from ORNL&#8217;s Artificial Intelligence initiative. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. There was no additional external funding received for this study.</funding-statement></funding-group><counts><fig-count count="2"/><table-count count="4"/><page-count count="19"/></counts><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All data are available from the GitHub repository (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/lining-nwpu/JiTReliability" ext-link-type="uri">https://github.com/lining-nwpu/JiTReliability</ext-link>).</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All data are available from the GitHub repository (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/lining-nwpu/JiTReliability" ext-link-type="uri">https://github.com/lining-nwpu/JiTReliability</ext-link>).</p></notes></front><body><sec sec-type="intro" id="sec001"><title>1 Introduction</title><p>Software quality assurance, including source code inspection and testing, has become increasingly necessary for building high-quality software [<xref rid="pone.0284077.ref001" ref-type="bibr">1</xref>]. Software defects, or bugs, are detrimental to software quality and have a negative economic and reputational impact on software stakeholders, especially when they lead to software failures [<xref rid="pone.0284077.ref002" ref-type="bibr">2</xref>]. Thus, there is a huge incentive to detect likely software defects as early as possible in the development process. Reducing the number of software defects through quick and automatic identification would lead to the production of better software by improving its usability and reducing costs associated with maintenance.</p><p>Previous research on software quality assurance focuses on either module-level [<xref rid="pone.0284077.ref003" ref-type="bibr">3</xref>] or Just-In-Time (JIT) defect prediction [<xref rid="pone.0284077.ref004" ref-type="bibr">4</xref>]. The module-level approach uses machine learning (ML) models trained on historical data obtained from software characteristics, including code churn, change metadata, and complexity metrics [<xref rid="pone.0284077.ref005" ref-type="bibr">5</xref>]. Defect prediction models detect defect-prone software modules (e.g., files [<xref rid="pone.0284077.ref006" ref-type="bibr">6</xref>], subsystems [<xref rid="pone.0284077.ref007" ref-type="bibr">7</xref>]). Defect prediction models are then used to identify software modules that likely contain faulty code. These models can also help prioritize software quality assurance efforts, such as code reviews and pre-release testing. The JIT approach, in contrast, focuses on change-level defect prediction. This means that the focus is on software changes (i.e., commits) rather than on modules.</p><p>JIT has important advantages over module-level defect prediction [<xref rid="pone.0284077.ref004" ref-type="bibr">4</xref>]. First, it reduces defect detection time: JIT predictions are obtained when changes are ready to be committed, <italic toggle="yes">before</italic> the software has been deployed. Second, it provides attribution: JIT predictions are linked to the author of the change rather than a group of authors. Lastly, it produces finer-grained predictions: JIT predictions spotlight specific changes, which are often smaller than coarser-grained prediction modules. Therefore, predicting defect-prone changes using JIT is preferred over module-level defect prediction.</p><p>Current JIT defect prediction models use software characteristics to inform commonly used, supervised ML models. Traditional features used in this task are related to the diffusion, size, purpose, history, and experience dimensions of the changes [<xref rid="pone.0284077.ref004" ref-type="bibr">4</xref>]. Recent models also add context to these features by leveraging the semantic information and syntactic structure hidden in source code [<xref rid="pone.0284077.ref008" ref-type="bibr">8</xref>]. Once this set of features has been computed for the targeted software commits, different ML models are used for JIT defect prediction, including logistic regression [<xref rid="pone.0284077.ref009" ref-type="bibr">9</xref>] and more sophisticated models, such as ensembles [<xref rid="pone.0284077.ref010" ref-type="bibr">10</xref>] and deep learning [<xref rid="pone.0284077.ref011" ref-type="bibr">11</xref>&#8211;<xref rid="pone.0284077.ref013" ref-type="bibr">13</xref>]. More recently, new features based on representing code semantics using word embeddings to map change sequences into numeric vectors have been proposed [<xref rid="pone.0284077.ref014" ref-type="bibr">14</xref>].</p><p>Obtaining large amounts of accurate historical data is a prerequisite for good performance in JIT defect prediction [<xref rid="pone.0284077.ref015" ref-type="bibr">15</xref>]. However, this data can be difficult to obtain because the nature of code commits/changes tends to evolve during the development cycle, which can impact the performance of JIT defect prediction [<xref rid="pone.0284077.ref016" ref-type="bibr">16</xref>]. In addition, as shown recently [<xref rid="pone.0284077.ref010" ref-type="bibr">10</xref>], even when using sophisticated ML models, such as ensembles, the achievable performance for JIT defect prediction still has much room for improvement (i.e., it currently reaches about 31% average F1 score and 51% Matthews correlation coefficient (MCC) for predicting early exposed defects).</p><p>Here, we introduce a novel framework for JIT defect prediction using contribution graphs [<xref rid="pone.0284077.ref017" ref-type="bibr">17</xref>] and graph-based ML [<xref rid="pone.0284077.ref018" ref-type="bibr">18</xref>]. Contribution graphs are bipartite graphs in which nodes represent developers and modules (source code files in our case). Edges in the contribution graph capture interactions between developers and modules, thereby representing software changes. We label edges in these graphs to distinguish clean commits from bug-introducing commits using the Sliwerski-Zimmermann-Zeller (SZZ) algorithm [<xref rid="pone.0284077.ref019" ref-type="bibr">19</xref>]. We then extract features from the contribution graph using (1) centrality metrics (Setting 1) and (2) community assignments and node embeddings (Setting 2) [<xref rid="pone.0284077.ref020" ref-type="bibr">20</xref>]. These two feature sets are then used to inform ML algorithms and classify code changes.</p><p>Our approach is novel for JIT defect prediction in that it assigns a probability score to each new code change (i.e., an unlabeled edge in the graph) that indicates the likelihood of that change being defect-prone. We operationalize this idea using edge classification. Edge classification refers to the problem of classifying unknown edge labels in a graph [<xref rid="pone.0284077.ref021" ref-type="bibr">21</xref>]. Here, the notion of an edge appearing in the future is quantified as a score that measures the likelihood of it being a defect-prone change. We show the potential of using this approach with higher classification results (i.e., with a 152% higher F1 score and a 3% higher MCC) compared to a recent benchmark on JIT defect prediction on early exposed defects over 14 large open-source projects [<xref rid="pone.0284077.ref010" ref-type="bibr">10</xref>].</p><p>The main contributions of this paper are as follows. First, we investigate the use of graph-based ML for JIT defect prediction. The core of our contribution is data modeling by using contribution graphs. In particular, we leverage contribution graphs as a modeling framework to capture the changes that developers make to software files. We used this abstraction as the basis of edge classification. Specifically, from the contribution graphs, we extract graph-related features that inform edge classification models when classifying defect-prone changes. Second, we perform an in-depth evaluation of these graph-based ML models using (1) centrality metrics (Setting 1) and (2) community assignments and node embedding features (Setting 2) while taking into account the unbalanced nature of the dataset. Lastly, we compare these graph-based models with traditional ML models, including 11 state-of-the art JIT defect detection methods. Our results show that the graph-based approach provides a 152% higher F1 score and a 3% higher MCC than the state-of-the-art. We are sharing the data [<xref rid="pone.0284077.ref022" ref-type="bibr">22</xref>] and code [<xref rid="pone.0284077.ref023" ref-type="bibr">23</xref>] used in this research so that our results can be reproduced.</p></sec><sec id="sec002"><title>2 Related work</title><p>Our research is informed by past work in network analysis for software engineering, JIT defect prediction, and graph-based ML. Here, we provide an overview of this related work.</p><sec id="sec003"><title>2.1 Network analysis in software engineering</title><p>Network analysis is used to model the interactions of software elements, including between software dependencies (i.e., the dependency graph [<xref rid="pone.0284077.ref024" ref-type="bibr">24</xref>]) and between developer and software modules (i.e., the contribution graph [<xref rid="pone.0284077.ref017" ref-type="bibr">17</xref>]). This modeling framework has also been used to predict failures in files within a closed networking software project [<xref rid="pone.0284077.ref025" ref-type="bibr">25</xref>], examine the relationship between ownership measures and software failures [<xref rid="pone.0284077.ref026" ref-type="bibr">26</xref>], quantify the impact of network analysis metrics as indicators of software vulnerabilities [<xref rid="pone.0284077.ref027" ref-type="bibr">27</xref>], and estimate insider threat risk in a version control system (VCS) [<xref rid="pone.0284077.ref028" ref-type="bibr">28</xref>].</p><p>One significant difference between our work and other studies using network analysis is that our work uses features derived from the contribution graph for JIT defect prediction. In doing so, we frame the problem of introducing defect-prone changes as the likelihood that unseen edges introduce them. We explore two kinds of network properties: (1) topological properties (Setting 1) and (2) community assignations and node embeddings (Setting 2) in the contribution graph.</p></sec><sec id="sec004"><title>2.2 SZZ algorithm</title><p>The SZZ algorithm is the primary algorithm used to identify defect-prone changes (i.e., bug-introducing commits) in a software repo. Using the SZZ algorithm, practitioners can identify individual commits that introduce defect-prone changes. The SZZ algorithm was introduced by &#346;liwerski et al. [<xref rid="pone.0284077.ref019" ref-type="bibr">19</xref>] and was originally conceived for centralized VCSs, such as CVS and its corresponding commit practices. Later iterations of the SZZ algorithm made it operational for distributed VCSs, such as <monospace specific-use="no-wrap">git</monospace>.</p><p>The SZZ algorithm uses two sources of data: (1) bug reports (BRs) from an issue tracker system (ITS), such as Jira or BugZilla, and (2) historical change logs from a VCS. The SZZ algorithm has two main steps. In the first step, BRs are linked to defect-fixing changes (i.e., bug-fixing commits). This is achieved by finding explicit calls to BRs in commit messages by using regular expressions. In the case in which the ITS does not allow the identification of bug fixes, commit messages using the word <italic toggle="yes">fix</italic> (or similar) are used as a proxy for identifying defect-fixing changes. In the second step, once defect-fixing changes are identified, the SZZ algorithm traces back the modified lines in the source code. Specifically, for each of the identified defect-fixing changes, the SZZ algorithm uses <monospace specific-use="no-wrap">git blame</monospace> to identify previous commits that made changes to those specific lines of code. Git blame also extracts the revision and the last author to modify those lines. This means that the output of git blame contains a set of candidate commits that may have introduced the defect. From this set of candidates, the SZZ algorithm determines whether or not any commits can be discarded as a defect-prone change. Borg et al. provide a detailed description of the heuristic used in the SZZ algorithm [<xref rid="pone.0284077.ref029" ref-type="bibr">29</xref>].</p></sec><sec id="sec005"><title>2.3 JIT defect prediction</title><p>JIT defect prediction consists of four main steps. First, JIT uses the SZZ algorithm [<xref rid="pone.0284077.ref019" ref-type="bibr">19</xref>] to label previous changes obtained from a VCS as defect prone or not. The SZZ algorithm is the primary algorithm used to identify defect-prone changes (i.e., bug-introducing commits) in a software repo. Second, it quantifies change metrics that characterize changes in the code. Third, it learns a ML classifier based on the previously computed labeled changes and their metrics. Finally, JIT defect prediction uses the learned classifier to predict if new code changes are defect-prone.</p><p>An important aspect of JIT defect prediction is identifying and extracting the independent variables used to build JIT defect prediction models. Generally, there are two approaches for doing that: feature engineering and feature learning. In the former, features are designed manually. In the latter, features are learned automatically via algorithms as feature representations from the data.</p><p>Early work on JIT defect prediction through feature engineering focused on using features derived from software change metrics as those directly computed from code changes. They include variables related to diffusion (e.g., number of modified subsystems), size (e.g., lines of code added), history (e.g., number of developers who modified the files), and experience (e.g., developer experience) [<xref rid="pone.0284077.ref030" ref-type="bibr">30</xref>]. The origin of JIT defect prediction through feature engineering is usually attributed to Mockus and Weiss [<xref rid="pone.0284077.ref031" ref-type="bibr">31</xref>]. Working with a large, closed telecommunication code base, Mockus and Weiss introduced the idea of quantifying software change properties to predict defects for initial maintenance requests (IMRs) when the IMRs consist of multiple changes. Kim et al. [<xref rid="pone.0284077.ref032" ref-type="bibr">32</xref>] focused on predicting individual defect-prone changes and applied this method to a variety of open-source code bases. Kamei et al. [<xref rid="pone.0284077.ref004" ref-type="bibr">4</xref>] extended previous work by applying it to open-source and commercial code bases across multiple industries. Jiang et al. [<xref rid="pone.0284077.ref033" ref-type="bibr">33</xref>] introduced a personalized defect prediction approach by building a separate prediction model for each developer. Kononenko et al. [<xref rid="pone.0284077.ref034" ref-type="bibr">34</xref>] added features extracted from code review databases, thereby leading to an increase in the explanatory power of JIT defect prediction models. Kamei et al. [<xref rid="pone.0284077.ref035" ref-type="bibr">35</xref>] evaluated the performance of JIT defect prediction in projects still in their initial development phases. In doing so, they showed that JIT models trained using data from projects with sufficient history are viable candidates for JIT defect prediction in projects with limited historical data.</p><p>Early work on JIT defect prediction via feature learning focused on estimating feature representations by extracting the amount of information in the commit message. Deep learning approaches, and deep neural networks in particular, are predominantly used to learn feature representations for JIT defect prediction. For example, Yang at al. [<xref rid="pone.0284077.ref011" ref-type="bibr">11</xref>] built a set of expressive features from a set of initial changes by leveraging a deep belief network algorithm. Later, they trained an ML classifier on selected features. Barnett et al. [<xref rid="pone.0284077.ref036" ref-type="bibr">36</xref>] mined commit message content by using SpamBayes classifiers [<xref rid="pone.0284077.ref037" ref-type="bibr">37</xref>] as filters. More recently, Hoang et al. [<xref rid="pone.0284077.ref012" ref-type="bibr">12</xref>] proposed an end-to-end deep learning framework, named DeepJIT, which automatically extracts features from code changes and commit messages and uses them to classify defects. Xu et al. [<xref rid="pone.0284077.ref038" ref-type="bibr">38</xref>] proposed a cross-triplet deep feature embedding method, called CDFE, for cross-app JIT defect prediction in mobile apps. The CDFE method incorporates a cross-triplet loss function into a deep neural network to learn high-level feature representation for the cross-app data. This loss function shortens the distance of commits with similar labels while lengthening the distance between commits with different labels. Zhuang et al. [<xref rid="pone.0284077.ref014" ref-type="bibr">14</xref>] proposed a method to represent code semantics based on Abstract Syntax Tress (ASTs). This method works by comparing the AST of source code before and after a change for extracting change sequences that are then mapped to a numeric vector by using word-embedding models.</p><p>
<xref rid="pone.0284077.t001" ref-type="table">Table 1</xref> summarizes closely related previous work on JIT defect prediction that uses feature learning. For a comprehensive survey on JIT defect prediction, we refer the reader to the work by Zhao et al. [<xref rid="pone.0284077.ref030" ref-type="bibr">30</xref>].</p><table-wrap position="float" id="pone.0284077.t001" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0284077.t001</object-id><label>Table 1</label><caption><title>Summary of JIT defect prediction works by using feature learning.</title></caption><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.t001g" position="float" orientation="portrait" xlink:href="pone.0284077.t001.jpg"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" style="border-top-width:thick" rowspan="1" colspan="1">Study</th><th align="left" style="border-top-width:thick" rowspan="1" colspan="1">Year</th><th align="left" style="border-top-width:thick" rowspan="1" colspan="1">Primary Topic</th><th align="left" style="border-top-width:thick" rowspan="1" colspan="1">Constraint</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Yang et al. [<xref rid="pone.0284077.ref011" ref-type="bibr">11</xref>]</td><td align="left" rowspan="1" colspan="1">2015</td><td align="left" rowspan="1" colspan="1">Proposed Deeper, which consists of a deep belief network and a logistic regression classifier for JIT defect prediction</td><td align="left" rowspan="1" colspan="1">Deeper does not fully exploit the true benefits of deep learning because it uses the same set of traditional features derived from feature engineering.</td></tr><tr><td align="left" rowspan="1" colspan="1">Barnett et al. [<xref rid="pone.0284077.ref036" ref-type="bibr">36</xref>]</td><td align="left" rowspan="1" colspan="1">2016</td><td align="left" rowspan="1" colspan="1">Investigated the benefits of adding commit message features for JIT defect prediction</td><td align="left" rowspan="1" colspan="1">Leveraging commit message proneness to be defective by using a SpamBayes classifier may produce overly specific scores for systems to which they
will be applied.</td></tr><tr><td align="left" rowspan="1" colspan="1">Hoang et al. [<xref rid="pone.0284077.ref012" ref-type="bibr">12</xref>]</td><td align="left" rowspan="1" colspan="1">2019</td><td align="left" rowspan="1" colspan="1">Introduced DeepJIT, an end-to-end JIT defect prediction model that learns feature representations from tokenized software changes and
commit messages</td><td align="left" rowspan="1" colspan="1">Because code is written using an open, rapidly changing vocabulary, word embeddings may introduce noise and then cause a negative impact on the performance of the cross-project defect prediction.</td></tr><tr><td align="left" rowspan="1" colspan="1">Xu et al. [<xref rid="pone.0284077.ref038" ref-type="bibr">38</xref>]</td><td align="left" rowspan="1" colspan="1">2021</td><td align="left" rowspan="1" colspan="1">Designed CDFE, a deep neural network with triplet loss function for cross-project JIT defect prediction in mobile apps</td><td align="left" rowspan="1" colspan="1">Using labeled commit data from other mobile apps to assist the labeling of the mobile app at hand may be impacted by the imbalanced nature of JIT defect prediction.</td></tr><tr><td align="left" style="border-bottom-width:thick" rowspan="1" colspan="1">Zhuang et al. [<xref rid="pone.0284077.ref014" ref-type="bibr">14</xref>]</td><td align="left" style="border-bottom-width:thick" rowspan="1" colspan="1">2022</td><td align="left" style="border-bottom-width:thick" rowspan="1" colspan="1">Introduced ACE based on Abstract Syntax Trees (ASTs) by comparing the AST of source code before and after a change and computing change sequences that are mapped to word embeddings</td><td align="left" style="border-bottom-width:thick" rowspan="1" colspan="1">Experiments conducted in projects coded on Java. AST nodes of different programming languages may differ, thereby influencing JIT defect prediction performance.</td></tr></tbody></table></alternatives></table-wrap><p>To the best of our knowledge, apart from features derived through feature engineering (based on software code change metrics) and features derived using feature learning, no prior studies have investigated the use of features derived from the contribution graphs to inform graph-based ML classifiers to predict the risk of introducing defect-prone changes.</p></sec><sec id="sec006"><title>2.4 Graph-based ML</title><p>Graph-based ML refers to the use of graph-based related features to train ML algorithms [<xref rid="pone.0284077.ref039" ref-type="bibr">39</xref>]. Graph-based features can be highly predictive, thereby adding value to existing ML models. Applications of graph-based ML span multiple industries, including attribute prediction in social networks [<xref rid="pone.0284077.ref040" ref-type="bibr">40</xref>], bot detection [<xref rid="pone.0284077.ref018" ref-type="bibr">18</xref>], understanding the dynamics of opioid doctor shopping [<xref rid="pone.0284077.ref041" ref-type="bibr">41</xref>], and cybersecurity applications, such as detection of lateral movement in enterprise computer networks [<xref rid="pone.0284077.ref042" ref-type="bibr">42</xref>].</p><p>Graph-based ML is based on extracting structural features from graphs. These features can be obtained from the structure of the graphs or by using representation learning (graph embeddings). The former refers to traditional structural properties, such as a node&#8217;s degrees and/or centrality metrics [<xref rid="pone.0284077.ref043" ref-type="bibr">43</xref>]. The latter refers to encoding structural information of individual nodes into a low-dimensional vector space. Graph embedding methods are flexible because they can adapt during the learning process, as opposed to purely structured features that require feature engineering. Graph embedding methods are classified based on the algorithm used for the encoding [<xref rid="pone.0284077.ref044" ref-type="bibr">44</xref>]. This classification includes matrix factorization [<xref rid="pone.0284077.ref045" ref-type="bibr">45</xref>, <xref rid="pone.0284077.ref046" ref-type="bibr">46</xref>], random walks [<xref rid="pone.0284077.ref020" ref-type="bibr">20</xref>, <xref rid="pone.0284077.ref047" ref-type="bibr">47</xref>], or deep learning methods [<xref rid="pone.0284077.ref048" ref-type="bibr">48</xref>, <xref rid="pone.0284077.ref049" ref-type="bibr">49</xref>]. The embedding choice usually depends on the application [<xref rid="pone.0284077.ref050" ref-type="bibr">50</xref>].</p><p>Our work is novel in that it compares second-order proximity metrics, which describe the proximity of node pairs and their neighborhood&#8217;s structure using centrality metrics and a random walk graph embedding (i.e., <monospace specific-use="no-wrap">node2vec</monospace> [<xref rid="pone.0284077.ref020" ref-type="bibr">20</xref>]). <monospace specific-use="no-wrap">node2vec</monospace> performs biased random walks by trading the bias between breadth-first and depth-first search. <monospace specific-use="no-wrap">node2vec</monospace> is parameterized using walk length, context size, and bias weights, and its embeddings ensure that nodes with common neighbors tend to appear close in the embedding space.</p></sec></sec><sec sec-type="materials|methods" id="sec007"><title>3 Methods</title><p>This section describes the mathematical frameworks and data sources used to perform this research. The proposed method for JIT defect prediction leverages contribution graphs to learn classifiers that distinguish regular commits from defect-prone changes. We extracted graph-based features to quantify the risk that new changes will introduce defects. Performance is measured by the the ability of the algorithm to distinguish between regular commits and defect-prone changes, i.e., edge classification.</p><p>An overview of the proposed framework is presented in <xref rid="pone.0284077.g001" ref-type="fig">Fig 1</xref>. Our method is composed of three main phases: dataset generation, training, and testing. In the dataset generation phase, we build a labeled commit dataset by combining the extracted graph features from the contribution graph (see Section 3.1) and bug-inducing commits produced by the SZZ algorithm. During the training phase, we process the training data (see Section 3.3) by conducting data preparation (see Section 3.3.1), model training (see Section 3.3.2), and selection (see Section 3.3.3) on a subset of classifiers (see Section 3.4). During the testing phase, we prepare the data from given code changes and feed it into the trained model (see Section 3.3.4). Predictions from the classifiers are used to estimate the quality of the predictions (see Section 3.5). We associated each step in the proposed method (and their subsequent section numbers) with the corresponding phase in <xref rid="pone.0284077.g001" ref-type="fig">Fig 1</xref>.</p><fig position="float" id="pone.0284077.g001" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0284077.g001</object-id><label>Fig 1</label><caption><title>Graph-based ML JIT defect prediction pipeline.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0284077.g001.jpg"/></fig><sec id="sec008"><title>3.1 Graph modeling</title><p>Each of the steps in our graph modeling framework are detailed below.</p><sec id="sec009"><title>3.1.1 Contribution graph</title><p>We model contribution graphs as undirected bipartite graphs made of developers (top nodes) and source code files (bottom nodes). We let <inline-formula id="pone.0284077.e001"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e001g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e001.jpg"/><mml:math id="M1" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:math></alternatives></inline-formula> represent the set of top nodes, or developers; and we let <inline-formula id="pone.0284077.e002"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e002g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e002.jpg"/><mml:math id="M2" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8869;</mml:mi></mml:msub></mml:math></alternatives></inline-formula> be the set of bottom nodes, or files. Note that <inline-formula id="pone.0284077.e003"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e003g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e003.jpg"/><mml:math id="M3" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0284077.e004"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e004g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e004.jpg"/><mml:math id="M4" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8869;</mml:mi></mml:msub></mml:math></alternatives></inline-formula> are a disjoint set of nodes. Let <inline-formula id="pone.0284077.e005"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e005g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e005.jpg"/><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">V</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mo>&#8746;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8869;</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> be the set of contribution graph nodes. Let <inline-formula id="pone.0284077.e006"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e006g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e006.jpg"/><mml:math id="M6" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">W</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>&#969;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#8838;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mo>&#215;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8869;</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> be the incident matrix of weights, <italic toggle="yes">&#969;</italic><sub><italic toggle="yes">ij</italic></sub>, that captures the number of changes (i.e., commits) made by developer, <italic toggle="yes">i</italic>, to file, <italic toggle="yes">j</italic>. The graph <inline-formula id="pone.0284077.e007"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e007g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e007.jpg"/><mml:math id="M7" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">W</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> represents a weighted bipartite graph that captures software changes.</p><p>To create the contribution graph, we used changelog metadata entries from <monospace specific-use="no-wrap">git</monospace> logs. Each one of these entries is used to extract the timestamps and information about which developer committed a change to a particular source file. We used Neo4j for storing the bipartite graphs. Neo4j is a high-performance NoSQL database that enables efficient computation of graph-related algorithms, including structural properties and node embeddings, as shown in different applications [<xref rid="pone.0284077.ref051" ref-type="bibr">51</xref>].</p></sec><sec id="sec010"><title>3.1.2 One-mode projection</title><p>We projected the contribution graph into a one-mode projection graph (on the developer side). Specifically, we let <inline-formula id="pone.0284077.e008"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e008g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e008.jpg"/><mml:math id="M8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">G</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> be the top, one-mode projection of <inline-formula id="pone.0284077.e009"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e009g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e009.jpg"/><mml:math id="M9" display="inline" overflow="scroll"><mml:mi mathvariant="script">G</mml:mi></mml:math></alternatives></inline-formula>. Two nodes of <inline-formula id="pone.0284077.e010"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e010g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e010.jpg"/><mml:math id="M10" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">G</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:math></alternatives></inline-formula> are connected if they have a common neighbor in <inline-formula id="pone.0284077.e011"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e011g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e011.jpg"/><mml:math id="M11" display="inline" overflow="scroll"><mml:mi mathvariant="script">G</mml:mi></mml:math></alternatives></inline-formula>, which means the two developers made changes to the same files. In the one-mode projection, we aggregated weights, which results in a weighted, one-mode projection described by the weight matrix, <inline-formula id="pone.0284077.e012"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e012g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e012.jpg"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>&#969;</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>&#8838;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pone.0284077.e013"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e013g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e013.jpg"/><mml:math id="M13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#969;</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8869;</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mi>&#969;</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#969;</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. We extracted graph-based features from the one-mode projection graph using the Neo4j Graph Data Science application programming interface (API). We assumed that the centrality metrics (Setting 1) and community assignments along with node embeddings (Setting 2) in the one-mode projection graph capture the connectivity around both edge endpoints (i.e., developer and file) in the contribution graph. <xref rid="pone.0284077.g002" ref-type="fig">Fig 2</xref> shows an illustration of a toy contribution graph (a) and its one-mode projection (b).</p><fig position="float" id="pone.0284077.g002" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0284077.g002</object-id><label>Fig 2</label><caption><title>Contribution graph and its projection.</title><p>a) A toy contribution graph. Check marks represent clean changes, whereas cross marks represent defect-prone changes. (b) Corresponding one-mode projection on the developer side. Classification is driven by developer-based features alone as the one-mode projection graph captures the connectivity around both endpoints (i.e., developer and file) in the contribution graph.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0284077.g002.jpg"/></fig></sec><sec id="sec011"><title>3.1.3 Edge classification</title><p>Edges in the contribution graph are labeled. Edge labels represent if a particular change is defect-prone or not. Edge classification refers to the task of classifying the edge labels [<xref rid="pone.0284077.ref021" ref-type="bibr">21</xref>]. More formally, consider the set of labeled edges: <inline-formula id="pone.0284077.e014"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e014g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e014.jpg"/><mml:math id="M14" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi><mml:mi>&#8467;</mml:mi></mml:msubsup><mml:mo>&#8838;</mml:mo><mml:msub><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Edges <inline-formula id="pone.0284077.e015"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e015g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e015.jpg"/><mml:math id="M15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#969;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#8712;</mml:mo><mml:msubsup><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> have a binary label, &#8467; &#8712; {0, 1}. Edge classification consists on determining the labels of the edges in <inline-formula id="pone.0284077.e016"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e016g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e016.jpg"/><mml:math id="M16" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi><mml:mi>u</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mrow><mml:mo>\</mml:mo></mml:mrow><mml:msubsup><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>.</p><p>The key for the edge classification task is to design features for a pair of nodes. We extracted two different types of features from the one-mode projection graphs to train ML models. The first type corresponds to a subset of structural properties. Specifically, we extracted centrality metrics from the nodes. These metrics capture the relative importance of nodes with respect to shared changes in the contribution graph. The second type of feature corresponds to node&#8217;s community assignments and embeddings. These assignments and embeddings capture more complex, nuanced neighborhood information of nodes to reflect the collaborative structure of software changes. We describe each of them in more detail below.</p></sec><sec id="sec012"><title>3.1.4 Graph structural properties (Setting 1)</title><p>We extracted centrality metrics from the nodes in the one-mode projection graph as a proxy for structural properties in the contribution graph. Centrality metrics quantify the relative importance of nodes in the graph [<xref rid="pone.0284077.ref052" ref-type="bibr">52</xref>]. In the context of contribution graphs, centrality metrics identify developers that contribute to many changes in similar modules. We extracted the following centrality metrics:</p></sec><sec id="sec013"><title>3.1.5 degree</title><p>The degree of node <inline-formula id="pone.0284077.e017"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e017g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e017.jpg"/><mml:math id="M17" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the number of edges attached to it. It is quantified as <inline-formula id="pone.0284077.e018"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e018g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e018.jpg"/><mml:math id="M18" display="inline" overflow="scroll"><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#8712;</mml:mo><mml:msub><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>&#969;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. In the context of contributions graphs, a high degree indicates a developer that has made changes to many modules in conjunction with other developers. In other words, they represent highly collaborative developers that made changes across different modules.</p></sec><sec id="sec014"><title>3.1.6 Betweenness</title><p>The betweenness of node <inline-formula id="pone.0284077.e019"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e019g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e019.jpg"/><mml:math id="M19" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the proportion of geodesic paths that include node <italic toggle="yes">i</italic>. It is quantified as <inline-formula id="pone.0284077.e020"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e020g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e020.jpg"/><mml:math id="M20" display="inline" overflow="scroll"><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mfrac><mml:msub><mml:mi>&#963;</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi>&#963;</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>, where <italic toggle="yes">&#963;</italic><sub><italic toggle="yes">jk</italic></sub>(<italic toggle="yes">i</italic>) is the total number of shortest paths that pass through node <italic toggle="yes">i</italic>, and <italic toggle="yes">&#963;</italic><sub><italic toggle="yes">jk</italic></sub> is the total number of shortest paths between nodes <italic toggle="yes">j</italic> and <italic toggle="yes">k</italic>. Developers with high betweenness are expected to contribute more widely among diverse groups of software modules.</p></sec><sec id="sec015"><title>3.1.7 Closeness</title><p>The closeness of node <inline-formula id="pone.0284077.e021"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e021g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e021.jpg"/><mml:math id="M21" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the average distance from node <italic toggle="yes">i</italic> to any other nodes in the graph that can be reached from node <italic toggle="yes">i</italic>. It is quantified as <inline-formula id="pone.0284077.e022"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e022g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e022.jpg"/><mml:math id="M22" display="inline" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. Closeness extends the notion of degree to account for distances to any other nodes beyond immediate neighbors. Developers with high closeness are expected to contribute to software modules that are highly dispersed.</p></sec><sec id="sec016"><title>3.1.8 Harmonic</title><p>The harmonic centrality of node <inline-formula id="pone.0284077.e023"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e023g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e023.jpg"/><mml:math id="M23" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is a variant of the closeness centrality that can be used to deal with unconnected graphs. It is defined as <inline-formula id="pone.0284077.e024"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e024g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e024.jpg"/><mml:math id="M24" display="inline" overflow="scroll"><mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>&#8800;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>.</p></sec><sec id="sec017"><title>3.1.9 PageRank</title><p>The PageRank of node <inline-formula id="pone.0284077.e025"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e025g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e025.jpg"/><mml:math id="M25" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> measures each developer&#8217;s prominence in the contribution graph. PageRank, which was originally conceived to rank web pages based on their importance [<xref rid="pone.0284077.ref053" ref-type="bibr">53</xref>], estimates the stationary probability that a random walker traversing the graph will arrive at a particular node. The stationary probability distribution over all the nodes is quantified by <inline-formula id="pone.0284077.e026"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e026g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e026.jpg"/><mml:math id="M26" display="inline" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msub><mml:mi>&#969;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>, where <italic toggle="yes">p</italic> is a damping factor, usually set to 0.85. Because our one-mode developer network does not have directional edges, we treated each directional edge as two directional edges. Developers with high PageRank are the ones that contribute to modules that also received contributions from important developers, who also have a high PageRank.</p></sec><sec id="sec018"><title>3.1.10 Communities and node embeddings (Setting 2)</title><p>The community assignment of node <inline-formula id="pone.0284077.e027"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e027g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e027.jpg"/><mml:math id="M27" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> captures its group identifier. Nodes within the same community are those with a significantly higher number of edges between them as opposed to other nodes in different communities [<xref rid="pone.0284077.ref054" ref-type="bibr">54</xref>]. In particular, let <inline-formula id="pone.0284077.e028"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e028g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e028.jpg"/><mml:math id="M28" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> denote a community partition of graph <inline-formula id="pone.0284077.e029"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e029g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e029.jpg"/><mml:math id="M29" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, thereby indicating the community membership of each node. Meaning, <italic toggle="yes">c</italic><sub><italic toggle="yes">i</italic></sub> and <italic toggle="yes">c</italic><sub><italic toggle="yes">j</italic></sub> have the same value if both <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic> belong to the same community. Here, we identified communities in the on-mode developer graph using the Louvain algorithm [<xref rid="pone.0284077.ref055" ref-type="bibr">55</xref>]. The Louvain algorithm is based on optimizing the modularity score of each community. The modularity of a community partition quantifies the quality of the nodes&#8217; community assignment. The optimization process used in the Louvain algorithm computes how many more densely connected nodes are inside communities compared to a random graph.</p><p>We embedded nodes in the graph <inline-formula id="pone.0284077.e030"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e030g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e030.jpg"/><mml:math id="M30" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">G</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> in a <italic toggle="yes">d</italic>-dimensional space. This means that every node <inline-formula id="pone.0284077.e031"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e031g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e031.jpg"/><mml:math id="M31" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mi mathvariant="script">G</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is represented by a unique <italic toggle="yes">d</italic>-dimensional vector that contains the coordinate values of node <italic toggle="yes">i</italic> in the embedding. In other words, let <inline-formula id="pone.0284077.e032"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e032g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e032.jpg"/><mml:math id="M32" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mo>&#8594;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> be the mapping function from nodes to a feature representation. Equivalently, <italic toggle="yes">f</italic> is a matrix of size <inline-formula id="pone.0284077.e033"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e033g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e033.jpg"/><mml:math id="M33" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mo>&#215;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. The proposed method can be applied using any embedding technique. Here, we used <monospace specific-use="no-wrap">node2vec</monospace> because it has shown robust results for link-related tasks [<xref rid="pone.0284077.ref044" ref-type="bibr">44</xref>]. We adopted commonly used values for the parameters of <monospace specific-use="no-wrap">node2vec</monospace> [<xref rid="pone.0284077.ref020" ref-type="bibr">20</xref>], specifically, a walk length of 80, a context size of 10, in/out of 1.0, return factor of 1.0, and an embedding dimension of 128. Note that these values are already the default in the Neo4j Graph Data Science API.</p><p>We summarize the notation used to model the contribution graphs and their extracted features in each Setting in <xref rid="pone.0284077.t002" ref-type="table">Table 2</xref>.</p><table-wrap position="float" id="pone.0284077.t002" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0284077.t002</object-id><label>Table 2</label><caption><title>Summary of notation used.</title></caption><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.t002g" position="float" orientation="portrait" xlink:href="pone.0284077.t002.jpg"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" style="border-top-width:thick" rowspan="1" colspan="1">Context</th><th align="left" style="border-top-width:thick" rowspan="1" colspan="1">Notation</th><th align="left" style="border-top-width:thick" rowspan="1" colspan="1">Description</th></tr></thead><tbody><tr><td align="left" rowspan="8" colspan="1">Contribution graph</td><td align="left" rowspan="1" colspan="1">
<inline-formula id="pone.0284077.e034">
<alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e034g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e034.jpg"/><mml:math id="M34" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:math></alternatives>
</inline-formula>
</td><td align="left" rowspan="1" colspan="1">The set of top nodes or developers</td></tr><tr><td align="left" rowspan="1" colspan="1">
<inline-formula id="pone.0284077.e035">
<alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e035g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e035.jpg"/><mml:math id="M35" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>&#8869;</mml:mi></mml:msub></mml:math></alternatives>
</inline-formula>
</td><td align="left" rowspan="1" colspan="1">The set of bottom nodes or files</td></tr><tr><td align="left" rowspan="1" colspan="1">
<inline-formula id="pone.0284077.e036">
<alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e036g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e036.jpg"/><mml:math id="M36" display="inline" overflow="scroll"><mml:mi mathvariant="script">V</mml:mi></mml:math></alternatives>
</inline-formula>
</td><td align="left" rowspan="1" colspan="1">The set of contribution graph nodes</td></tr><tr><td align="left" rowspan="1" colspan="1">
<inline-formula id="pone.0284077.e037">
<alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e037g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e037.jpg"/><mml:math id="M37" display="inline" overflow="scroll"><mml:mi mathvariant="script">W</mml:mi></mml:math></alternatives>
</inline-formula>
</td><td align="left" rowspan="1" colspan="1">The incident matrix of weights</td></tr><tr><td align="left" rowspan="1" colspan="1">
<inline-formula id="pone.0284077.e038">
<alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e038g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e038.jpg"/><mml:math id="M38" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">W</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives>
</inline-formula>
</td><td align="left" rowspan="1" colspan="1">The weighted bipartite graph capturing software changes</td></tr><tr><td align="left" rowspan="1" colspan="1">
<inline-formula id="pone.0284077.e039">
<alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e039g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e039.jpg"/><mml:math id="M39" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">G</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:math></alternatives>
</inline-formula>
</td><td align="left" rowspan="1" colspan="1">The developer-based one-mode projection</td></tr><tr><td align="left" rowspan="1" colspan="1">
<inline-formula id="pone.0284077.e040">
<alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e040g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e040.jpg"/><mml:math id="M40" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:math></alternatives>
</inline-formula>
</td><td align="left" rowspan="1" colspan="1">Weighted matrix in the developer-based one-mode projection</td></tr><tr><td align="left" rowspan="1" colspan="1">
<inline-formula id="pone.0284077.e041">
<alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e041g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e041.jpg"/><mml:math id="M41" display="inline" overflow="scroll"><mml:msubsup><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:math></alternatives>
</inline-formula>
</td><td align="left" rowspan="1" colspan="1">The set of labeled <inline-formula id="pone.0284077.e042"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e042g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e042.jpg"/><mml:math id="M42" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">W</mml:mi><mml:mi>&#8868;</mml:mi></mml:msub></mml:math></alternatives></inline-formula> edges</td></tr><tr><td align="left" rowspan="5" colspan="1">Setting 1</td><td align="left" rowspan="1" colspan="1"><italic toggle="yes">d</italic>(<italic toggle="yes">i</italic>)</td><td align="left" rowspan="1" colspan="1">The degree of node <italic toggle="yes">i</italic></td></tr><tr><td align="left" rowspan="1" colspan="1"><italic toggle="yes">b</italic>(<italic toggle="yes">i</italic>)</td><td align="left" rowspan="1" colspan="1">The betweenness of node <italic toggle="yes">i</italic></td></tr><tr><td align="left" rowspan="1" colspan="1"><italic toggle="yes">c</italic>(<italic toggle="yes">i</italic>)</td><td align="left" rowspan="1" colspan="1">The closeness of node <italic toggle="yes">i</italic></td></tr><tr><td align="left" rowspan="1" colspan="1"><italic toggle="yes">h</italic>(<italic toggle="yes">i</italic>)</td><td align="left" rowspan="1" colspan="1">The harmonic centrality of node <italic toggle="yes">i</italic></td></tr><tr><td align="left" rowspan="1" colspan="1"><italic toggle="yes">PR</italic>(<italic toggle="yes">i</italic>)</td><td align="left" rowspan="1" colspan="1">The PageRank of node <italic toggle="yes">i</italic></td></tr><tr><td align="left" rowspan="2" style="border-bottom-width:thick" colspan="1">Setting 2</td><td align="left" rowspan="1" colspan="1">
<italic toggle="yes">C</italic>
</td><td align="left" rowspan="1" colspan="1">The community partition</td></tr><tr><td align="left" style="border-bottom-width:thick" rowspan="1" colspan="1">
<italic toggle="yes">f</italic>
</td><td align="left" style="border-bottom-width:thick" rowspan="1" colspan="1">The node embedding mapping function</td></tr></tbody></table></alternatives></table-wrap></sec></sec><sec id="sec019"><title>3.2 Dataset</title><p>We tested the proposed method on the dataset collected by Tian et al. [<xref rid="pone.0284077.ref010" ref-type="bibr">10</xref>]. This dataset contains 18 well-known, open source multi-application projects coded in Java (17) and C++ (1). Note that this dataset tracked nearly the entire development cycle of these projects, as opposed to a limited software release time window [<xref rid="pone.0284077.ref056" ref-type="bibr">56</xref>]. We reported results on 14 of 18 of these repos because four of them (POI, Pig, VELOCITY, and XERCESC) have missing commits. We believe that missing commits may correspond to name changes in the branches of the repo, and we omitted them for that reason. <xref rid="pone.0284077.t003" ref-type="table">Table 3</xref> summarizes the dataset used. We describe the projects in the dataset in terms of age, kilo (thousands) of lines of code (KLOC), number of changes (# Changes), and early exposed defect ratio used in training (tr.) and testing (te.).</p><table-wrap position="float" id="pone.0284077.t003" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0284077.t003</object-id><label>Table 3</label><caption><title>The 14 open-source target projects from the dataset.</title></caption><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.t003g" position="float" orientation="portrait" xlink:href="pone.0284077.t003.jpg"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" style="border-top-width:thick" rowspan="1" colspan="1">Project</th><th align="left" style="border-top-width:thick" rowspan="1" colspan="1">Description</th><th align="right" style="border-top-width:thick" rowspan="1" colspan="1">Age (years)</th><th align="right" style="border-top-width:thick" rowspan="1" colspan="1">KLOC</th><th align="right" style="border-top-width:thick" rowspan="1" colspan="1">#Changes</th><th align="right" style="border-top-width:thick" rowspan="1" colspan="1">Period</th><th align="right" style="border-top-width:thick" rowspan="1" colspan="1">Pos. tr.</th><th align="right" style="border-top-width:thick" rowspan="1" colspan="1">Neg. tr.</th><th align="right" style="border-top-width:thick" rowspan="1" colspan="1">Pos. te.</th><th align="right" style="border-top-width:thick" rowspan="1" colspan="1">Neg. te.</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">ActiveMQ</td><td align="left" rowspan="1" colspan="1">High-performance messaging server</td><td align="char" char="." rowspan="1" colspan="1">13.45</td><td align="right" rowspan="1" colspan="1">38</td><td align="right" rowspan="1" colspan="1">10,213</td><td align="right" rowspan="1" colspan="1">2005&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">43.34%</td><td align="char" char="." rowspan="1" colspan="1">56.66%</td><td align="char" char="." rowspan="1" colspan="1">43.27%</td><td align="char" char="." rowspan="1" colspan="1">56.73%</td></tr><tr><td align="left" rowspan="1" colspan="1">Ant</td><td align="left" rowspan="1" colspan="1">A Java-based build tool</td><td align="char" char="." rowspan="1" colspan="1">8.75</td><td align="right" rowspan="1" colspan="1">339</td><td align="right" rowspan="1" colspan="1">14,387</td><td align="right" rowspan="1" colspan="1">2000&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">21.43%</td><td align="char" char="." rowspan="1" colspan="1">78.57%</td><td align="char" char="." rowspan="1" colspan="1">21.91%</td><td align="char" char="." rowspan="1" colspan="1">78.09%</td></tr><tr><td align="left" rowspan="1" colspan="1">Camel</td><td align="left" rowspan="1" colspan="1">An open-source integration framework</td><td align="char" char="." rowspan="1" colspan="1">11.53</td><td align="right" rowspan="1" colspan="1">75</td><td align="right" rowspan="1" colspan="1">38,563</td><td align="right" rowspan="1" colspan="1">2007&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">17.24%</td><td align="char" char="." rowspan="1" colspan="1">82.76%</td><td align="char" char="." rowspan="1" colspan="1">17.35%</td><td align="char" char="." rowspan="1" colspan="1">82.65%</td></tr><tr><td align="left" rowspan="1" colspan="1">Derby</td><td align="left" rowspan="1" colspan="1">Java-based relational database engine</td><td align="char" char="." rowspan="1" colspan="1">9.42</td><td align="right" rowspan="1" colspan="1">1350</td><td align="right" rowspan="1" colspan="1">8,268</td><td align="right" rowspan="1" colspan="1">2004&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">41.86%</td><td align="char" char="." rowspan="1" colspan="1">58.14%</td><td align="char" char="." rowspan="1" colspan="1">42.01%</td><td align="char" char="." rowspan="1" colspan="1">57.99%</td></tr><tr><td align="left" rowspan="1" colspan="1">Geronimo</td><td align="left" rowspan="1" colspan="1">An open-source server runtime</td><td align="char" char="." rowspan="1" colspan="1">6.79</td><td align="right" rowspan="1" colspan="1">48</td><td align="right" rowspan="1" colspan="1">13,137</td><td align="right" rowspan="1" colspan="1">2003&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">42.66%</td><td align="char" char="." rowspan="1" colspan="1">57.34%</td><td align="char" char="." rowspan="1" colspan="1">43.15%</td><td align="char" char="." rowspan="1" colspan="1">56.85%</td></tr><tr><td align="left" rowspan="1" colspan="1">Hadoop</td><td align="left" rowspan="1" colspan="1">Open-source distributed computing system</td><td align="char" char="." rowspan="1" colspan="1">11.59</td><td align="right" rowspan="1" colspan="1">102</td><td align="right" rowspan="1" colspan="1">16,084</td><td align="right" rowspan="1" colspan="1">2009&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">47.58%</td><td align="char" char="." rowspan="1" colspan="1">52.42%</td><td align="char" char="." rowspan="1" colspan="1">47.41%</td><td align="char" char="." rowspan="1" colspan="1">52.59%</td></tr><tr><td align="left" rowspan="1" colspan="1">HBase</td><td align="left" rowspan="1" colspan="1">A distributed, scalable, big data store</td><td align="char" char="." rowspan="1" colspan="1">5.03</td><td align="right" rowspan="1" colspan="1">413</td><td align="right" rowspan="1" colspan="1">10,509</td><td align="right" rowspan="1" colspan="1">2007&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">0.26%</td><td align="char" char="." rowspan="1" colspan="1">99.74%</td><td align="char" char="." rowspan="1" colspan="1">0.23%</td><td align="char" char="." rowspan="1" colspan="1">99.77%</td></tr><tr><td align="left" rowspan="1" colspan="1">IVY</td><td align="left" rowspan="1" colspan="1">A project dependencies managing tool</td><td align="char" char="." rowspan="1" colspan="1">3.29</td><td align="right" rowspan="1" colspan="1">135</td><td align="right" rowspan="1" colspan="1">2,880</td><td align="right" rowspan="1" colspan="1">2005&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">35.20%</td><td align="char" char="." rowspan="1" colspan="1">64.80%</td><td align="char" char="." rowspan="1" colspan="1">35.38%</td><td align="char" char="." rowspan="1" colspan="1">64.62%</td></tr><tr><td align="left" rowspan="1" colspan="1">JCR</td><td align="left" rowspan="1" colspan="1">Repo for Java Technology API</td><td align="char" char="." rowspan="1" colspan="1">8.82</td><td align="right" rowspan="1" colspan="1">38</td><td align="right" rowspan="1" colspan="1">8,651</td><td align="right" rowspan="1" colspan="1">2004&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">2.87%</td><td align="char" char="." rowspan="1" colspan="1">97.13%</td><td align="char" char="." rowspan="1" colspan="1">2.84%</td><td align="char" char="." rowspan="1" colspan="1">97.16%</td></tr><tr><td align="left" rowspan="1" colspan="1">JMeter</td><td align="left" rowspan="1" colspan="1">Load test applications/measure performance</td><td align="char" char="." rowspan="1" colspan="1">15.89</td><td align="right" rowspan="1" colspan="1">264</td><td align="right" rowspan="1" colspan="1">16,341</td><td align="right" rowspan="1" colspan="1">1998&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">18.04%</td><td align="char" char="." rowspan="1" colspan="1">81.96%</td><td align="char" char="." rowspan="1" colspan="1">18.09%</td><td align="char" char="." rowspan="1" colspan="1">81.91%</td></tr><tr><td align="left" rowspan="1" colspan="1">LOG4J2</td><td align="left" rowspan="1" colspan="1">A logging library for Java</td><td align="char" char="." rowspan="1" colspan="1">5.37</td><td align="right" rowspan="1" colspan="1">85</td><td align="right" rowspan="1" colspan="1">10,690</td><td align="right" rowspan="1" colspan="1">2010&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">10.96%</td><td align="char" char="." rowspan="1" colspan="1">89.04%</td><td align="char" char="." rowspan="1" colspan="1">11.35%</td><td align="char" char="." rowspan="1" colspan="1">88.65%</td></tr><tr><td align="left" rowspan="1" colspan="1">LUCENE</td><td align="left" rowspan="1" colspan="1">Full-featured text search engine library</td><td align="char" char="." rowspan="1" colspan="1">15.93</td><td align="right" rowspan="1" colspan="1">183</td><td align="right" rowspan="1" colspan="1">31,240</td><td align="right" rowspan="1" colspan="1">2001&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">20.48%</td><td align="char" char="." rowspan="1" colspan="1">79.52%</td><td align="char" char="." rowspan="1" colspan="1">20.60%</td><td align="char" char="." rowspan="1" colspan="1">79.40%</td></tr><tr><td align="left" rowspan="1" colspan="1">Mahout</td><td align="left" rowspan="1" colspan="1">Linear algebra framework and Scala DSL</td><td align="char" char="." rowspan="1" colspan="1">5.52</td><td align="right" rowspan="1" colspan="1">189</td><td align="right" rowspan="1" colspan="1">4,115</td><td align="right" rowspan="1" colspan="1">2008&#8211;2020</td><td align="char" char="." rowspan="1" colspan="1">36.57%</td><td align="char" char="." rowspan="1" colspan="1">63.43%</td><td align="char" char="." rowspan="1" colspan="1">36.76%</td><td align="char" char="." rowspan="1" colspan="1">63.24%</td></tr><tr><td align="left" style="border-bottom-width:thick" rowspan="1" colspan="1">OpenJPA</td><td align="left" style="border-bottom-width:thick" rowspan="1" colspan="1">Java Persistence API specification</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">7.72</td><td align="right" style="border-bottom-width:thick" rowspan="1" colspan="1">108</td><td align="right" style="border-bottom-width:thick" rowspan="1" colspan="1">4,893</td><td align="right" style="border-bottom-width:thick" rowspan="1" colspan="1">2006&#8211;2020</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">32.70%</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">67.30%</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">32.49%</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">67.51%</td></tr></tbody></table></alternatives></table-wrap><p>The dataset, which is also available for download [<xref rid="pone.0284077.ref022" ref-type="bibr">22</xref>], focuses on the active middle part of each software effort by trimming off the inactive start and end of each project. The final dataset contains over 85% of the changes spanning only 30% of the original development period. This dataset already contains the annotated, defect-prone changes after running an open-source implementation of the SZZ algorithm, known as <italic toggle="yes">SZZ Unleashed</italic> [<xref rid="pone.0284077.ref029" ref-type="bibr">29</xref>].</p><p>When processing this dataset, the focus is on identifying early exposed defects by tracking the time gap between defect-prone changes and defect exposure. A threshold, <italic toggle="yes">&#952;</italic>, is used to identify early exposed defects, which are defects that last less than <italic toggle="yes">&#952;</italic>. Specifically, <italic toggle="yes">&#952;</italic> = min(4 <italic toggle="yes">weeks</italic>, 1% &#215; (<italic toggle="yes">&#964;</italic> &#8722; <italic toggle="yes">&#964;</italic><sub>0</sub>)), where <italic toggle="yes">&#964;</italic><sub>0</sub> and <italic toggle="yes">&#964;</italic> are the beginning and the end time of the whole project. This helps account for the time span of software projects, which can vary from months to years. We used whether or not a software change contains early exposed defects as the dependent variable for the JIT defect prediction.</p><p>Note that the dataset we used here already provides labeled defect introduction fix pairs [<xref rid="pone.0284077.ref010" ref-type="bibr">10</xref>]. However, the proposed framework is flexible enough to be used in other code repos in which the SZZ algorithm can be applied on the required version control logs and labeled defects.</p></sec><sec id="sec020"><title>3.3 Study setup</title><p>We randomly partition the dataset of labeled changes into training sets (75%) and testing sets (25%). The testing data is only used once for computing the performance of the classification task. We implemented the proposed framework using the <monospace specific-use="no-wrap">scikit-learn</monospace> [<xref rid="pone.0284077.ref057" ref-type="bibr">57</xref>] and <monospace specific-use="no-wrap">imbalanced-learn</monospace> [<xref rid="pone.0284077.ref058" ref-type="bibr">58</xref>] APIs. After the train/test split, the following steps are performed.</p><sec id="sec021"><title>3.3.1 Data preparation</title><p>We scaled independent variables using min-max normalization. We noticed that the dataset is imbalanced given that the number of defect-prone changes in both training and testing datasets is much smaller than the number of benign changes (see <xref rid="pone.0284077.t003" ref-type="table">Table 3</xref>). We used the Synthetic Minority Oversampling Technique (SMOTE) to handle the imbalance [<xref rid="pone.0284077.ref059" ref-type="bibr">59</xref>]. SMOTE processes each sample in the minority class to generate new synthetic samples along the line by joining them to their <italic toggle="yes">k</italic>-nearest neighbors. We used regular SMOTE with <italic toggle="yes">k</italic> = 5, owing to its simplicity and higher performance. SMOTE can also help increase the framework&#8217;s ability to classify defective modules [<xref rid="pone.0284077.ref060" ref-type="bibr">60</xref>]. We applied SMOTE only in the training dataset.</p></sec><sec id="sec022"><title>3.3.2 Build model</title><p>We trained prediction models by using the labeled training dataset. The methods used to train the models are described in Section 3.4.</p></sec><sec id="sec023"><title>3.3.3 Select model</title><p>To achieve optimal performance, tuning is performed to find the optimal set of hyperparameters for each model. A grid search is used to consider a small combination of parameters with reasonable values, and a stratified, 10-fold cross validation is implemented to evaluate model performance during this step.</p></sec><sec id="sec024"><title>3.3.4 Apply model</title><p>The optimal defect prediction model is applied on the testing dataset. For each change in the testing dataset, the proposed model predicts whether the change is likely to introduce a defect and then outputs a binary label.</p></sec></sec><sec id="sec025"><title>3.4 Building prediction models</title><p>The graph-based ML models for JIT defect prediction are built using two settings. The first setting leverages features extracted from the centrality properties of the one-mode projection graph (i.e., degree, betweenness, closeness, harmonic, and PageRank). The second setting uses the community assignment and the nodes&#8217; embeddings in the one-mode projection graph.</p><p>Both settings use three types of classifiers: (1) logistic regression (regression-based classifier), (2) random forest (ML-based classifier), and (3) extreme gradient boosting (XGBoost) (ML-based classifier). These classifiers have been widely used for JIT defect prediction [<xref rid="pone.0284077.ref004" ref-type="bibr">4</xref>, <xref rid="pone.0284077.ref035" ref-type="bibr">35</xref>, <xref rid="pone.0284077.ref061" ref-type="bibr">61</xref>]. Each classifier is described below along with their train and test time complexities. Here, <italic toggle="yes">n</italic> refers to the number of samples, <italic toggle="yes">m</italic> refers to the number of features, <italic toggle="yes">t</italic> is the number of trees, <italic toggle="yes">d</italic> is the height of the trees, and <italic toggle="yes">x</italic> is the number of non-missing entries in the training dataset [<xref rid="pone.0284077.ref062" ref-type="bibr">62</xref>]. Their default parameters were used unless otherwise noted.</p><sec id="sec026"><title>3.4.1 Logistic regression</title><p>Logistic regression is used for binary classification [<xref rid="pone.0284077.ref063" ref-type="bibr">63</xref>] and models the relationship between one or more independent variables (i.e., extracted from the one-mode projection graph) and a binary dependent variable (i.e., defect-prone or clean changes). The training and testing time complexities of logistic regression are <italic toggle="yes">O</italic>(<italic toggle="yes">nm</italic>) and <italic toggle="yes">O</italic>(<italic toggle="yes">m</italic>) respectively. We performed a grid search over the inverse of the regularization strength parameter: <italic toggle="yes">C</italic> &#8712; [0.01, 0.1, 1.0, 10, 100]. The optimal value is 100. The training and testing time complexities of logistic regression are <italic toggle="yes">O</italic>(<italic toggle="yes">nm</italic>) and <italic toggle="yes">O</italic>(<italic toggle="yes">m</italic>), respectively.</p></sec><sec id="sec027"><title>3.4.2 Random forest</title><p>Random forest is an ensemble method that leverages a large number of decision trees [<xref rid="pone.0284077.ref064" ref-type="bibr">64</xref>]. Each of these trees focuses on a random subset of features. When reporting a decision, trees may report different results. The random forest then aggregates each of the results from the trees to make a final decision. The training and testing time complexities of random forest are <italic toggle="yes">O</italic>(<italic toggle="yes">tn</italic>log<italic toggle="yes">nm</italic>) and <italic toggle="yes">O</italic>(<italic toggle="yes">mt</italic>) respectively. We performed a grid search of trees in the forest parameter: <monospace specific-use="no-wrap">n_estimators</monospace> &#8712; [10, 100, 1000]. We found that the optimal value is 100.</p></sec><sec id="sec028"><title>3.4.3 XGBoost</title><p>XGBoost is an implementation of gradient-boosted decision trees that is designed for speed and performance [<xref rid="pone.0284077.ref065" ref-type="bibr">65</xref>]. Boosting is an ensemble method in which new models are added iteratively to improve performance. The process stops at diminishing returns. Gradient boosting is used to create new models that predict the error of previous models; they are then added together to make a final decision. Gradient boosting uses gradient descent to minimize errors when adding new models. The training and testing time complexities of XGBoost are <italic toggle="yes">O</italic>(<italic toggle="yes">tdx</italic>log<italic toggle="yes">n</italic>) and <italic toggle="yes">O</italic>(<italic toggle="yes">td</italic>) respectively. We performed a grid search of the learning rate parameter, <monospace specific-use="no-wrap">learning_rate</monospace> &#8712;[0.001, 0.01, 0.1], and of the number of trees in the forest parameter, <monospace specific-use="no-wrap">n_estimators</monospace> &#8712; [10, 100, 1000]. We found that the optimal set of values is 0.01 for the learning rate and 1000 for the number of trees.</p></sec></sec><sec id="sec029"><title>3.5 Evaluation metrics</title><p>We used confusion matrix&#8211;based metrics to compute the performance of the proposed methods, which have been widely employed for JIT defect prediction [<xref rid="pone.0284077.ref010" ref-type="bibr">10</xref>, <xref rid="pone.0284077.ref066" ref-type="bibr">66</xref>]. The basis for comparison is counting the number of code changes that were labeled as true positives (TP), false positives (FP), false negatives (FN), and true negatives (TN). We focus on <italic toggle="yes">Precision</italic>, defined as <inline-formula id="pone.0284077.e043"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e043g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e043.jpg"/><mml:math id="M43" display="inline" overflow="scroll"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>, which gives the likelihood that a detected change is defect-prone; <italic toggle="yes">Recall</italic>, defined as <inline-formula id="pone.0284077.e044"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e044g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e044.jpg"/><mml:math id="M44" display="inline" overflow="scroll"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>, which gives the likelihood that a defect-prone change is detected; <italic toggle="yes">F1 score</italic>, defined as <inline-formula id="pone.0284077.e045"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e045g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e045.jpg"/><mml:math id="M45" display="inline" overflow="scroll"><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#215;</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>, which combines precision and recall to provide a balanced view between them; and the Matthews correlation coefficient (MCC), defined as <inline-formula id="pone.0284077.e046"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.e046g" position="anchor" orientation="portrait" xlink:href="pone.0284077.e046.jpg"/><mml:math id="M46" display="inline" overflow="scroll"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:msqrt><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>)</mml:mo><mml:mo>&#215;</mml:mo><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo>)</mml:mo><mml:mo>&#215;</mml:mo><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>)</mml:mo><mml:mo>&#215;</mml:mo><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac></mml:math></alternatives></inline-formula>, which is the Pearson correlation for a contingency table [<xref rid="pone.0284077.ref067" ref-type="bibr">67</xref>]. MCC takes values in the range [&#8722;1, 1], with extreme values &#8722;1 and + 1 reached in the case of perfect misclassification and perfect classification, respectively. MCC equals 0 is equivalent to the expected value for the coin-tossing classifier. We include the MCC metric because the above metrics overemphasize the positive class while not putting much emphasis on the negative class, which is also important for defect prediction. Note, however, that among the 14 repos that we analyzed, they have different levels of imbalance with only one of them (HBase in <xref rid="pone.0284077.t002" ref-type="table">Table 2</xref>) showing extreme imbalance (i.e., less than 1% for the minority class [<xref rid="pone.0284077.ref068" ref-type="bibr">68</xref>]). Therefore, we report results by using precision, recall, and F1 scores in addition to MCC. We let the reader explore the literature [<xref rid="pone.0284077.ref069" ref-type="bibr">69</xref>, <xref rid="pone.0284077.ref070" ref-type="bibr">70</xref>] for a more thorough discussion of the advantages of MCC over other classification metrics. We evaluate the performance of our proposed framework against a state-of-the-art baseline that uses software-level characteristics as features of a random forest classifier [<xref rid="pone.0284077.ref010" ref-type="bibr">10</xref>].</p><p>To compare the performance of the proposed framework using different classifiers over a range of detection thresholds, we used the Precision-Recall (PR) curve. We chose the PR curve instead of the commonly used receiver operating characteristic curve because the PR curve is better suited for handling highly imbalanced datasets [<xref rid="pone.0284077.ref071" ref-type="bibr">71</xref>, <xref rid="pone.0284077.ref072" ref-type="bibr">72</xref>]. We reported the results of precision, recall, and F1 score based on the optimal threshold obtained from the PR curve for the F1 score. We report results for the MCC based on the default threshold of 0.5. The PR curve also allows for a head-to-head method comparison (independent of thresholds) based on the area under the PR curve (AUC-PR). Higher percentages indicate better overall performance. Note that this metric was not computed in the state-of-the-art baseline. Given that our results are aggregated over different datasets, for comparison we report the mean value and the average rank of each classifier on each metric across the 14 datasets (shown in the <italic toggle="yes">Avg. R</italic> column in <xref rid="pone.0284077.t004" ref-type="table">Table 4</xref>).</p><table-wrap position="float" id="pone.0284077.t004" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0284077.t004</object-id><label>Table 4</label><caption><title>Classification results for both settings with the two best performing classifiers shown in bold text.</title></caption><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0284077.t004g" position="float" orientation="portrait" xlink:href="pone.0284077.t004.jpg"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" colspan="2" rowspan="2" style="border-top-width:thick"/><th align="center" colspan="2" style="border-top-width:thick" rowspan="1">Precision</th><th align="center" colspan="2" style="border-top-width:thick" rowspan="1">Recall</th><th align="center" colspan="2" style="border-top-width:thick" rowspan="1">F1 score</th><th align="center" colspan="2" style="border-top-width:thick" rowspan="1">MCC</th><th align="center" colspan="2" style="border-top-width:thick" rowspan="1">AUC-PR</th></tr><tr><th align="center" rowspan="1" colspan="1">Mean</th><th align="center" rowspan="1" colspan="1">Avg. R</th><th align="center" rowspan="1" colspan="1">Mean</th><th align="center" rowspan="1" colspan="1">Avg. R</th><th align="center" rowspan="1" colspan="1">Mean</th><th align="center" rowspan="1" colspan="1">Avg. R</th><th align="center" rowspan="1" colspan="1">Mean</th><th align="center" rowspan="1" colspan="1">Avg. R</th><th align="center" rowspan="1" colspan="1">Mean</th><th align="center" rowspan="1" colspan="1">Avg. R</th></tr></thead><tbody><tr><td align="left" rowspan="3" colspan="1">Setting 1</td><td align="left" rowspan="1" colspan="1">Logistic Regression</td><td align="char" char="." rowspan="1" colspan="1">0.6050</td><td align="char" char="." rowspan="1" colspan="1">2.57</td><td align="char" char="." rowspan="1" colspan="1">0.6005</td><td align="char" char="." rowspan="1" colspan="1">2.64</td><td align="char" char="." rowspan="1" colspan="1">0.5871</td><td align="char" char="." rowspan="1" colspan="1">2.86</td><td align="char" char="." rowspan="1" colspan="1">0.3393</td><td align="char" char="." rowspan="1" colspan="1">2.64</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.8074</bold>
</td><td align="char" char="." rowspan="1" colspan="1">2.29</td></tr><tr><td align="left" rowspan="1" colspan="1">Random Forest</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.7359</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>2.00</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.8241</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.86</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.7724</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.79</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.5316</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.86</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.8022</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>2.07</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">XGBoost</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.7341</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.43</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.8239</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.50</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.7755</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.36</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.5234</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.50</bold>
</td><td align="char" char="." rowspan="1" colspan="1">0.7993</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.64</bold>
</td></tr><tr><td align="left" rowspan="3" colspan="1">Setting 2</td><td align="left" rowspan="1" colspan="1">Logistic Regression</td><td align="char" char="." rowspan="1" colspan="1">0.6407</td><td align="char" char="." rowspan="1" colspan="1">2.50</td><td align="char" char="." rowspan="1" colspan="1">0.7773</td><td align="char" char="." rowspan="1" colspan="1">2.36</td><td align="char" char="." rowspan="1" colspan="1">0.6950</td><td align="char" char="." rowspan="1" colspan="1">2.36</td><td align="char" char="." rowspan="1" colspan="1">0.3231</td><td align="char" char="." rowspan="1" colspan="1">2.64</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.8151</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.93</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Random Forest</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.7343</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>2.07</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.8237</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>2.00</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.7714</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>2.00</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.5215</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>2.07</bold>
</td><td align="char" char="." rowspan="1" colspan="1">0.8015</td><td align="char" char="." rowspan="1" colspan="1">2.21</td></tr><tr><td align="left" rowspan="1" colspan="1">XGBoost</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.7418</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.43</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.8235</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.64</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.7748</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.64</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.5234</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.29</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>0.8061</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>1.86</bold>
</td></tr><tr><td align="left" style="border-bottom-width:thick" rowspan="1" colspan="1">Beseline [<xref rid="pone.0284077.ref010" ref-type="bibr">10</xref>]</td><td align="left" style="border-bottom-width:thick" rowspan="1" colspan="1">Random Forest</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">0.4673</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">1.03</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">0.7644</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">1.03</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">0.3083</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">1.03</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">0.5141</td><td align="char" char="." style="border-bottom-width:thick" rowspan="1" colspan="1">1.03</td><td align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">&#8212;</td><td align="center" style="border-bottom-width:thick" rowspan="1" colspan="1">&#8212;</td></tr></tbody></table></alternatives></table-wrap></sec></sec><sec sec-type="results" id="sec030"><title>4 Results</title><p>This section details the performance of the proposed framework based on graph-based ML for JIT defect prediction.</p><sec id="sec031"><title>4.1 Comparison of graph-based ML with the baseline</title><p>We applied the two settings of graph-based ML classifiers and measured the performance in the classification task by using the mean and average ranks of Precision, Recall, F1 score, AUC-PR, and MCC across the 14 repositories of code. These metrics are defined in Section 3.5. <xref rid="pone.0284077.t004" ref-type="table">Table 4</xref> summarizes the results based on the performance evaluation in the two settings (see Section 3.4 for details). We observe that the graph-based ML classifiers based on random forest and XGBoost (in both settings) outperform the baseline that uses a random forest classifier in terms of F1 score and MCC. The baseline reports lower precision on average than the proposed framework in both settings. This means that the proposed framework produces fewer FPs, even when using a simpler classifier, such as logistic regression. Likewise, the baseline reports lower average recall results, suggesting that the proposed framework detects more defect-prone changes (TPs) than the baseline, on average. The F1 scores obtained by the proposed framework show a relative improvement of at least 90% (from 30.83% to 58.71%) for the logistic regression classifier in Setting 1 and as much as 152% (from 30.83% to 77.55%) for the XGBoost classifier in Setting 1. Finally, the MCC scores obtained with the proposed framework are relatively higher than the baseline for random forest and XGBoost classifiers (i.e., 3% [from 51.41% to 53.16%] and 2% [from 51.41% to 52.34%] in Setting 1 and 1% [from 51.41% to 52.15%] and 2% [from 51.41% to 52.34%] in Setting 2). These MCC scores reflect a moderate positive relationship (between 0.3 and 0.7 based on [<xref rid="pone.0284077.ref073" ref-type="bibr">73</xref>]). Yet, this does not hold for the logistic regression classifier. Note, however, that the F1 score and MCC results are concordant when using random forest and XGBoost classifiers, meaning that we obtain consistent preferred classifiers regardless of whether we use an F1 score or MCC score when comparing with the baseline [<xref rid="pone.0284077.ref070" ref-type="bibr">70</xref>]. This provides empirical evidence that the proposed framework performs better than the state-of-the-art baseline when using classifiers of similar complexity.</p></sec><sec id="sec032"><title>4.2 Comparison of graph-based ML classifiers</title><p>We also compare the performance of different classifiers in each setting by using the mean of AUC-PR. Under Setting 1, the three classifiers perform similarly with a slight advantage of logistic regression (80.74%) over random forest (80.22%) and XGBoost (79.93%). The relative performance increase of logistic regression based on AUC-PR is at most 1% over XGBoost. Note, however, that the XGBoost classifier tends to perform best in terms of average ranking across the 14 repos (i.e., [1.64] over random forest [2.07] and logistic regression [2.29]). Under Setting 2, the best performing classifier based on average AUC-PR is logistic regression (81.51%) followed by XGBoost (80.61%) with a relative performance increase of at most 1%. However, like in Setting 1, the best performing classifier based on rankings is again XGBoost (1.86) over logistic regression (1.93) and random forest (2.21). This suggests that across repos, XGBoost consistently has the best performance despite outliers.</p><p>In general, we observe that the performance of graph-based ML classifiers is similar in each setting based on mean AUC-PR. The observed differences based on rankings are of at most 0.65 (from 1.64 of XGBoost to 2.29 of logistic regression) in Setting 1 and 0.35 (from 1.86 of XGBoost to 2.21 of random forest) in Setting 2. This suggests that the exclusive use of structural features from the contribution graphs in the classification task (i.e., Setting 1) benefits from a more complex classification function derived from more advanced classifiers, such as random forest and XGBoost. In contrast, under Scenario 2, the more complex features make the classifier task less determinant. This observation is also corroborated by the reported average rankings. Recall that in Setting 2, we use community assignments and node embeddings of length 128.</p></sec></sec><sec sec-type="conclusions" id="sec033"><title>5 Discussion</title><p>JIT defect prediction is at the core of software quality assurance efforts. Here, we proposed using graph-based ML to improve JIT defect prediction. To do so, we constructed contribution graphs (or bipartite graphs made of developers and source files) and framed the JIT defect prediction challenge as an edge classification problem, in which the objective was to classify defect-prone edges in the contribution graph. We extracted features from a projected version of the contribution graph by computing centrality measures of the nodes (Setting 1) and community assignment and node embeddings (Setting 2). We showed that the relative performance increase in the JIT defect prediction task is 152% for F1 score and 3% for MCC over the state-of-the-art baseline when using Setting 1.</p><p>We validated the effectiveness of the proposed approach by performing JIT defect prediction on 14 open-source software projects. We assessed the predictive power of graph-based features on edge classification using logistic regression, random forest, and XGBoost classifiers. Overall, we found that using graph-based features improved classification accuracy over traditional repo-based features, such as those related to size, purpose, and history of code bases. Comparing Setting 1 and Setting 2, we find that they tend to produce similar results encoded in almost negligible differences in the mean of classification results. Comparing classification models based on rankings, XGBoost outperformed random forest and logistic regression for the code bases we tested in our approach&#8212;at the expense of computational complexity. We conclude, however, that by using the features derived from Setting 2, the decision of what classifier to use for better performance is less important and produces negligible differences. We are sharing the data [<xref rid="pone.0284077.ref022" ref-type="bibr">22</xref>] and code [<xref rid="pone.0284077.ref023" ref-type="bibr">23</xref>] used in this research so that our results can be reproduced.</p><p>The proposed graph-based ML framework is effective at improving the detection performance of JIT defect prediction. Having noted the potential, we are also aware of some limitations of the proposed work.</p><sec id="sec034"><title>5.1 Accuracy of the SZZ algorithm</title><p>Our analysis is based on the assumption that code changes are correctly labeled by the SZZ algorithm. We acknowledge that SZZ can mislabel changes, thereby impacting the results of JIT defect prediction [<xref rid="pone.0284077.ref074" ref-type="bibr">74</xref>].</p></sec><sec id="sec035"><title>5.2 Extracting features from static graphs</title><p>We study a snapshot of a contribution graph, but this is inherently dynamic. This implies that the structural features and the node embeddings extracted using <monospace specific-use="no-wrap">node2vec</monospace> need to be recomputed when the graph changes so that they do not generalize to unseen nodes and/or edges. Thus, we did not assess, until what extent, the temporal information of developers changing files may be useful for the prediction of software defects.</p></sec><sec id="sec036"><title>5.3 Strict focus in network topology</title><p>Our analysis relies on the structure of the contribution graphs to generate classification features. We do not consider node and/or edge attributes, such as experience, programming proficiency, and education, in the case of nodes; and we do not consider characteristics of code changes, such as size, diversification of changes, and time, in the case of edges.</p></sec><sec id="sec037"><title>5.4 Feature-importance assessment</title><p>We report results based on average performance and rankings for precision, recall, F1 score, and AUC-PRC. This compact performance representation can hinder specific performance details for particular code bases and the effect of model features (for both Setting 1 and Setting 2).</p></sec><sec id="sec038"><title>5.5 Classifier&#8217;s complexity and interpretability</title><p>Performance gains obtained by using the graph-based ML classifiers are fueled by the rich set of features extracted from the contribution graphs. However, classification results are also dependent on the type of classifier used. In that respect, both complexity and interpretability are advantages of the simpler models, such as logistic regression, as opposed to more robust models, such as random forest and XGBoost, despite superior performance.</p></sec><sec id="sec039"><title>5.6 Use of default graph algorithms&#8217; parameter values</title><p>We run the graph algorithms to extract features from the one-mode projection graphs by using their default parameters. See related documentation of graph algorithm parameters in [<xref rid="pone.0284077.ref075" ref-type="bibr">75</xref>]. Thus, we do not optimize results by tuning these parameters.</p></sec><sec id="sec040"><title>5.7 Use of AUC-style metrics to compare classifiers</title><p>Note that AUC-style metrics are based on a family of possible classifiers at different thresholds instead of a specific classifier. Because in practice only a single classifier can be deployed, we also include other metrics that focus on a single threshold (i.e., F1 score and MCC) to better qualify the best performing classifier.</p></sec></sec><sec sec-type="conclusions" id="sec041"><title>6 Conclusion</title><p>In this paper, we show the potential of graph-based ML for JIT defect prediction. The proposed framework outperforms the state-of-the-art in JIT defect prediction with a higher average F1 score (152%) and higher average MCC (3%) across 14 open-source projects. Our contribution focus on characterizing the process of building software using a contribution graph (a bipartite graph of developers and source files) by capturing the nuanced structure of code collaborations. In the contribution graph, edges represent code changes made by developers. Our proposed framework leverages centrality metrics (Setting 1) and node&#8217;s community assignments and embeddings (Setting 2) extracted from the contribution graph for edge classification. Relying on this abstraction, we detailed a classification framework that can decide whether a change is defect-prone or not.</p><p>Future work will include examining the effectiveness of the proposed approach using inductive embedding frameworks, such as GraphSAGE [<xref rid="pone.0284077.ref076" ref-type="bibr">76</xref>]. The approach proposed in this work would benefit from an inductive framework that can efficiently generate node embeddings from previously unseen graph data by aggregating features from node-local neighborhoods, including node attributes. In addition, future work could include benchmarking the effectiveness of the proposed framework with more diverse codebases to further improve the generalizability of the proposed method. A working prototype for JIT defect prediction using the principles described in this paper seems feasible because the tools are available and ready to use in the Neo4j Graph Data Science API.</p></sec></body><back><ack><p>We are grateful to the reviewers and the editor for their constructive input that help us to improve our manuscript. Pablo Moriano thanks David Womble and Sudip Seal for their guidance.</p></ack><ref-list><title>References</title><ref id="pone.0284077.ref001"><label>1</label><mixed-citation publication-type="other">Bacchelli A, Bird C. Expectations, outcomes, and challenges of modern code review. In: 35th International Conference on Software Engineering (ICSE); 2013. p. 712&#8211;721.</mixed-citation></ref><ref id="pone.0284077.ref002"><label>2</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Telang</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Wattal</surname><given-names>S</given-names></name>. <article-title>An empirical analysis of the impact of software vulnerability announcements on firm stock price</article-title>. <source>IEEE Trans Softw Eng</source>. <year>2007</year>;<volume>33</volume>(<issue>8</issue>):<fpage>544</fpage>&#8211;<lpage>557</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TSE.2007.70712</pub-id></mixed-citation></ref><ref id="pone.0284077.ref003"><label>3</label><mixed-citation publication-type="other">Hassan AE. Predicting faults using the complexity of code changes. In: 31st IEEE International Conference on Software Engineering (ICSE); 2009. p. 78&#8211;88.</mixed-citation></ref><ref id="pone.0284077.ref004"><label>4</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Kamei</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Shihab</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Adams</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Hassan</surname><given-names>AE</given-names></name>, <name name-style="western"><surname>Mockus</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sinha</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>A large-scale empirical study of just-in-time quality assurance</article-title>. <source>IEEE Trans Softw Eng</source>. <year>2012</year>;<volume>39</volume>(<issue>6</issue>):<fpage>757</fpage>&#8211;<lpage>773</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TSE.2012.70</pub-id></mixed-citation></ref><ref id="pone.0284077.ref005"><label>5</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Hall</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Beecham</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Bowes</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Gray</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Counsell</surname><given-names>S</given-names></name>. <article-title>A systematic literature review on fault prediction performance in software engineering</article-title>. <source>IEEE Trans Softw Eng</source>. <year>2011</year>;<volume>38</volume>(<issue>6</issue>):<fpage>1276</fpage>&#8211;<lpage>1304</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TSE.2011.103</pub-id></mixed-citation></ref><ref id="pone.0284077.ref006"><label>6</label><mixed-citation publication-type="other">Zimmermann T, Premraj R, Zeller A. Predicting defects for eclipse. In: Third International Workshop on Predictor Models in Software Engineering (PROMISE&#8217;07: ICSE Workshops 2007); 2007. p. 9&#8211;9.</mixed-citation></ref><ref id="pone.0284077.ref007"><label>7</label><mixed-citation publication-type="other">Nagappan N, Ball T. Use of relative code churn measures to predict system defect density. In: 27th International Conference on Software Engineering (ICSE); 2005. p. 284&#8211;292.</mixed-citation></ref><ref id="pone.0284077.ref008"><label>8</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Kondo</surname><given-names>M</given-names></name>, <name name-style="western"><surname>German</surname><given-names>DM</given-names></name>, <name name-style="western"><surname>Mizuno</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Choi</surname><given-names>EH</given-names></name>. <article-title>The impact of context metrics on just-in-time defect prediction</article-title>. <source>Empir Softw Eng</source>. <year>2020</year>;<volume>25</volume>(<issue>1</issue>):<fpage>890</fpage>&#8211;<lpage>939</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10664-019-09736-3</pub-id></mixed-citation></ref><ref id="pone.0284077.ref009"><label>9</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Kamei</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Shihab</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Adams</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Hassan</surname><given-names>AE</given-names></name>, <name name-style="western"><surname>Mockus</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sinha</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>A large-scale empirical study of just-in-time quality assurance</article-title>. <source>IEEE Trans Softw Eng</source>. <year>2012</year>;<volume>39</volume>(<issue>6</issue>):<fpage>757</fpage>&#8211;<lpage>773</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TSE.2012.70</pub-id></mixed-citation></ref><ref id="pone.0284077.ref010"><label>10</label><mixed-citation publication-type="other">Tian Y, Li N, Tian J, Zheng W. How Well Just-In-Time Defect Prediction Techniques Enhance Software Reliability? In: 20th IEEE International Conference on Software Quality, Reliability and Security (QRS); 2020. p. 212&#8211;221.</mixed-citation></ref><ref id="pone.0284077.ref011"><label>11</label><mixed-citation publication-type="other">Yang X, Lo D, Xia X, Zhang Y, Sun J. Deep learning for just-in-time defect prediction. In: 15th IEEE International Conference on Software Quality, Reliability and Security (QRS); 2015. p. 17&#8211;26.</mixed-citation></ref><ref id="pone.0284077.ref012"><label>12</label><mixed-citation publication-type="other">Hoang T, Dam HK, Kamei Y, Lo D, Ubayashi N. DeepJIT: an end-to-end deep learning framework for just-in-time defect prediction. In: 16th IEEE/ACM International Conference on Mining Software Repositories (MSR); 2019. p. 34&#8211;45.</mixed-citation></ref><ref id="pone.0284077.ref013"><label>13</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Qiao</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name>. <article-title>Effort-aware and just-in-time defect prediction with neural network</article-title>. <source>PloS one</source>. <year>2019</year>;<volume>14</volume>(<issue>2</issue>):<fpage>e0211359</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0211359</pub-id><pub-id pub-id-type="pmid">30707738</pub-id><pub-id pub-id-type="pmcid">PMC6358090</pub-id></mixed-citation></ref><ref id="pone.0284077.ref014"><label>14</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Zhuang</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>X</given-names></name>. <article-title>Just-in-time defect prediction based on AST change embedding</article-title>. <source>Knowl Based Syst</source>. <year>2022</year>;<volume>248</volume>:<fpage>108852</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.knosys.2022.108852</pub-id></mixed-citation></ref><ref id="pone.0284077.ref015"><label>15</label><mixed-citation publication-type="other">Zimmermann T, Nagappan N, Gall H, Giger E, Murphy B. Cross-project defect prediction: a large scale experiment on data vs. domain vs. process. In: 7th joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE); 2009. p. 91&#8211;100.</mixed-citation></ref><ref id="pone.0284077.ref016"><label>16</label><mixed-citation publication-type="journal"><name name-style="western"><surname>McIntosh</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kamei</surname><given-names>Y</given-names></name>. <article-title>Are fix-inducing changes a moving target? a longitudinal case study of just-in-time defect prediction</article-title>. <source>IEEE Trans Softw Eng</source>. <year>2017</year>;<volume>44</volume>(<issue>5</issue>):<fpage>412</fpage>&#8211;<lpage>428</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TSE.2017.2693980</pub-id></mixed-citation></ref><ref id="pone.0284077.ref017"><label>17</label><mixed-citation publication-type="other">Pinzger M, Nagappan N, Murphy B. Can developer-module networks predict failures? In: 16th ACM SIGSOFT International Symposium on Foundations of Software Engineering (FSE); 2008. p. 2&#8211;12.</mixed-citation></ref><ref id="pone.0284077.ref018"><label>18</label><mixed-citation publication-type="other">Abou Daya A, Salahuddin MA, Limam N, Boutaba R. A graph-based machine learning approach for bot detection. In: IFIP/IEEE Symposium on Integrated Network and Service Management (IM); 2019. p. 144&#8211;152.</mixed-citation></ref><ref id="pone.0284077.ref019"><label>19</label><mixed-citation publication-type="journal"><name name-style="western"><surname>&#346;liwerski</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Zimmermann</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Zeller</surname><given-names>A</given-names></name>. <article-title>When do changes induce fixes?</article-title><source>Softw Eng Notes</source>. <year>2005</year>;<volume>30</volume>(<issue>4</issue>):<fpage>1</fpage>&#8211;<lpage>5</lpage>.</mixed-citation></ref><ref id="pone.0284077.ref020"><label>20</label><mixed-citation publication-type="other">Grover A, Leskovec J. node2vec: Scalable feature learning for networks. In: 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; 2016. p. 855&#8211;864.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1145/2939672.2939754</pub-id><pub-id pub-id-type="pmcid">PMC5108654</pub-id><pub-id pub-id-type="pmid">27853626</pub-id></mixed-citation></ref><ref id="pone.0284077.ref021"><label>21</label><mixed-citation publication-type="other">Aggarwal C, He G, Zhao P. Edge classification in networks. In: 32nd IEEE International Conference on Sata Engineering (ICDE); 2016. p. 1038&#8211;1049.</mixed-citation></ref><ref id="pone.0284077.ref022"><label>22</label><mixed-citation publication-type="other">Ning L. JiTReliability; 2020. <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/lining-nwpu/JiTReliability.git" ext-link-type="uri">https://github.com/lining-nwpu/JiTReliability.git</ext-link>.</mixed-citation></ref><ref id="pone.0284077.ref023"><label>23</label><mixed-citation publication-type="other">Bryan J. defect-prediction; 2022. <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/jtbryan/defect-prediction" ext-link-type="uri">https://github.com/jtbryan/defect-prediction</ext-link>.</mixed-citation></ref><ref id="pone.0284077.ref024"><label>24</label><mixed-citation publication-type="other">Zimmermann T, Nagappan N. Predicting defects using network analysis on dependency graphs. In: 30th IEEE International Conference on Software Engineering; 2008. p. 531&#8211;540.</mixed-citation></ref><ref id="pone.0284077.ref025"><label>25</label><mixed-citation publication-type="other">Meneely A, Williams L, Snipes W, Osborne J. Predicting failures with developer networks and social network analysis. In: 16th ACM SIGSOFT International Symposium on Foundations of Software Engineering (FSE); 2008. p. 13&#8211;23.</mixed-citation></ref><ref id="pone.0284077.ref026"><label>26</label><mixed-citation publication-type="other">Bird C, Nagappan N, Murphy B, Gall H, Devanbu P. Don&#8217;t touch my code! Examining the effects of ownership on software quality. In: 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering (FSE); 2011. p. 4&#8211;14.</mixed-citation></ref><ref id="pone.0284077.ref027"><label>27</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Shin</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Meneely</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Williams</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Osborne</surname><given-names>JA</given-names></name>. <article-title>Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities</article-title>. <source>IEEE Trans Softw Eng</source>. <year>2010</year>;<volume>37</volume>(<issue>6</issue>):<fpage>772</fpage>&#8211;<lpage>787</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TSE.2010.81</pub-id></mixed-citation></ref><ref id="pone.0284077.ref028"><label>28</label><mixed-citation publication-type="other">Moriano P, Pendleton J, Rich S, Camp LJ. Insider threat event detection in user-system interactions. In: International Workshop on Managing Insider Security Threats (MIST); 2017. p. 1&#8211;12.</mixed-citation></ref><ref id="pone.0284077.ref029"><label>29</label><mixed-citation publication-type="other">Borg M, Svensson O, Berg K, Hansson D. SZZ unleashed: An open implementation of the SZZ algorithm featuring example usage in a study of just-in-time bug prediction for the Jenkins project. In: 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation; 2019. p. 7&#8211;12.</mixed-citation></ref><ref id="pone.0284077.ref030"><label>30</label><mixed-citation publication-type="other">Zhao Y, Damevski K, Chen H. A Systematic Survey of Just-In-Time Software Defect Prediction: Online Supplement. ACM Computing Surveys. 2022;.</mixed-citation></ref><ref id="pone.0284077.ref031"><label>31</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Mockus</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Weiss</surname><given-names>DM</given-names></name>. <article-title>Predicting risk of software changes</article-title>. <source>Bell Labs Tech J</source>. <year>2000</year>;<volume>5</volume>(<issue>2</issue>):<fpage>169</fpage>&#8211;<lpage>180</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/bltj.2229</pub-id></mixed-citation></ref><ref id="pone.0284077.ref032"><label>32</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Kim</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Whitehead</surname><given-names>EJ</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>Y</given-names></name>. <article-title>Classifying software changes: Clean or buggy?</article-title><source>IEEE Trans Softw Eng</source>. <year>2008</year>;<volume>34</volume>(<issue>2</issue>):<fpage>181</fpage>&#8211;<lpage>196</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TSE.2007.70773</pub-id></mixed-citation></ref><ref id="pone.0284077.ref033"><label>33</label><mixed-citation publication-type="other">Jiang T, Tan L, Kim S. Personalized defect prediction. In: 28th IEEE/ACM International Conference on Automated Software Engineering (ASE); 2013. p. 279&#8211;289.</mixed-citation></ref><ref id="pone.0284077.ref034"><label>34</label><mixed-citation publication-type="other">Kononenko O, Baysal O, Guerrouj L, Cao Y, Godfrey MW. Investigating code review quality: Do people and participation matter? In: IEEE International Conference on Software Maintenance and Evolution (ICSME); 2015. p. 111&#8211;120.</mixed-citation></ref><ref id="pone.0284077.ref035"><label>35</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Kamei</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Fukushima</surname><given-names>T</given-names></name>, <name name-style="western"><surname>McIntosh</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Yamashita</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Ubayashi</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Hassan</surname><given-names>AE</given-names></name>. <article-title>Studying just-in-time defect prediction using cross-project models</article-title>. <source>Empir Softw Eng</source>. <year>2016</year>;<volume>21</volume>(<issue>5</issue>):<fpage>2072</fpage>&#8211;<lpage>2106</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10664-015-9400-x</pub-id></mixed-citation></ref><ref id="pone.0284077.ref036"><label>36</label><mixed-citation publication-type="other">Barnett JG, Gathuru CK, Soldano LS, McIntosh S. The relationship between commit message detail and defect proneness in java projects on github. In: 13th IEEE/ACM Working Conference on Mining Software Repositories (MSR); 2016. p. 496&#8211;499.</mixed-citation></ref><ref id="pone.0284077.ref037"><label>37</label><mixed-citation publication-type="other">Meyer TA, Whateley B. SpamBayes: Effective open-source, Bayesian based, email classification system. In: 7th Annual Collaboration, Electronic Messaging, Anti-Abuse and Spam Conference (CEAS); 2004.</mixed-citation></ref><ref id="pone.0284077.ref038"><label>38</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Xu</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Fu</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Yan</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Xie</surname><given-names>Z</given-names></name>, <etal>et al</etal>. <article-title>Effort-aware just-in-time bug prediction for mobile apps via cross-triplet deep feature embedding</article-title>. <source>IEEE Transactions on Reliability</source>. <year>2021</year>;<volume>71</volume>(<issue>1</issue>):<fpage>204</fpage>&#8211;<lpage>220</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TR.2021.3066170</pub-id></mixed-citation></ref><ref id="pone.0284077.ref039"><label>39</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Hamilton</surname><given-names>WL</given-names></name>, <name name-style="western"><surname>Ying</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Leskovec</surname><given-names>J</given-names></name>. <article-title>Representation learning on graphs: Methods and applications</article-title>. <source>IEEE Data Eng Bull</source>. <year>2017</year>;<volume>40</volume>(<issue>3</issue>):<fpage>52</fpage>&#8211;&#8211;<lpage>74</lpage>.</mixed-citation></ref><ref id="pone.0284077.ref040"><label>40</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Ding</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Yan</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Dai</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Dong</surname><given-names>L</given-names></name>. <article-title>Predicting the attributes of social network users using a graph-based machine learning method</article-title>. <source>Comput Commun</source>. <year>2016</year>;<volume>73</volume>:<fpage>3</fpage>&#8211;<lpage>11</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.comcom.2015.07.007</pub-id></mixed-citation></ref><ref id="pone.0284077.ref041"><label>41</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Perry</surname><given-names>BL</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>KC</given-names></name>, <name name-style="western"><surname>Kaminski</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Odabas</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Park</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Martel</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Co-prescription network reveals social dynamics of opioid doctor shopping</article-title>. <source>PloS One</source>. <year>2019</year>;<volume>14</volume>(<issue>10</issue>):<fpage>e0223849</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0223849</pub-id><pub-id pub-id-type="pmid">31652266</pub-id><pub-id pub-id-type="pmcid">PMC6814254</pub-id></mixed-citation></ref><ref id="pone.0284077.ref042"><label>42</label><mixed-citation publication-type="other">Bowman B, Laprade C, Ji Y, Huang HH. Detecting Lateral Movement in Enterprise Computer Networks with Unsupervised Graph AI. In: 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID); 2020.</mixed-citation></ref><ref id="pone.0284077.ref043"><label>43</label><mixed-citation publication-type="book"><name name-style="western"><surname>Bhagat</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Cormode</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Muthukrishnan</surname><given-names>S</given-names></name>. <part-title>Node classification in social networks</part-title>. In: <source>Social Network Data Analytics</source>. <publisher-name>Springer</publisher-name>; <year>2011</year>. p. <fpage>115</fpage>&#8211;<lpage>148</lpage>.</mixed-citation></ref><ref id="pone.0284077.ref044"><label>44</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Goyal</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Ferrara</surname><given-names>E</given-names></name>. <article-title>Graph embedding techniques, applications, and performance: A survey</article-title>. <source>Knowl-Based Syst</source>. <year>2018</year>;<volume>151</volume>:<fpage>78</fpage>&#8211;<lpage>94</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.knosys.2018.03.022</pub-id></mixed-citation></ref><ref id="pone.0284077.ref045"><label>45</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Roweis</surname><given-names>ST</given-names></name>, <name name-style="western"><surname>Saul</surname><given-names>LK</given-names></name>. <article-title>Nonlinear dimensionality reduction by locally linear embedding</article-title>. <source>Science</source>. <year>2000</year>;<volume>290</volume>(<issue>5500</issue>):<fpage>2323</fpage>&#8211;<lpage>2326</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1126/science.290.5500.2323</pub-id><pub-id pub-id-type="pmid">11125150</pub-id></mixed-citation></ref><ref id="pone.0284077.ref046"><label>46</label><mixed-citation publication-type="other">Belkin M, Niyogi P. Laplacian eigenmaps and spectral techniques for embedding and clustering. In: 14th International Conference on Neural Information Processing Systems (NIPS). vol. 14; 2001. p. 585&#8211;591.</mixed-citation></ref><ref id="pone.0284077.ref047"><label>47</label><mixed-citation publication-type="other">Perozzi B, Al-Rfou R, Skiena S. Deepwalk: Online learning of social representations. In: 20th ACM SIGKDD international Conference on Knowledge Discovery and Data Mining (KDD); 2014. p. 701&#8211;710.</mixed-citation></ref><ref id="pone.0284077.ref048"><label>48</label><mixed-citation publication-type="other">Wang D, Cui P, Zhu W. Structural deep network embedding. In: 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; 2016. p. 1225&#8211;1234.</mixed-citation></ref><ref id="pone.0284077.ref049"><label>49</label><mixed-citation publication-type="other">Cao S, Lu W, Xu Q. Deep neural networks for learning graph representations. In: 13th AAAI Conference on Artificial Intelligence. vol. 30; 2016.</mixed-citation></ref><ref id="pone.0284077.ref050"><label>50</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Nelson</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Zitnik</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Leskovec</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Goldenberg</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sharan</surname><given-names>R</given-names></name>. <article-title>To embed or not: network embedding as a paradigm in computational biology</article-title>. <source>Front Genet</source>. <year>2019</year>;<volume>10</volume>:<fpage>381</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fgene.2019.00381</pub-id><pub-id pub-id-type="pmid">31118945</pub-id><pub-id pub-id-type="pmcid">PMC6504708</pub-id></mixed-citation></ref><ref id="pone.0284077.ref051"><label>51</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Gong</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Ma</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Gong</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Yuan</surname><given-names>X</given-names></name>. <article-title>Neo4j graph database realizes efficient storage performance of oilfield ontology</article-title>. <source>PloS One</source>. <year>2018</year>;<volume>13</volume>(<issue>11</issue>):<fpage>e0207595</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0207595</pub-id><pub-id pub-id-type="pmid">30444913</pub-id><pub-id pub-id-type="pmcid">PMC6239324</pub-id></mixed-citation></ref><ref id="pone.0284077.ref052"><label>52</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Sabidussi</surname><given-names>G</given-names></name>. <article-title>The centrality index of a graph</article-title>. <source>Psychometrika</source>. <year>1966</year>;<volume>31</volume>(<issue>4</issue>):<fpage>581</fpage>&#8211;<lpage>603</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/BF02289527</pub-id><pub-id pub-id-type="pmid">5232444</pub-id></mixed-citation></ref><ref id="pone.0284077.ref053"><label>53</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Brin</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Page</surname><given-names>L</given-names></name>. <article-title>The anatomy of a large-scale hypertextual web search engine</article-title>. <source>Comput Netw</source>. <year>1998</year>;<volume>30</volume>(<issue>1-7</issue>):<fpage>107</fpage>&#8211;<lpage>117</lpage>.</mixed-citation></ref><ref id="pone.0284077.ref054"><label>54</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Fortunato</surname><given-names>S</given-names></name>. <article-title>Community detection in graphs</article-title>. <source>Phys Rep</source>. <year>2010</year>;<volume>486</volume>(<issue>3-5</issue>):<fpage>75</fpage>&#8211;<lpage>174</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.physrep.2009.11.002</pub-id></mixed-citation></ref><ref id="pone.0284077.ref055"><label>55</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Blondel</surname><given-names>VD</given-names></name>, <name name-style="western"><surname>Guillaume</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Lambiotte</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Lefebvre</surname><given-names>E</given-names></name>. <article-title>Fast unfolding of communities in large networks</article-title>. <source>J Stat Mech: Theory Exp</source>. <year>2008</year>;<volume>2008</volume>(<issue>10</issue>):<fpage>P10008</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1088/1742-5468/2008/10/P10008</pub-id></mixed-citation></ref><ref id="pone.0284077.ref056"><label>56</label><mixed-citation publication-type="other">Nam J, Kim S. CLAMI: Defect Prediction on Unlabeled Datasets (T). In: 30th IEEE/ACM International Conference on Automated Software Engineering (ASE); 2015. p. 452&#8211;463.</mixed-citation></ref><ref id="pone.0284077.ref057"><label>57</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Pedregosa</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Varoquaux</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Gramfort</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Michel</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Thirion</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Grisel</surname><given-names>O</given-names></name>, <etal>et al</etal>. <article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>J Mach Learn Res</source>. <year>2011</year>;<volume>12</volume>:<fpage>2825</fpage>&#8211;<lpage>2830</lpage>.</mixed-citation></ref><ref id="pone.0284077.ref058"><label>58</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Lema&#238;tre</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Nogueira</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Aridas</surname><given-names>CK</given-names></name>. <article-title>Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning</article-title>. <source>J Mach Learn Res</source>. <year>2017</year>;<volume>18</volume>(<issue>17</issue>):<fpage>1</fpage>&#8211;<lpage>5</lpage>.</mixed-citation></ref><ref id="pone.0284077.ref059"><label>59</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Chawla</surname><given-names>NV</given-names></name>, <name name-style="western"><surname>Bowyer</surname><given-names>KW</given-names></name>, <name name-style="western"><surname>Hall</surname><given-names>LO</given-names></name>, <name name-style="western"><surname>Kegelmeyer</surname><given-names>WP</given-names></name>. <article-title>SMOTE: synthetic minority over-sampling technique</article-title>. <source>J Artif Intell Res</source>. <year>2002</year>;<volume>16</volume>:<fpage>321</fpage>&#8211;<lpage>357</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1613/jair.953</pub-id></mixed-citation></ref><ref id="pone.0284077.ref060"><label>60</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Tantithamthavorn</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Hassan</surname><given-names>AE</given-names></name>, <name name-style="western"><surname>Matsumoto</surname><given-names>K</given-names></name>. <article-title>The impact of class rebalancing techniques on the performance and interpretation of defect prediction models</article-title>. <source>IEEE Trans Softw Eng</source>. <year>2018</year>;<volume>46</volume>(<issue>11</issue>):<fpage>1200</fpage>&#8211;<lpage>1219</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TSE.2018.2876537</pub-id></mixed-citation></ref><ref id="pone.0284077.ref061"><label>61</label><mixed-citation publication-type="other">Gupta A, Sharma S, Goyal S, Rashid M. Novel XGBoost tuned machine learning model for software bug prediction. In: International Conference on Intelligent Engineering and Management (ICIEM); 2020. p. 376&#8211;380.</mixed-citation></ref><ref id="pone.0284077.ref062"><label>62</label><mixed-citation publication-type="other">Surana S. Computational Complexity of Machine Learning Models&#8212;II; 2021. <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.kaggle.com/general/263127" ext-link-type="uri">https://www.kaggle.com/general/263127</ext-link>.</mixed-citation></ref><ref id="pone.0284077.ref063"><label>63</label><mixed-citation publication-type="book"><name name-style="western"><surname>Hosmer</surname><given-names>DW</given-names><suffix>Jr</suffix></name>, <name name-style="western"><surname>Lemeshow</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Sturdivant</surname><given-names>RX</given-names></name>. <source>Applied Logistic Regression</source>. <publisher-name>John Wiley &amp; Sons</publisher-name>; <year>2013</year>.</mixed-citation></ref><ref id="pone.0284077.ref064"><label>64</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Breiman</surname><given-names>L</given-names></name>. <article-title>Random forests</article-title>. <source>Mach Learn</source>. <year>2001</year>;<volume>45</volume>(<issue>1</issue>):<fpage>5</fpage>&#8211;<lpage>32</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id></mixed-citation></ref><ref id="pone.0284077.ref065"><label>65</label><mixed-citation publication-type="other">Chen T, Guestrin C. XGBoost: A scalable tree boosting system. In: 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; 2016. p. 785&#8211;794.</mixed-citation></ref><ref id="pone.0284077.ref066"><label>66</label><mixed-citation publication-type="other">Liu J, Zhou Y, Yang Y, Lu H, Xu B. Code churn: A neglected metric in effort-aware just-in-time defect prediction. In: ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM); 2017. p. 11&#8211;19.</mixed-citation></ref><ref id="pone.0284077.ref067"><label>67</label><mixed-citation publication-type="other">Powers DM. Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation. arXiv preprint arXiv:201016061. 2020;.</mixed-citation></ref><ref id="pone.0284077.ref068"><label>68</label><mixed-citation publication-type="other">Google. Imbalanced Data; 2022. <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data" ext-link-type="uri">https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data</ext-link>.</mixed-citation></ref><ref id="pone.0284077.ref069"><label>69</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Chicco</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Jurman</surname><given-names>G</given-names></name>. <article-title>The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation</article-title>. <source>BMC genomics</source>. <year>2020</year>;<volume>21</volume>(<issue>1</issue>):<fpage>1</fpage>&#8211;<lpage>13</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12864-019-6413-7</pub-id><pub-id pub-id-type="pmid">31898477</pub-id><pub-id pub-id-type="pmcid">PMC6941312</pub-id></mixed-citation></ref><ref id="pone.0284077.ref070"><label>70</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Yao</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Shepperd</surname><given-names>M</given-names></name>. <article-title>The impact of using biased performance metrics on software defect prediction research</article-title>. <source>Inf Softw Technol</source>. <year>2021</year>;<volume>139</volume>:<fpage>106664</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.infsof.2021.106664</pub-id></mixed-citation></ref><ref id="pone.0284077.ref071"><label>71</label><mixed-citation publication-type="other">Davis J, Goadrich M. The relationship between Precision-Recall and ROC curves. In: 23rd International Conference on Machine Learning (ICML); 2006. p. 233&#8211;240.</mixed-citation></ref><ref id="pone.0284077.ref072"><label>72</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Moriano</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Finke</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Ahn</surname><given-names>YY</given-names></name>. <article-title>Community-based event detection in temporal networks</article-title>. <source>Sci Rep</source>. <year>2019</year>;<volume>9</volume>(<issue>1</issue>):<fpage>1</fpage>&#8211;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-019-40137-0</pub-id><pub-id pub-id-type="pmid">30867459</pub-id><pub-id pub-id-type="pmcid">PMC6416296</pub-id></mixed-citation></ref><ref id="pone.0284077.ref073"><label>73</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Ratner</surname><given-names>B</given-names></name>. <article-title>The correlation coefficient: Its values range between+ 1/- 1, or do they?</article-title><source>J Target Meas Anal Mark</source>. <year>2009</year>;<volume>17</volume>(<issue>2</issue>):<fpage>139</fpage>&#8211;<lpage>142</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1057/jt.2009.5</pub-id></mixed-citation></ref><ref id="pone.0284077.ref074"><label>74</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Fan</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Xia</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Da Costa</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Lo</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Hassan</surname><given-names>AE</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>S</given-names></name>. <article-title>The impact of changes mislabeled by SZZ on just-in-time defect prediction</article-title>. <source>IEEE Trans Softw Eng</source>. <year>2021</year>;<volume>47</volume>(<issue>8</issue>):<fpage>1559</fpage>&#8211;<lpage>1586</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TSE.2019.2929761</pub-id></mixed-citation></ref><ref id="pone.0284077.ref075"><label>75</label><mixed-citation publication-type="other">Neo4j. Graph algorithms; 2022. <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://neo4j.com/docs/graph-data-science/current/algorithms/" ext-link-type="uri">https://neo4j.com/docs/graph-data-science/current/algorithms/</ext-link>.</mixed-citation></ref><ref id="pone.0284077.ref076"><label>76</label><mixed-citation publication-type="other">Hamilton WL, Ying R, Leskovec J. Inductive representation learning on large graphs. In: 30th Conference on Neural Information Processing Systems (NIPS). vol. 30; 2017.</mixed-citation></ref></ref-list></back><sub-article article-type="aggregated-review-documents" id="pone.0284077.r001" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0284077.r001</article-id><title-group><article-title>Decision Letter 0</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Thinnukool</surname><given-names initials="O">Orawit</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#169; 2023 Orawit Thinnukool</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Orawit Thinnukool</copyright-holder><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0284077" id="rel-obj001" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>0</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">14 Dec 2022</named-content>
</p><p>PONE-D-22-18053Graph-based machine learning improves just-in-time defect predictionPLOS ONE</p><p>Dear Dr. Moriano,</p><p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE&#8217;s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p><p>Please submit your revised manuscript by Jan 27 2023 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at&#160;<email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p><p>Please include the following items when submitting your revised manuscript:</p><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list><p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p><p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link>.</p><p>We look forward to receiving your revised manuscript.</p><p>Kind regards,</p><p>Orawit Thinnukool, Ph.D.</p><p>Academic Editor</p><p>PLOS ONE</p><p>Journal Requirements:</p><p>When submitting your revision, we need you to address these additional requirements.</p><p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at</p><p><ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and</p><p>
<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
</p><p>2. Thank you for stating in your Funding Statement:</p><p>&#8220;This research was sponsored in part by Oak Ridge National Laboratory's (ORNL's) Laboratory Directed Research and Development program. Pablo Moriano acknowledges support from ORNL's Artificial Intelligence initiative. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.&#8221;</p><p>Please provide an amended statement that declares *all* the funding or sources of support (whether external or internal to your organization) received during this study, as detailed online in our guide for authors at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://journals.plos.org/plosone/s/submit-now.&#xA0;" ext-link-type="uri">http://journals.plos.org/plosone/s/submit-now.&#160;</ext-link> Please also include the statement &#8220;There was no additional external funding received for this study.&#8221; in your updated Funding Statement.</p><p>Please include your amended Funding Statement within your cover letter. We will change the online submission form on your behalf.</p><p>3. Thank you for stating the following in the Acknowledgments Section of your manuscript:</p><p>&#8220;This research was sponsored in part by Oak Ridge National Laboratory&#8217;s (ORNL&#8217;s) 503 Laboratory Directed Research and Development program. Pablo Moriano acknowledges 504 support from ORNL&#8217;s Artificial Intelligence initiative.&#8221;</p><p>We note that you have provided additional information within the Acknowledgements Section that is not currently declared in your Funding Statement. Please note that funding information should not appear in the Acknowledgments section or other areas of your manuscript. We will only publish funding information present in the Funding Statement section of the online submission form.</p><p>Please remove any funding-related text from the manuscript and let us know how you would like to update your Funding Statement. Currently, your Funding Statement reads as follows:</p><p>&#8220;This research was sponsored in part by Oak Ridge National Laboratory's (ORNL's) Laboratory Directed Research and Development program. Pablo Moriano acknowledges support from ORNL's Artificial Intelligence initiative. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.&#8221;</p><p>Please include your amended statements within your cover letter; we will change the online submission form on your behalf.</p><p>Additional Editor Comments (if provided):</p><p>Dear Author</p><p>The manuscript Graph-based machine learning improves just-in-time defect prediction by investigating very important and practice problems. The author presented a sufficient introduction and research motivation as well as contribution. The literature review is sufficient. The proposed methods are new and innovative.</p><p>In my point of view, the idea of this paper is interesting and has some novelty. The paper is clearly presented and easy to follow assuming the reader has some background knowledge.</p><p>Although I found that your paper has merit, it is not acceptable to publish in its present form. Please revise the manuscript according to the reviewers' comments and upload the revised file within 30 days.</p><p>Please find the reviewer's comments at the end of this message;</p><p>The evaluation is also good. However, the paper can be improved in the following way.</p><p>Major:</p><p>1. Though the authors have updated the manuscript, a few comments are not still addressed. please consider the following comments and revise the paper :</p><p>1. Abstract: Read the complete abstract and try to write direct, simple, and straight sentences e.g., &#8220;The main objective &#8230;&#8230;</p><p>2.Open science? Although a link is provided to the data (provided by another research group/Ning Li) there is no code or details for instance on how the holdout samples were undertaken. This means your analysis could not be reproduced. Please provide your python code etc.</p><p>3.There does seem a slight tendency to cherry pick results to "big up" their method. This isn't helpful or necessary. It would be better to either give the range of possible results and/or typical improvement.</p><p>4. The reviwers concern about the classification performance evaluation. The authors note the problems relating to imbalanced datasets and for that reason advocate AUC-PRC (fair enough) but then extensively quote F1 performance stats which seems odd (e.g., l438).</p><p>5. Another problem with AUC style stats is they are based on entire families of classifier (many of which are uninteresting in a practical sense) so unless classifier x strictly dominates y knowing AUC_x &gt; AUC_y is not informative. There are also other concerns (see [1-2])</p><p>6. I'd consider using Matthews correlation coefficient/phi or Youden's J (which compares against a guessing strategy).</p><p>7.Lack of tuning may be misleading (l480-2). I appreciate you've not tuned any method but it seems a bit unrealistic.</p><p>8. The paper should have more case studies related to work.</p><p>9. Literature work should have a table in which each paper's method, problem, constraints, and research should be analyzed in detail in tabular form.</p><p>10.The research findings and limitations must be defined before the conclusion of the work.</p><p>11.Authors mentioned "The core of our contribution is problem 65</p><p>formulation. In particular, we leverage contribution graphs to extract graph-related 66</p><p>features that inform classification models when classifying defect-prone changes."I do not understand if the contribution is more on data classification modeling or proposing new feature vector OR new framework</p><p>Please Elaborate.</p><p>12.Expand the comparison with state of art work (at least 3-4 works) not only work [10].</p><p>Minor:</p><p>1. English should be extensively revised and corrected.</p><p>2.Abstract (and l486): "by as much as 46.72%" but this isn't the representative case. I think the authors can reframe this claim in a more reasonable way without losing the impact or value of their work. We're not in the advertising business ;-)</p><p>l398: lower -&gt; fewer (being a bit pedantic here!)</p><p>REFERENCES:</p><p>[1] Hand, D. (2009). Measuring classifier performance: a coherent alternative to the area under the ROC curve. Machine Learning, 77, 103--123. <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://doi.org/10.1007/s10994-009-5119-5" ext-link-type="uri">https://doi.org/10.1007/s10994-009-5119-5</ext-link></p><p>[2] Powers, D. (2012). The Problem of Area Under the Curve International Conference on Information Science and Technology (ICIST), Wuhan.</p><p>3.The notations should have a particular table.</p><p>4. The time complexity of each method must be defined in the paper.</p><p>5. -Reorganize the methodology section into phases with one main diagram that represent each phase as well as each step into distinct phase.</p><p>6.-Figure 1 and 2 are missing.</p><p>[Note: HTML markup is below. Please do not edit.]</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>

<bold>Comments to the Author</bold>
</p><p>1. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p><p>Reviewer #1:&#160;Partly</p><p>Reviewer #2:&#160;Yes</p><p>Reviewer #3:&#160;Partly</p><p>**********</p><p>2. Has the statistical analysis been performed appropriately and rigorously? </p><p>Reviewer #1:&#160;N/A</p><p>Reviewer #2:&#160;Yes</p><p>Reviewer #3:&#160;Yes</p><p>**********</p><p>3. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#8212;e.g. participant privacy or use of data from a third party&#8212;those must be specified.</p><p>Reviewer #1:&#160;Yes</p><p>Reviewer #2:&#160;Yes</p><p>Reviewer #3:&#160;Yes</p><p>**********</p><p>4. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p><p>Reviewer #1:&#160;Yes</p><p>Reviewer #2:&#160;Yes</p><p>Reviewer #3:&#160;Yes</p><p>**********</p><p>5. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p><p>Reviewer #1:&#160;STRENGTHS:</p><p>The idea is interesting and has some novelty.</p><p>The paper is clearly presented and easy to follow assuming the reader has some background knowledge.</p><p>WEAKNESSES:</p><p>Open science? Although a link is provided to the data (provided by another research group/Ning Li) there is no code or details for instance on how the holdout samples were undertaken. This means your analysis could not be reproduced. Please provide your python code etc.</p><p>There does seem a slight tendency to cherry pick results to "big up" their method. This isn't helpful or necessary. It would be better to either give the range of possible results and/or typical improvement.</p><p>OTHER COMMENTS:</p><p>I'm concerned about the classification performance evaluation. The authors note the problems relating to imbalanced datasets and for that reason advocate AUC-PRC (fair enough) but then extensively quote F1 performance stats which seems odd (e.g., l438).</p><p>Another problem with AUC style stats is they are based on entire families of classifier (many of which are uninteresting in a practical sense) so unless classifier x strictly dominates y knowing AUC_x &gt; AUC_y is not informative. There are also other concerns (see [1-2])</p><p>I'd consider using Matthews correlation coefficient/phi or Youden's J (which compares against a guessing strategy).</p><p>Lack of tuning may be misleading (l480-2). I appreciate you've not tuned any method but it seems a bit unrealistic.</p><p>MINOR:</p><p>Abstract (and l486): "by as much as 46.72%" but this isn't the representative case. I think the authors can reframe this claim in a more reasonable way without losing the impact or value of their work. We're not in the advertising business ;-)</p><p>l398: lower -&gt; fewer (being a bit pedantic here!)</p><p>REFERENCES:</p><p>[1] Hand, D. (2009). Measuring classifier performance: a coherent alternative to the area under the ROC curve. Machine Learning, 77, 103--123. <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://doi.org/10.1007/s10994-009-5119-5" ext-link-type="uri">https://doi.org/10.1007/s10994-009-5119-5</ext-link></p><p>[2] Powers, D. (2012). The Problem of Area Under the Curve International Conference on Information Science and Technology (ICIST), Wuhan.</p><p>Reviewer #2:&#160;The manuscript Graph-based machine learning improves just-in-time defect prediction by investigating very important and practice problems. The author presented a sufficient introduction and research motivation as well as contribution. The literature review is sufficient. The proposed methods are new and innovative. The evaluation is also good. However, the paper can be improved in the following way.</p><p>1. The paper should have more case studies related to work.</p><p>2. The notations should have a particular table.</p><p>3. The time complexity of each method must be defined in the paper.</p><p>4. Literature work should have a table in which each paper's method, problem, constraints, and research should be analyzed in detail in tabular form.</p><p>5.The research findings and limitations must be defined before the conclusion of the work.</p><p>Reviewer #3:&#160;Many drawbacks are existed into presented paper such as:</p><p>-Authors mentioned "The core of our contribution is problem 65</p><p>formulation. In particular, we leverage contribution graphs to extract graph-related 66</p><p>features that inform classification models when classifying defect-prone changes."I do not understand if the contribution is more on data classification modeling or proposing new feature vector OR new framework. Elaborate.</p><p>-Reorganize the methodology section into phases with one main diagram that represent each phase as well as each step into distinct phase.</p><p>-Figure 1 and 2 are missing.</p><p>-Expand the comparison with state of art work (at least 3-4 works) not only work [10].</p><p>**********</p><p>6. PLOS authors have the option to publish the peer review history of their article (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p><p>If you choose &#8220;no&#8221;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.</p><p>Reviewer #1:&#160;<bold>Yes:&#160;</bold>Martin Shepperd</p><p>Reviewer #2:&#160;<bold>Yes:&#160;</bold>Abdullah Lakhan</p><p>Reviewer #3:&#160;No</p><p>**********</p><p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p><p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool,&#160;<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at&#160;<email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p></body></sub-article><sub-article article-type="author-comment" id="pone.0284077.r002"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0284077.r002</article-id><title-group><article-title>Author response to Decision Letter 0</article-title></title-group><related-article xmlns:xlink="http://www.w3.org/1999/xlink" related-article-type="editor-report" id="rel-obj002" xml:lang="en" ext-link-type="doi" xlink:href="10.1371/journal.pone.0284077"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="author-response-date">16 Feb 2023</named-content>
</p><p>The handling editor of this submission is Orawit Thinnukool. Response to the reviewers was attached as a separate PDF file.</p><supplementary-material id="pone.0284077.s001" position="float" content-type="local-data" orientation="portrait"><label>Attachment</label><caption><p>Submitted filename: <named-content content-type="submitted-filename">Rebuttal-Letter-PLOS-ONE.pdf</named-content></p></caption><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0284077.s001.pdf" position="float" orientation="portrait"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></body></sub-article><sub-article article-type="editor-report" id="pone.0284077.r003" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0284077.r003</article-id><title-group><article-title>Decision Letter 1</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Thinnukool</surname><given-names initials="O">Orawit</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#169; 2023 Orawit Thinnukool</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Orawit Thinnukool</copyright-holder><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article xmlns:xlink="http://www.w3.org/1999/xlink" related-article-type="reviewed-article" id="rel-obj003" xml:lang="en" ext-link-type="doi" xlink:href="10.1371/journal.pone.0284077"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">23 Mar 2023</named-content>
</p><p>Graph-based machine learning improves just-in-time defect prediction</p><p>PONE-D-22-18053R1</p><p>Dear Dr. Moriano,</p><p>We&#8217;re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p><p>Within one week, you&#8217;ll receive an e-mail detailing the required amendments. When these have been addressed, you&#8217;ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p><p>An invoice for payment will follow shortly after the formal acceptance. To ensure an efficient process, please log into Editorial Manager at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.editorialmanager.com/pone/" ext-link-type="uri">http://www.editorialmanager.com/pone/</ext-link>, click the 'Update My Information' link at the top of the page, and double check that your user information is up-to-date. If you have any billing related questions, please contact our Author Billing department directly at <email>authorbilling@plos.org</email>.</p><p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they&#8217;ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email>onepress@plos.org</email>.</p><p>Kind regards,</p><p>Orawit Thinnukool, Ph.D.</p><p>Academic Editor</p><p>PLOS ONE</p><p>Additional Editor Comments (optional):</p><p>I am confident that the paper is now ready for publication.</p><p>Reviewers' comments:</p></body></sub-article><sub-article article-type="editor-report" id="pone.0284077.r004" specific-use="acceptance-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0284077.r004</article-id><title-group><article-title>Acceptance letter</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Thinnukool</surname><given-names initials="O">Orawit</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#169; 2023 Orawit Thinnukool</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Orawit Thinnukool</copyright-holder><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0284077" id="rel-obj004" related-article-type="reviewed-article"/></front-stub><body><p>
<named-content content-type="letter-date">3 Apr 2023</named-content>
</p><p>PONE-D-22-18053R1 </p><p>Graph-based machine learning improves just-in-time defect prediction </p><p>Dear Dr. Moriano:</p><p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department. </p><p>If your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact <email>onepress@plos.org</email>.</p><p>If we can help with anything else, please email us at <email>plosone@plos.org</email>. </p><p>Thank you for submitting your work to PLOS ONE and supporting open access. </p><p>Kind regards, </p><p>PLOS ONE Editorial Office Staff</p><p>on behalf of</p><p>Assistant Professor Orawit Thinnukool </p><p>Academic Editor</p><p>PLOS ONE</p></body></sub-article></article></pmc-articleset>