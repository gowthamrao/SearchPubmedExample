<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS One</journal-id><journal-id journal-id-type="pmc-domain-id">440</journal-id><journal-id journal-id-type="pmc-domain">plosone</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-title-group><journal-title>PLOS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>PLOS</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC10019629</article-id><article-id pub-id-type="pmcid-ver">PMC10019629.1</article-id><article-id pub-id-type="pmcaid">10019629</article-id><article-id pub-id-type="pmcaiid">10019629</article-id><article-id pub-id-type="pmid">36928721</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0282882</article-id><article-id pub-id-type="publisher-id">PONE-D-20-39301</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Semantics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Language</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Language</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Language</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Grammar</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Grammar</subject><subj-group><subject>Syntax</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject><subj-group><subject>Deep Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Parsers</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Parsers</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Semantics</subject><subj-group><subject>Lexical Semantics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Information Technology</subject><subj-group><subject>Natural Language Processing</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Design considerations for a hierarchical semantic compositional framework for medical natural language understanding</article-title><alt-title alt-title-type="running-head">A hierarchical semantic compositional framework for medical natural language understanding</alt-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9754-8993</contrib-id><name name-style="western"><surname>Taira</surname><given-names initials="RK">Ricky K.</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1665-678X</contrib-id><name name-style="western"><surname>Garlid</surname><given-names initials="AO">Anders O.</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Speier</surname><given-names initials="W">William</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref></contrib></contrib-group><aff id="aff001"><label>1</label>
<addr-line>Medical and Imaging Informatics (MII) Group, Department of Radiological Sciences, University of California, Los Angeles, Los Angeles, California, United States of America</addr-line></aff><aff id="aff002"><label>2</label>
<addr-line>Department of Bioengineering, University of California, Los Angeles, Los Angeles, California, United States of America</addr-line></aff><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Safro</surname><given-names initials="I">Ilya</given-names></name><role>Editor</role><xref rid="edit1" ref-type="aff"/></contrib></contrib-group><aff id="edit1">
<addr-line>University of Delaware, UNITED STATES</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>rtaira@ucla.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>16</day><month>3</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>18</volume><issue>3</issue><issue-id pub-id-type="pmc-issue-id">430135</issue-id><elocation-id>e0282882</elocation-id><history><date date-type="received"><day>16</day><month>12</month><year>2020</year></date><date date-type="accepted"><day>24</day><month>2</month><year>2023</year></date></history><pub-history><event event-type="pmc-release"><date><day>16</day><month>03</month><year>2023</year></date></event><event event-type="pmc-live"><date><day>17</day><month>03</month><year>2023</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2023-03-18 04:10:13.400"><day>18</day><month>03</month><year>2023</year></date></event></pub-history><permissions><copyright-statement>&#169; 2023 Taira et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Taira et al</copyright-holder><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="pone.0282882.pdf"/><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pdf" xlink:href="pone.0282882.pdf"/><related-article xmlns:xlink="http://www.w3.org/1999/xlink" related-article-type="editor-report" xml:lang="en" ext-link-type="doi" xlink:href="10.1371/journal.pone.0282882"><pub-id pub-id-type="doi">10.1371/journal.pone.0282882</pub-id></related-article><related-article xmlns:xlink="http://www.w3.org/1999/xlink" related-article-type="reviewed-article" xml:lang="en" ext-link-type="doi" xlink:href="10.1371/journal.pone.0282882"><pub-id pub-id-type="doi">10.1371/journal.pone.0282882</pub-id></related-article><abstract><p>Medical natural language processing (NLP) systems are a key enabling technology for transforming Big Data from clinical report repositories to information used to support disease models and validate intervention methods. However, current medical NLP systems fall considerably short when faced with the task of logically interpreting clinical text. In this paper, we describe a framework inspired by mechanisms of human cognition in an attempt to jump the NLP performance curve. The design centers on a hierarchical semantic compositional model (HSCM), which provides an internal substrate for guiding the interpretation process. The paper describes insights from four key cognitive aspects: semantic memory, semantic composition, semantic activation, and hierarchical predictive coding. We discuss the design of a generative semantic model and an associated semantic parser used to transform a free-text sentence into a logical representation of its meaning. The paper discusses supportive and antagonistic arguments for the key features of the architecture as a long-term foundational framework.</p></abstract><funding-group><award-group id="award001"><funding-source><institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000054</institution-id><institution>National Cancer Institute</institution></institution-wrap></funding-source><award-id>R01 CA226079</award-id></award-group><award-group id="award002"><funding-source><institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000092</institution-id><institution>U.S. National Library of Medicine</institution></institution-wrap></funding-source><award-id>R01 LM012309</award-id></award-group><award-group id="award003"><funding-source><institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000054</institution-id><institution>National Cancer Institute</institution></institution-wrap></funding-source><award-id>R01 CA157533</award-id></award-group><award-group id="award004"><funding-source><institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000092</institution-id><institution>U.S. National Library of Medicine</institution></institution-wrap></funding-source><award-id>R01 LM011333</award-id></award-group><award-group id="award005"><funding-source><institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000060</institution-id><institution>National Institute of Allergy and Infectious Diseases</institution></institution-wrap></funding-source><award-id>U24 AI117966</award-id></award-group><funding-statement>This work was supported by funds from the National Institutes of Health grants R01-CA226079, R01-LM012309, R01-CA157533, R01-LM011333, and U24-AI117966. There was no additional external funding received for this study.</funding-statement></funding-group><counts><fig-count count="5"/><table-count count="2"/><page-count count="37"/></counts><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>This paper is a concept paper. There is no data associated with this paper.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>This paper is a concept paper. There is no data associated with this paper.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>Natural language processing (NLP) of clinical reports is an important area of research in medical informatics. It is considered a key enabling technology for transforming unstructured Big Data from clinical repositories into a computer-understandable representation that would allow for compiling phenotypic observations and treatments from a large number of patients [<xref rid="pone.0282882.ref001" ref-type="bibr">1</xref>, <xref rid="pone.0282882.ref002" ref-type="bibr">2</xref>]. These curated structured databases can then potentially be used to build individually tailored predictive disease models and/or assist in identifying new patient stratification principles for targeted therapies [<xref rid="pone.0282882.ref003" ref-type="bibr">3</xref>&#8211;<xref rid="pone.0282882.ref005" ref-type="bibr">5</xref>]. A comprehensive review of the tasks and applications that involve NLP in the medical field are given in [<xref rid="pone.0282882.ref006" ref-type="bibr">6</xref>, <xref rid="pone.0282882.ref007" ref-type="bibr">7</xref>].</p><p>Bibliographic reviews in the field of medical informatics have reported NLP-related research to rank among the most cited topics [<xref rid="pone.0282882.ref008" ref-type="bibr">8</xref>] with an increasing number of publications since at least 2007 [<xref rid="pone.0282882.ref009" ref-type="bibr">9</xref>]. Publicly available de-identified clinical data sets are now increasingly available for researchers. Community-wide standards for tagging and representation of NLP semantic constituents (e.g., concepts and relations) are being actively defined [<xref rid="pone.0282882.ref010" ref-type="bibr">10</xref>&#8211;<xref rid="pone.0282882.ref015" ref-type="bibr">15</xref>]. Cooperative publicly available toolkits and development environments are actively being contributed to and supported (<italic toggle="yes">e</italic>.<italic toggle="yes">g</italic>., Open Health NLP Consortium [<xref rid="pone.0282882.ref016" ref-type="bibr">16</xref>]). New application areas continue to arise. Yet, despite these efforts and the long history of medical NLP as a focused area of research, the ability to perform deep understanding of clinical notes by computers remains elusive and generally far from the abilities of human cognition. The driving need for a deep understanding of medical text was emphasized as early as 2012 at a two-day workshop at the National Library of Medicine. At this meeting, prominent researchers in both general and biomedical NLP were invited to discuss directions and strategies that would lead to more efficient development of NLP solutions for diverse medical research applications [<xref rid="pone.0282882.ref017" ref-type="bibr">17</xref>]. These experts agreed that there is a need for a new paradigm involving the integration of statistics, linguistic knowledge, and domain knowledge. The late Dr. Donald Lindberg, then Director of the National Library of Medicine, emphasized the need for natural language understanding (NLU) over NLP. (For a description of the major issues related to the medical NLU problem, see the <xref rid="sec024" ref-type="sec">Discussion</xref> Section under the subheading &#8220;Comparing the Problem Circumstances of General versus Medical NLU&#8221;).</p><p>The challenge of bringing a medical text understanding system closer to human capabilities is considerable. A key strategic design decision is specifying an overall system architecture to provide the framework for how various NLP tasks and knowledge sources interact. Reviews of architectural designs for medical NLP developments can be found in [<xref rid="pone.0282882.ref006" ref-type="bibr">6</xref>, <xref rid="pone.0282882.ref018" ref-type="bibr">18</xref>, <xref rid="pone.0282882.ref019" ref-type="bibr">19</xref>]. Currently, there are no agreed integrated models for deep understanding of clinical text.</p><p><xref rid="pone.0282882.g001" ref-type="fig">Fig 1</xref> shows an overview of the basic NLU mapping problem that transforms an input sequence of characters representing a sentence to a computer-understandable logical interpretation. Defining an ontological representation at this level depends upon the driving application, and in particular, the set of questions the NLU system should be able to answer. In other words, the fidelity of the &#8220;True Intended Meaning&#8221; can be formulated in terms of how well the NLU system can answer the set of application-driven queries in the paradigm of a Turing Test. A stricter account would also charge the system to explain how it derived its answers. For examples of various language level ambiguities within clinical text, see the <xref rid="sec024" ref-type="sec">Discussion</xref> Section under the subsection &#8220;Comparing the Problem Circumstances of General versus Medical NLU&#8221;.</p><fig position="float" id="pone.0282882.g001" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0282882.g001</object-id><label>Fig 1</label><caption><title>Overall basic mapping problem.</title><p>The NLU problem maps the characters of a sentence to a conceptual representation of meaning. Defining the &#8220;internal semantic layers&#8221; is a key representational challenge.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0282882.g001.jpg"/></fig><p>In order to address the large joint state space associated with this mapping, a number of internal layers are defined. Specifically, our approach involves factoring the NLU problem using a hierarchical semantic compositional model (HSCM). This structure enables a more efficient process of encoding sentence meaning by facilitating a generative model. The overall goal then is to navigate a sentence interpretation through the internal layers and states of the hierarchy using a predictive coding approach. Our design involves explicitly defining this structure in a way that parallels the manner in which humans compose meaning. This process contrasts with deep learning methods, which attempt to define these layers automatically based on training data and an objective function related to the specific query being addressed.</p><p>In this paper, we describe the conceptual design of a processing framework that can potentially serve as a foundational architecture for medical NLU applications. The architecture is designed to provide an overarching global semantic structure to organize a diversity of symbol-to-symbol mapping schemes in order to synthesize meaning from clinical text. These schemes can include a diversity of approaches, including rule-based, symbolic pattern matching, statistical inferencing methods, and deep learning approaches. The design decisions presented are in response to the known weakness inherent in data-driven approaches [<xref rid="pone.0282882.ref020" ref-type="bibr">20</xref>&#8211;<xref rid="pone.0282882.ref022" ref-type="bibr">22</xref>]. The main contribution of this paper is to present arguments for moving toward a symbolic-based NLU framework that is inspired by cognitive principles. We hope these arguments will stimulate much-needed open discussions toward the strategic developmental direction for building effective, sustainable clinical NLU solutions.</p></sec><sec sec-type="intro" id="sec002"><title>Background</title><p>Although the exact nature of how humans can comprehend language so well and fast is still uncertain, there are four main inter-related ideas that are likely critical to our ability to comprehend language. (See, for example, [<xref rid="pone.0282882.ref023" ref-type="bibr">23</xref>, <xref rid="pone.0282882.ref024" ref-type="bibr">24</xref>]). The four ideas are: 1) predefined abstract semantic representations; 2) semantic composition; 3) semantic activation; and 4) hierarchical predictive coding. A brief background describing how these ideas relate to natural language understanding is presented below.</p><sec id="sec003"><title>Predefined semantic representations</title><p>Humans possess what is known as semantic memory, which stores knowledge about declarative facts, ideas, meanings, concepts, and knowledge of the world we have acquired. Semantic memory is an integral part of human intelligence. Evidence for its physical existence is being investigated using fMRI activation studies, which show a continuous semantic space describing thousands of objects and action categories along the brain&#8217;s cortical surface [<xref rid="pone.0282882.ref025" ref-type="bibr">25</xref>]. There is significant evidence that all animal brains have the ability to generalize and create categories and concepts and encode them in neurons, where each group of such cells is dedicated to a single category or concept [<xref rid="pone.0282882.ref026" ref-type="bibr">26</xref>]. Semantic memory can be viewed as precompiled informational structures primed for understanding language. When humans are presented with unfamiliar words or concepts, we adapt to our environment by evolving this representation (e.g., memory formation). Conversely, concepts no longer fitting for our &#8220;survival&#8221; may also cause semantic categories to be removed (memory loss). A radiologist, for example, might have a comprehensive abstract informational template for what is a tumoral mass compared to a non-medically trained person. These templates allow language signals to be encoded efficiently into semantic memory, which in turn is primed for efficient interpretation. One important point related to semantic memory is that it is relatively comprehensive. It encompasses a representation for conceivably every discussion item and characterizes the capacity for which a person can understand language. Additionally, the stored summary representation used by the brain allows for the production and comprehension of sentences beyond those that have been experienced [<xref rid="pone.0282882.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0282882.ref028" ref-type="bibr">28</xref>]. With respect to medical NLU, capturing the meaning of a sentence requires the development of a sufficiently rich representation model suitable for its targeted situational use. Circumscribing the scope of sanctioned interpretations is part of the application domain modeling problem and, in general, there is a need to create application-specific (i.e., situational or &#8220;realism-based&#8221;) ontologies and semantic models [<xref rid="pone.0282882.ref029" ref-type="bibr">29</xref>, <xref rid="pone.0282882.ref030" ref-type="bibr">30</xref>].</p></sec><sec id="sec004"><title>Semantic composition</title><p>Utilizing a compositional approach to meaning representation is an idea deeply rooted in language theory [<xref rid="pone.0282882.ref031" ref-type="bibr">31</xref>]. Composition allows a system to have a large descriptive capacity utilizing combinations of more elementary units. The rationale for the approach can be summarized as follows. Firstly, a direct mapping from text to sentence-level logical interpretation is unreasonable given the variability of free text and the large state space associated with the universe of all possible logical interpretations. To deal with these difficulties, it is typical to introduce layers of intermediate structure representing sub-interpretations [<xref rid="pone.0282882.ref032" ref-type="bibr">32</xref>, <xref rid="pone.0282882.ref033" ref-type="bibr">33</xref>]. This composition significantly reduces the dimensionality of the mapping problem through independence assumptions. Secondly, humans understand text at several conceptual levels [<xref rid="pone.0282882.ref034" ref-type="bibr">34</xref>]. For example, humans can derive meaning from text at the morphological level (e.g., word endings), lexical level, within the context of a syntactic phrase, or within predicate argument constructions. Thirdly, cognitive science research generally views language as a generative process [<xref rid="pone.0282882.ref035" ref-type="bibr">35</xref>&#8211;<xref rid="pone.0282882.ref037" ref-type="bibr">37</xref>]. This implies that the language can produce an infinite number of sentences from its basic constructions as well as understand sentences it has never seen. From a cognitive point of view, an effective composition of a sentence implies that all the information that a human would expect to decipher from the sentence should be extractable from the compositional representation [<xref rid="pone.0282882.ref038" ref-type="bibr">38</xref>]. This structure implies that any questions that could be answered from the meaning of the sentence should be answerable from the representation alone (see <xref rid="pone.0282882.g001" ref-type="fig">Fig 1</xref>). That is, we do not lose any information stated within the sentence by factoring it into components that are themselves meaningful at various levels of semantic abstraction.</p></sec><sec id="sec005"><title>Semantic activation networks</title><p>One powerful feature of the brain is the connectivity of its memory units. This connectivity allows the brain to support the notion of priming, in which memory units within the brain&#8217;s semantic network are activated in such a way as to prepare the cognition system for encoding to-be-interpreted language signals [<xref rid="pone.0282882.ref039" ref-type="bibr">39</xref>]. That is, humans rely on a significant amount of knowledge in which words activate a cascade of semantically related concepts, relevant scenarios of their use, and models of reality [<xref rid="pone.0282882.ref040" ref-type="bibr">40</xref>, <xref rid="pone.0282882.ref041" ref-type="bibr">41</xref>]. For example, mentioning a &#8220;tumor&#8221; within a medical report could prime an oncologist&#8217;s brain to expect various clinical characteristics and referents of this topic concept. The mention of the phrase &#8220;located in&#8221; primes the cognitive system to expect a description of a spatial location. Connections among semantic memory units allow recalling related concepts to an activated concept, resulting in a functional integration of brain areas and the spreading of activated semantic units. Depending upon the types of entailment relationships coded within the network, the spreading of the activation can differ. This spreading activation builds a dynamic semantic field that primes the brain for maximizing comprehension and introduces relevant context to elevate interpretation in response to and in anticipation of the given input [<xref rid="pone.0282882.ref042" ref-type="bibr">42</xref>]. The connectivity of semantic units is based largely on experience and knowledge. Knowledge aspects may involve a hierarchical typing system that humans commonly use to categorize objects, while experience aspects may be used to efficiently navigate to associated concepts based on past personal encounters [<xref rid="pone.0282882.ref040" ref-type="bibr">40</xref>]. Of note, the configuration of the network is highly fluid. Mounting evidence suggests that such network reconfiguration is necessary to help keep the overall cognitive system in healthy balance [<xref rid="pone.0282882.ref043" ref-type="bibr">43</xref>].</p></sec><sec id="sec006"><title>Hierarchical predictive coding</title><p>Hierarchical predictive coding seems to be a fundamental mechanism for human cognition, involved in both vision [<xref rid="pone.0282882.ref044" ref-type="bibr">44</xref>] and language processing [<xref rid="pone.0282882.ref045" ref-type="bibr">45</xref>]. The brain uses it to solve seemingly intractable problems (e.g., scene analysis and language understanding) involving sensory inputs (e.g., visual or auditory signals) in a highly efficient manner. The central idea is that the brain is an organ of prediction guided by a hierarchical generative model of how it understands the world. Interpretation is seen as a process of minimizing free energy. Free energy is small when internal neural representations can accurately predict lower level inputs. Instead of minimizing the entropy of the interpretations, the strategy is to minimize the entropy of the observations (Free Energy Principle). Operationally, predictive coding refers to a processing paradigm that utilizes an adaptive strategy for hierarchically interpreting input sensory signals using a hybrid top-down and bottom-up processing approach. The top-down strategy uses lower level cues to posit upper level hypotheses (<italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., causes) that are then tested based on evidence from lower level inputs (<italic toggle="yes">i</italic>.<italic toggle="yes">e</italic>., observations). As part of the conceptual knowledge base of the brain, a predictive algorithm assesses the virtual situation that given an upper level hypothesis prior, what is its likelihood based on the state of the lower level inputs. Top-down processing will explain away (by predicting) only those elements of the driving signal that conform to (and hence are predicted by) the current winning hypothesis. The higher-level guesses are thus acting as priors for the lower-level processing in the fashion of so-called &#8220;empirical Bayes&#8221; [<xref rid="pone.0282882.ref046" ref-type="bibr">46</xref>] (such methods use their own internal target data sets to estimate the prior distribution: a kind of bootstrapping that exploits the statistical independencies that characterize hierarchical models). When a prediction is accepted, the system updates the higher-level priors to posteriors. The bottom-up processing relates to carrying lower level evidence that cannot be accounted for by the top-down predictions to higher levels as residual prediction errors. Thus, the better the top-down matches, the less we see prediction errors propagating up the hierarchy. Upper levels of processing provide greater context to interpret these residual errors (i.e., unaccounted tokens) due to the hypotheses that have been previously crystallized. Thus, in predictive coding, navigating the interpretation hierarchy relies on transitioning through the system&#8217;s internal states by utilizing a cascade of top-down predictions to move up the hierarchy. The interesting aspect of the paradigm is the utilization of both successful predictions (as defined by some tolerable error rate) and unsuccessful predictions related to the input. This is an application of the idea of &#8220;analysis-by-synthesis&#8221; [<xref rid="pone.0282882.ref047" ref-type="bibr">47</xref>&#8211;<xref rid="pone.0282882.ref050" ref-type="bibr">50</xref>]. The processing paradigm also supports the notion that language comprehension is a form of abductive reasoning [<xref rid="pone.0282882.ref051" ref-type="bibr">51</xref>] in which the process of interpreting sentences in discourse can be viewed as the process of providing the best explanation of why the sentence would be true. In this processing model of the brain, hierarchical predictive coding [<xref rid="pone.0282882.ref052" ref-type="bibr">52</xref>] can be seen as a form of Bayesian filtering (least surprising interpretation) [<xref rid="pone.0282882.ref044" ref-type="bibr">44</xref>, <xref rid="pone.0282882.ref053" ref-type="bibr">53</xref>&#8211;<xref rid="pone.0282882.ref055" ref-type="bibr">55</xref>].</p></sec></sec><sec sec-type="materials|methods" id="sec007"><title>Methods</title><p>In this section, we first introduce the overall NLU problem highlighting the need for a predefined compositional structure. We then describe the elements and features of our central HSCM knowledge base. The model design contains elements that emulate the cognitive features of semantic memory, semantic activation, and semantic composition. The design of the semantic parser, which executes on an input sentence to derive an ontologic representation of the meaning of the sentence, is then described. Finally, we highlight important principles employed by the architecture, which provide the basis for what we believe to be a solid foundation for future growth. Note that, for brevity, we focus only on foundational architectural issues (i.e., what should be done) and leave specific implementations (i.e., how it should be done) with respect to grammars, classifiers, and specific knowledge sources, as open options within the framework.</p><sec id="sec008"><title>Problem definition and overview</title><sec id="sec009"><title>Hierarchical semantic compositional model</title><p>The HSCM knowledge source defines the &#8220;hidden layers&#8221; of the NLU mapping problem. <xref rid="pone.0282882.g002" ref-type="fig">Fig 2</xref> shows an overview of the elements associated with the model. These elements can be described in terms of semantic constituents, semantic composition grammars, semantic networks, and a query processor. The HSCM addresses the need for an NLU system to possess a comprehensive internal representation for the universe of sentences it intends to understand (e.g., sentences that describe a tumor in a radiology report), which is the semantic substrate needed to encode meaning (see <xref rid="pone.0282882.g002" ref-type="fig">Fig 2</xref>, Box 1). The semantic constituents correspond to semantic memory elements within the cognitive paradigm. Defining the constituents within the model is an open research question and must be approached with caution since navigating and maintaining the knowledge source becomes increasingly difficult as the number of nodes in the hierarchy increases. It is thus imperative to apply various organizing principles including methods for building medical ontologies [<xref rid="pone.0282882.ref056" ref-type="bibr">56</xref>], methods for analyzing complex systems [<xref rid="pone.0282882.ref057" ref-type="bibr">57</xref>, <xref rid="pone.0282882.ref058" ref-type="bibr">58</xref>], and methods involving problem decomposition [<xref rid="pone.0282882.ref059" ref-type="bibr">59</xref>] (e.g., abstraction, encapsulation, modularity, and inheritance). Referring to prior efforts in building semantic grammars and semantic frames for both medical and general NLP can also be productive [<xref rid="pone.0282882.ref060" ref-type="bibr">60</xref>, <xref rid="pone.0282882.ref061" ref-type="bibr">61</xref>]. See, for example, work by the Linguistic Data Consortium and the Abstract Meaning Representation [<xref rid="pone.0282882.ref062" ref-type="bibr">62</xref>].</p><fig position="float" id="pone.0282882.g002" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0282882.g002</object-id><label>Fig 2</label><caption><title>Tasks associated with the construction of the hierarchical compositional semantic model.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0282882.g002.jpg"/></fig><p>In practice, defining the semantic compositional model for a class of target sentences is not straightforward and can evolve to a variety of configurations. Accurately capturing the level of specificity required by the anticipated driving queries is an exercise in carefully decomposing each level of semantic detail. Topic-centric (e.g., tumoral mass) corpus-based (thoracic radiology reports) methods can be applied in general [<xref rid="pone.0282882.ref063" ref-type="bibr">63</xref>&#8211;<xref rid="pone.0282882.ref065" ref-type="bibr">65</xref>]. Alternatively, one could approach the problem from a syntactic point of view and proceed to learn, for example, the most common verbs and their related semantic constructions [<xref rid="pone.0282882.ref066" ref-type="bibr">66</xref>, <xref rid="pone.0282882.ref067" ref-type="bibr">67</xref>]. As previously mentioned, the semantic nodes provide a template to encode language meaning at various levels of complexity. Although there have been efforts in the literature to define the semantic primitives and higher-order constituents for medical NLP, the specification of the constituent nodes is often by necessity a personal and situational effort. (Like the brain, we constantly update our internal expectation models of stimulus from our environment). Both bottom-up (&#8220;compositionality principle&#8221; [<xref rid="pone.0282882.ref068" ref-type="bibr">68</xref>]) and top-down (&#8220;context principle&#8221; [<xref rid="pone.0282882.ref069" ref-type="bibr">69</xref>]) methods for modeling semantic nodes are useful in designing appropriate levels of abstraction and organization. <xref rid="pone.0282882.g003" ref-type="fig">Fig 3</xref> shows a rough schematic of this semantic generative representation. For diagrammatic purposes, we characterize various semantics constituents within domains according to specificity and/or semantic richness. A brief description of these broad node types is given below.</p><fig position="float" id="pone.0282882.g003" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0282882.g003</object-id><label>Fig 3</label><caption><title>Layers and example node instances for the HSCM.</title><p>An example sentence illustrates how the input tokens can be interpreted by instantiating network paths through the model. Each plane contains the domain of semantic constituents for the given abstraction level. For visual simplicity, arrows should be assumed to point downward to indicate compositionality.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0282882.g003.jpg"/></fig></sec><sec id="sec010"><title>Semantic constituents</title><p><italic toggle="yes">Semantic layer 0&#8212;Surface words</italic>. The hierarchical layering starts with a character stream for a given sentence. The first layer performs an initial surface level (i.e., the verbatim string) grouping of characters into words. A factory of tokenization schemes can be used to parse the character stream into a sequence of surface word tokens. Rule bases can be used to address dashes, slashes, apostrophes, and parentheticals [<xref rid="pone.0282882.ref070" ref-type="bibr">70</xref>].</p><p><italic toggle="yes">Semantic layer 1&#8212;Functional words</italic>. Functional words can be defined as the primitive semantic constituents of a language. The functional definition of a word reflects how the system will strategize making semantic sense for a given segment of text. Different strategies for word-level tokenization will lead an NLP system to process a given input text in different ways. Mapping surface words to functional words involves a number of subproblems including: a) spelling corrections; b) identification of idiomatic expressions (e.g., throw up); d) identification of collocations (e.g., vena cava, computed tomography, and medical center); e) identification and/or parsing of symbol expressions; f) expansion and interpretation of abbreviations and acronyms; and e) decomposition of compound words. Commons knowledge sources used to address these subproblems include: idiomatic dictionaries, lexicons of common medical term collocations [<xref rid="pone.0282882.ref071" ref-type="bibr">71</xref>], and co-occurrence phrase chunking models utilizing simple <italic toggle="yes">t</italic>-tests [<xref rid="pone.0282882.ref072" ref-type="bibr">72</xref>].</p><p><italic toggle="yes">Semantic layer 2&#8212;Ontological primitives</italic>. Ontologic primitives represent the lowest level internal HSCM constituents and are abstract units of meaning that are sanctioned by the interpretation system. Example concepts include nodes for numbers, property names, property values, certainty, medical procedure names, anatomy descriptions and medical conditions. Defining the granularity of these primitive constituents can be a challenging task often dictated by the particular application under consideration. For example, with size measurements, an application may simply want to parse the phrase &#8220;5cm x 4cm x 3cm&#8221; versus an alternative application which may require the internal semantics to be specified (i.e., the individual dimensions, units, and values). These choices in representation will influence strategies used for parsing (e.g., finite state machines or hidden Markov models). Some functional words, like &#8220;extends&#8221; and adverbs, are only identified within the HSCM in the context of higher order constituents such as other propositional constructions or predicate-argument structures due to their varying contextual roles across these targets. Thus, not all functional words will map directly to ontologic primitives.</p><p><italic toggle="yes">Semantic layer 3&#8212;Ontological propositions</italic>. Moving up the semantic compositional hierarchy, lower level constituents continue to compose higher-level constructions. Propositions can be thought of as basic units of information (Finding Y is interpreted as Disease X). This level of semantic nodes include descriptions of properties and their values (<italic toggle="yes">e</italic>.<italic toggle="yes">g</italic>., &#8220;size of 2.2cm x 3.0cm&#8221;), locative prepositions (<italic toggle="yes">e</italic>.<italic toggle="yes">g</italic>., &#8220;within the right lower lobe of the lung&#8221;), temporal relations (<italic toggle="yes">e</italic>.<italic toggle="yes">g</italic>., &#8220;within the last two weeks&#8221;), and various degrees of completion of predicate-argument structures (<italic toggle="yes">e</italic>.<italic toggle="yes">g</italic>., &#8220;extends from the third to the fifth intercostal space&#8221;). Note that we can define complex propositions that provide more detailed descriptions by allowing the arguments of a proposition to be HSCM nodes at any level of abstraction. These arguments of propositions can include such node types such as ontologic primitives, other ontologic propositions, or higher-level object/event frames. For example, a spatial relation proposition could be formed using an anatomy frame for its location argument. A proposition describing an entity&#8217;s size (e.g., &#8220;mass is 5cm in cranio-caudal dimension&#8221;) could be constructed using a quantification relation frame and a size measurement frame.</p><p><italic toggle="yes">Semantic layer 4&#8212;Object / event frames</italic>. These high-level nodes define comprehensive representational templates for targeted entities and events. Again, the definition of these node descriptions (i.e., their attributes) should be determined by formal ontology design and frame-based semantics methods. The richness of these nodes can be seen, for example, in defining a semantic entity frame for a tumoral mass. The specification of a mass includes a timeline of its states. A state is characterized by a collection of observations at a particular point in time. The observation description, in turn, is composed of a reference to a procedure and the various measurements associated with a property (e.g., size may be associated with three linear measurements). A procedure description is composed of a description of date, facilities, devices, and methodological protocols.</p><p><italic toggle="yes">Semantic layer 5&#8212;Discourse and domain-specific templates</italic>. Conceptually, one could include even richer templates (e.g., application domains) at the sentence level and beyond, which comprehensively capture a more extensive range of semantic abstractions and text spans. Examples of such constructions include timelines, procedure-specific structured reports such as BiRADS, topic or procedure specific discourse templates, and phenomenon-centric disease models [<xref rid="pone.0282882.ref073" ref-type="bibr">73</xref>]). Discourse templates provide an expectation model between a speaker (e.g., specialist) and listener (e.g., referring physician). An example of a discourse model topic would be the expected communicative goals of a radiologist describing a patient&#8217;s smoking habits in the context of determining whether a patient is eligible for lung cancer screening. In particular, this discourse model can be used to disambiguate instances of ellipsis commonly observed in this domain (e.g., incomplete specification of units of pack-years, which can be implicated from the discourse model). These high-level semantic templates are useful because they can be linked to application-specific queries. For example, an instance of a radiology mass template could be used by a lung cancer screening application to help determine whether a patient might be eligible for a particular screening protocol.</p></sec><sec id="sec011"><title>Semantic linkages</title><p><italic toggle="yes">Downward links for compositionality</italic>. As part of the HSCM, a number of semantic links are defined. Downward links define the constituents that can synthesize an upper level node (see <xref rid="pone.0282882.g002" ref-type="fig">Fig 2</xref>, Box 2). Each upper level composite node has its own methods for its grammatical construction. In practice, a variety of methods can perform these mappings. For example, the mappings may be implemented using dictionaries, lexico-semantic-syntactic patterns, finite state machines, context free grammars, or hidden sequence methods (e.g., Bayesian and deep learning methods). These mappings define the constituents, their sequencing, and the context for a valid construction. The methods of choice depend on the state space associated with their mapping, which in turn depends on the richness of the compositional model. As a note, although we use the term &#8220;downward link&#8221; to emphasize compositionality, in practice, the rules for construction are quite flexible so that the composition of higher order constituents (e.g., propositions, frames, and discourse templates) can be constructed using a variety of elements. For example, the arguments for a proposition can be filled with another ontologic proposition or even an ontologic frame. See the example described in the Parser Design section of this paper for further details and specific examples of these possibilities.</p><p><italic toggle="yes">Semantic activation network</italic>. In addition to downward compositional links, we define links from lower level semantic types to higher-level semantic constituents (see <xref rid="pone.0282882.g002" ref-type="fig">Fig 2</xref>, Box 3). These upward links activate a process that identifies plausible hypotheses for constituents higher up in the HSCM given a set of tokens for a given sentence. For example, the word &#8220;extending&#8221; would trigger a hypothesis for instantiating the higher-level propositional template corresponding to the &#8220;extends&#8221; predicate argument structure. This link would then prime the system to activate the associated grammar to search for identifying modifiers and arguments associated with the semantic model for the &#8220;extends&#8221; proposition. Activation of hypotheses also occurs by exploring the ontologic attributes of entities that have been identified. For example, identifying the concept &#8220;tumoral mass&#8221; would automatically activate the grammars for all the attribute concepts associated with the ontologic definition of a tumoral mass (e.g., size, shape, radiographic density, and border architecture). These upward links can thus be seen as a means for allowing the parser to search for paths within the internal semantic hierarchical model to identify plausible interpretations of the input sentence. While downward compositional links are designed for high precision, the upward links that activate higher-level semantic hypotheses are designed to emphasize high recall. In contrast to upward activation links, suppression links can be activated by true negative language patterns to rule out a hypothesis. For example, the word &#8216;mass&#8217; in the context of the phrase &#8216;bone mass density&#8221; could use the lexical pattern &#8220;bone mass density&#8221; as a suppression pattern for the hypothesis of a (tumoral) mass concept.</p><p>The semantic activation network can also be extended using generalization-specialization links between HSCM nodes (see <xref rid="pone.0282882.g002" ref-type="fig">Fig 2</xref>, Box 4). For example, the general &#8216;anatomy class&#8217; concept could include the subclass nodes &#8220;heart anatomy&#8221;, &#8220;lung anatomy&#8221;, and &#8220;liver anatomy&#8221;. These concept relationships allow the HSCM to include such class level meta-nodes (i.e., anatomy class) that encapsulate the grammar model for the superclass. Thus, any subclass member (e.g., lung) can activate the hypothesis of the existence of an instance of the superclass. In processing a sentence, this implies that a subclass member (e.g., &#8220;lung&#8221;) can activate the grammar attached to its superclass (e.g., anatomy concept).</p></sec><sec id="sec012"><title>HSCM query processing</title><p>Associated with the HSCM knowledge base is a query processing manager (see <xref rid="pone.0282882.g002" ref-type="fig">Fig 2</xref>, Box 6). It supports the following basic queries:</p><list list-type="order"><list-item><p>Retrieve all plausible hypotheses for the given token sequence and the given application profile. This task aims to identify patterns in the input token sequence that can activate upward links to higher-order semantic nodes within the HSCM. The query manager returns the set of plausible hypotheses, with each hypothesis corresponding to a node description in the HSCM. The hypothesis activation pattern can be influenced by the application such as when there exists a specific situational ontology tied to the given application.</p></list-item><list-item><p>Determine the most likely semantic node assignment for an unknown token within a sentence. For example, typing errors can be relatively common in medical reports. Various methods can be used to address this query including sequence language models (see <xref rid="pone.0282882.g002" ref-type="fig">Fig 2</xref>, Box 5), spelling correction algorithms, and context sensitive deep learning methods.</p></list-item><list-item><p>Given two incompatible hypotheses, decide which should be given precedence. The HSCM model maintains a decision model for resolving instances where two hypotheses within a sentence are conflicting due to overlapping tokens. Features such as compositional dependencies, token spans comparisons, and contextualized precedence ordering rules are maintained within the HSCM knowledge base.</p></list-item><list-item><p>Determine the semantic compatibility between two constituents. In cases in which the semantic parser (see next section) cannot combine a token into the overall semantic parse due to inadequacies within the compositional grammar, the query processor can ask the question: can the unattached token serve as an attribute for any of the other tokens within the sentence. For example, upon encountering an agrammatical sentence such as: &#8220;Mass, June 2020, 2.3cm in right lung, spiculated margins&#8221; if the concept &#8220;spiculated margins&#8221; is left unaccounted for by the grammar, the query processor can explore the HSCM concept &#8220;Mass&#8221;, examining the property space contained as part of its logical representation. In effect, the query processor would convey to the client that the token &#8220;spiculated margins&#8221; is compatible with the real world logical understanding that it is a sanctioned feature for the concept of a &#8220;mass&#8221;.</p></list-item></list><p>Examples for each of these query classes are provided in the following section describing the parser design.</p></sec><sec id="sec013"><title>Parser design</title><p>Parsing a sentence involves transforming an input sequence of characters into well-formed logical representations sanctioned by the hierarchical compositional model. The semantic parser utilizes the main ideas from a hierarchical predictive coding paradigm and assumes the following HSCM knowledge sources are available: 1) a comprehensive internal model of the semantic constituents; 2) the associated grammar for synthesizing such constituents; and 3) hypothesis activation link definitions. Intuitively, the sentence input (e.g., tokens) is passed through a series of progressively finer-grained processing levels as described below. In this section, we use the running sentence example below to illustrate the overall processor steps.</p><disp-quote><p><bold>[Ex-1]</bold> &#8220;<italic toggle="yes">There is a 5</italic>.<italic toggle="yes">5cm mass in the left upper lobe</italic>.&#8221;</p></disp-quote><p><xref rid="pone.0282882.g003" ref-type="fig">Fig 3</xref> shows the transformations through the HSCM for Ex-1. <xref rid="pone.0282882.g004" ref-type="fig">Fig 4</xref> shows the transformation through various processing levels of refinement as executed by the parser. Note that the references to levels L0, L1, L2, L4, and L5 in the discussion of the parser (see <xref rid="pone.0282882.g004" ref-type="fig">Fig 4</xref>) are unrelated to the reference of the term &#8220;layer&#8221; in the HSCM representation.</p><fig position="float" id="pone.0282882.g004" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0282882.g004</object-id><label>Fig 4</label><caption><title>Parser execution diagram for Ex-1.</title><p>The parser process involves iteratively transforming input tokens into higher levels of semantic abstraction. Box colors of tokens correspond to the class of the semantic constituent within the HSCM. (See figure legend for color assignments. Frame label definitions are as follows: pName.size&#8211;size property name; Ont.Cnpt&#8211;ontologic concept; Num.real&#8211;real number; PName&#8211;property name; pValue&#8211;property value; Ont.E-Frame&#8211;ontologic entity frame; POS.art.indef&#8211;part-of-speech description, definite article; Locative.prep&#8211;locative preposition).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0282882.g004.jpg"/></fig></sec><sec id="sec014"><title>Preprocessing steps</title><p>The first two processing levels, L0 and L1, utilize standard NLP methods to handle relatively simple but useful, tasks and are briefly described below.</p><p><italic toggle="yes">L0 Tokenizer</italic>. The character sequence is mapped to a surface and functional word token sequence. This step is initially performed using common delimiters for orthographic tokenization (e.g., whitespaces and brackets). Attention to the particular input character representation scheme is vital for the proper application of tokenization rules (e.g., ASCII, UTF-32, and EBCDIC). Hyphens and slashes can be disambiguated using context sensitive pattern-based rules. Certain characters such as quotes may be completely ignored in the tokenization process. In our example, the L0 tokenization step results in ten surface word tokens as shown in <xref rid="pone.0282882.g004" ref-type="fig">Fig 4</xref>.</p><p><italic toggle="yes">L1 Lexical analyzer</italic>. The L1 lexical analyzer processing task performs additional mappings of surface words to functional words and computes some initial word level features for each token. In identifying functional words, the lexical analyzer makes use of precompiled lexicons for drug names, abbreviations, and medical idioms. Example word level features computed by the lexical analyzer include morphological features of words, embedding assignments, context free semantic classes from a general medical dictionary, part-of-speech tags, and dependency syntactic parser linkages to other tokens in the sentence. Private to the lexical analyzer are domain-specific pre-compiled lexicons (e.g., radiology terms, drug names, and special symbols) that are used to assign an initial general word-level semantic class for each token. See <xref rid="pone.0282882.t001" ref-type="table">Table 1</xref> for example semantic class and part-of-speech features for Ex-1. The granularity of the L1 semantic tagset is similar to that of the UMLS semantic network. L1 semantics use an outline label-naming syntax to indicate class/subclass relationships (e.g., &#8220;physobj.anatomy&#8221;. Note that the L1 semantics described here are not part of the HSCM model per se, but are used as features to facilitate upward HSCM mappings, as in the task of semantic activation. This mapping is primarily used as the starting point (i.e., prior) for generalizing word-level context for upper level interpretations, rather than for mapping to precise end-user meaning. Out-of-vocabulary terms are initially assigned an L1 semantic tag of _UNKNOWN. The HSCM query processor (see <xref rid="pone.0282882.g002" ref-type="fig">Fig 2</xref>, Box 6) can be consulted to posit initial labels as described above using predictive sequence models. The lexical analyzer also maintains a rule base containing handcrafted sequence patterns to resolve some word sense ambiguities. These ambiguities can often be handled better at higher processing stage levels due to improved surrounding context. As a final note, observe in <xref rid="pone.0282882.g004" ref-type="fig">Fig 4</xref> that the surface token &#8220;5.5cm&#8221; was parsed into the two functional word tokens of &#8220;5.5&#8221; and &#8220;cm&#8221;. This particular parse is performed to ultimately extract the internal semantics of value and units of the length measurement separately. Further details of these first two processing levels can be found in [<xref rid="pone.0282882.ref071" ref-type="bibr">71</xref>, <xref rid="pone.0282882.ref074" ref-type="bibr">74</xref>].</p><table-wrap position="float" id="pone.0282882.t001" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0282882.t001</object-id><label>Table 1</label><caption><title>Example of functional word features as assigned to sentence Ex-1 during the lexical analysis step.</title></caption><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0282882.t001g" position="float" orientation="portrait" xlink:href="pone.0282882.t001.jpg"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Functional Word</th><th align="center" rowspan="1" colspan="1">L1 Semantic Class</th><th align="center" rowspan="1" colspan="1">POS</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">There is</td><td align="center" rowspan="1" colspan="1">relation.exist.be</td><td align="center" rowspan="1" colspan="1">connective</td></tr><tr><td align="center" rowspan="1" colspan="1">a</td><td align="center" rowspan="1" colspan="1">pos.indef_art</td><td align="center" rowspan="1" colspan="1">det</td></tr><tr><td align="center" rowspan="1" colspan="1">5.5</td><td align="center" rowspan="1" colspan="1">number</td><td align="center" rowspan="1" colspan="1">adjective</td></tr><tr><td align="center" rowspan="1" colspan="1">cm</td><td align="center" rowspan="1" colspan="1">propertyName.length</td><td align="center" rowspan="1" colspan="1">noun</td></tr><tr><td align="center" rowspan="1" colspan="1">mass</td><td align="center" rowspan="1" colspan="1">physobj.finding.abnormal</td><td align="center" rowspan="1" colspan="1">noun.sing</td></tr><tr><td align="center" rowspan="1" colspan="1">in</td><td align="center" rowspan="1" colspan="1">pos.in</td><td align="center" rowspan="1" colspan="1">preposition</td></tr><tr><td align="center" rowspan="1" colspan="1">the</td><td align="center" rowspan="1" colspan="1">pos.defin_art</td><td align="center" rowspan="1" colspan="1">determiner</td></tr><tr><td align="center" rowspan="1" colspan="1">left</td><td align="center" rowspan="1" colspan="1">propertyValue.spatial.direction</td><td align="center" rowspan="1" colspan="1">adjective</td></tr><tr><td align="center" rowspan="1" colspan="1">upper</td><td align="center" rowspan="1" colspan="1">propertyValue.spatial.direction</td><td align="center" rowspan="1" colspan="1">adjective</td></tr><tr><td align="center" rowspan="1" colspan="1">lobe</td><td align="center" rowspan="1" colspan="1">physobj.anatomy</td><td align="center" rowspan="1" colspan="1">noun.sing</td></tr></tbody></table></alternatives></table-wrap><p>L1 semantic class and part-of-speech features assigned to the function word tokens for Ex-1. Note that the L1 semantic word classes are not part of the HSCM model and are used only as features of the functional word class. The semantics categories are adapted from [<xref rid="pone.0282882.ref071" ref-type="bibr">71</xref>].</p></sec><sec id="sec015"><title>Predictive coding</title><p>Starting from the third processing level (L2), the parser proceeds using the general ideas of hierarchical predictive coding. The parser performs an iterative procedure summarized as follows:</p><p><italic toggle="yes">a</italic>. <italic toggle="yes">Instantiate a level manager</italic>. A level manager is instantiated to coordinate the global processing for the current stream of tokens (see <xref rid="pone.0282882.g004" ref-type="fig">Fig 4</xref>). The level manager can access the current stream of tokens and global knowledge of the report context and/or driving application (e.g., section heading, procedure description, and NLU task definition).</p><p><italic toggle="yes">b</italic>. <italic toggle="yes">Perform hypothesis generation process</italic>. (see <xref rid="pone.0282882.g005" ref-type="fig">Fig 5</xref>, Box 1): The level manager queries the HSCM knowledge base to identify all possible HSCM hypotheses given the current set of tokens and situational context. The activation network is consulted for this task. The task is treated as a node retrieval problem for most likely HSCM constituents given the current tokens and driving application information. In our example, various functional word patterns can activate a hypothesis. The function word &#8220;lobe&#8221;, for example, has an L1 semantic tag of &#8220;physobj.anatomy&#8221; which will activate the hypothesis of the HSCM ontologic concept &#8220;anatomy concept&#8221;. Depending upon the driving application, a word such as &#8220;lobe&#8221; could activate a more specialized ontologic concept class. For example, for a hepatology application, the word &#8216;lobe&#8217; could activate a specialized HSCM concept node &#8220;anatomy.liver&#8221;. The specialized node can either inherit the grammar from the more general class or can include its own local grammar model in order to parse specific anatomic elements of the liver. Some tokens, like the word &#8220;mass&#8221;, can activate hypotheses through several layers of the HSCM model. In <xref rid="pone.0282882.g003" ref-type="fig">Fig 3</xref>, the L2 level manager will note that the function word &#8220;mass&#8221; has an upward link to the ontologic concept &#8220;Finding.tumoralMass&#8221; which in turn has an upward link to the HSCM model for the &#8220;Mass Description Frame&#8221;. Interestingly, the &#8220;Mass Description Frame&#8221; can activates hypothesis pointing to the ontologic attributes associated with a tumoral mass. This causes a cascade of new hypotheses that includes each of the possible properties associated with the mass. For example, there is an HSCM node for &#8220;x-ray density signal intensity&#8221; associated with the radiological attributes of a mass. This hypothesis could then be used to characterize the phrase &#8220;low density&#8221; in the term &#8220;low density mass&#8221;.</p><fig position="float" id="pone.0282882.g005" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0282882.g005</object-id><label>Fig 5</label><caption><title>Internal processes initiated by the level manager within the parser execution process.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0282882.g005.jpg"/></fig><p><italic toggle="yes">c</italic>. <italic toggle="yes">Perform hypothesis testing process</italic>. (see <xref rid="pone.0282882.g005" ref-type="fig">Fig 5</xref>, Box 2): The level manager activates a bank of agents to test each of the independent activated HSCM hypotheses utilizing their corresponding local grammars. Each higher-level hypothesis is then tested against the current level tokens to assess the validity of the hypothesis. An independent software agent is dispatched per hypothesis. Encapsulated within the semantic node being tested is a grammar model for its synthesis. Short spanning concepts (e.g., single word concepts such as &#8220;mass&#8221;, &#8220;spiculated&#8221;, and &#8220;well-circumscribed&#8221;) can be identified with simple lexico-syntactic-semantic patterns that may include left and right local context. Longer, more complex instances, can be tested, using for example, a finite state machine grammar. Each hypothesis testing agent returns to the level manager a report regarding the truth of the hypothesis. If the hypothesis is true, the agent returns to the level manager the instance (or instances) of the hypothesized HSCM node. Note that the level manager can control which hypothesis testing algorithms (i.e., grammars) to apply depending upon the task application and/or prior failures under similar token context during lower levels of processing.</p><p><italic toggle="yes">d</italic>. <italic toggle="yes">Perform global level assessment of hypothesis testing results</italic>. (see <xref rid="pone.0282882.g005" ref-type="fig">Fig 5</xref>, Box 3): The level manager receives all the results from each of the individual hypothesis testing agents. Again, note that each hypothesis is tested in isolation from all others, thus the need for a global consistency check. The level manager is responsible for adjudicating competitive and/or conflicting hypotheses in order to decide which, if any, should be ultimately instantiated. That is, it must decide which set of hypotheses can credibly explain the input sequence of tokens. Conflicts may arise due to overlapping token sequences. If there are no partial overlapping tokens, a simple rule to prefer the longer text span can be applied. For example, in Ex-1, the anatomy phrase hypothesis &#8220;left upper lobe&#8221; would have preference over the hypotheses for the individual tokens &#8220;left&#8221; (as an anatomic direction), &#8220;upper&#8221; (also as an anatomic direct), and &#8220;lobe&#8221;. Ideally, two different hypotheses with the same text span should not occur in the HSCM model, and would be logged as an inconsistency in the model to be resolved by an adjudicating process. Imposing semantic constraints can can be applied to resolve syntactic attachment ambiguities and/or situations in which two hypotheses have partially overlapping token spans. A rule base or classifier can be consulted as part of the HSCM query capabilities (see <xref rid="pone.0282882.g005" ref-type="fig">Fig 5</xref>, box 3). For example, consider the sentence:</p><disp-quote><p>[<bold>Ex-2</bold>]: &#8220;There is mass in the right lower lobe that is still growing&#8221;.</p></disp-quote><p>Two possible competing hypotheses for the token sequence &#8220;that is still growing&#8221; are the synthesis of an &#8220;Anatomy-Perturbation Frame&#8221; (&#8220;right lower lobe is still growing), or a &#8220;Mass-Finding Frame&#8221; (&#8220;mass is still growing&#8221;).</p><p>Here, the HSCM manager would need to check whether the anatomy phrase &#8220;right lower lobe&#8221; is semantically in the role of an anatomic reference location or the subject of an anatomic description. From the valid construction of the spatial location predicate &#8220;in the right lower lobe&#8221;, the HSCM query manager infers that the anatomy phrase is a reference location and thus can rule out its participation within the &#8220;Anatomy-Perturbation Frame.&#8221; Thus, in general, various types of complex dependency relationships and their respective ordering precedence can be maintained by the HSCM to resolve such conflicts.</p><p><italic toggle="yes">e</italic>, <italic toggle="yes">f</italic>. <italic toggle="yes">Instantiate next level token sequence</italic>. (see <xref rid="pone.0282882.g005" ref-type="fig">Fig 5</xref>, Box 4): The last task of the level manager is to define the token sequence for the next iteration of processing. In <xref rid="pone.0282882.g004" ref-type="fig">Fig 4</xref>, the L2-Level manager has identified several 1-to-1 token mappings from the functional word level to elementary ontologic concepts for sentence Ex-1. For example, the surface words &#8220;5.5&#8221; and &#8220;cm&#8221; are mapped to the elementary concepts &#8220;number.real&#8221; and &#8220;property.length.unit&#8221;. Note that the word &#8220;mass&#8221; was mapped to the high-level HSCM node referring to the &#8220;Mass Description Frame&#8221;. The L2 manager combined the three tokens &#8220;left,&#8221; &#8220;upper,&#8221; and &#8220;lobe&#8221; into the general class of anatomy concept. Note that there is a reduction from 11 to 8 tokens as the parser progressed from level 2 to level 3 processing stages. Also, note that at higher processing levels of the example in <xref rid="pone.0282882.g004" ref-type="fig">Fig 4</xref>, the composition of instantiated tokens can be synthesized using a diversity of node types. For example, the L3 level manager synthesizes two ontologic concept nodes (the &#8220;5.5&#8221; and &#8220;cm&#8221; tokens) into a single ontologic proposition node (&#8220;Property-Value relation&#8221;). The L4 level manager constructs an ontologic proposition node describing a spatial relation from an ontologic concept node (viz., the &#8220;locative.preposition&#8221; concept &#8220;in&#8221;) with an ontologic entity frame (viz., &#8220;Anatomy Description&#8221; frame &#8220;the-left upper lobe&#8221;). As a final example, the L5 level manager defines the top level &#8220;Mass Description Frame&#8221; from an ontologic concept (viz., the &#8220;_thereIs&#8221; concept), an ontologic entity frame (viz., &#8220;Mass Description&#8221; Frame), and an ontologic preposition (viz., &#8220;Spatial Relation&#8221; preposition). Note also the application of a recursion grammar for the &#8220;Mass Description Frame.&#8221; Finally, in defining the next level of tokens, any tokens that cannot be integrated or refined are simply percolated up to the next level processing stage. The idea is that these residual tokens will have a better chance to be interpreted by the HSCM at the next level, where the context for its interpretative role is stronger due to the reduced number of tokens and richer semantic elements.</p></sec><sec id="sec016"><title>Features of the design</title><p>In this section, we discuss some of the notable features of the design and its rationale.</p></sec><sec id="sec017"><title>Structure first</title><p>The most notable element of the design is the presence of the HSCM. The design emphasizes the need to impose a pre-defined internal structure governing the sentence interpretation process. This structure allows the system to factor the understanding task into a number of lower dimensionality problems. Without such structure, it is unlikely that a large clinical corpus alone could model all the contextual variability required for deep understanding. Assuming that the process of semantic compositionality accurately mirrors how humans would factor the interpretation for a given utterance, the structure of the semantic hierarchy will tend to be stable over time, although the stochastic nature of the network will vary across document domains [<xref rid="pone.0282882.ref075" ref-type="bibr">75</xref>]. Once the representation for interpreting a sentence can be established, then the process of acquiring the knowledge for how to navigate through the hierarchy becomes systematically clear. Each node maintains a local grammar model for how it is synthesized from its parts and context. The predefined semantic structure also greatly increases the probability of generating only plausible interpretations. For example, given a comprehensive frame model for a tumoral mass, the parser is guided by the semantic selectional constraints defined by the frame definition and thus can instantiate only property states of the mass that are sanctioned by the model.</p></sec><sec id="sec018"><title>Multi-scale representation</title><p>The parser borrows ideas related to scale-space representation in which the input token sequence of words is iteratively transformed to coarser levels of representation. Each level results in either a reduction or semantic refinement of the tokens from the previous level. Higher-level semantic abstractions summarize structures at finer scales in a manner controlled by their defining semantic grammar. The multi-scale representation aim is to simplify further processing by compacting local details from the current level token sequence. From a signal processing point of view, the constituents at coarser scales constitute simplifications of corresponding constituents at finer scales, a form of noise reduction [<xref rid="pone.0282882.ref076" ref-type="bibr">76</xref>]. The suppression of fine-scale details generally improves the surrounding context for making compositional aggregation decisions at higher processing levels.</p></sec><sec id="sec019"><title>Pattern activation and recognition</title><p>The brain primes itself to receive expected information by activating various semantic memory units. This activation allows the brain to bring into working memory prior semantic expectations for anticipated language signals. These activated nodes serve as hypotheses to be tested using &#8220;environmental sensors&#8221;, which in our design are the semantic grammars associated with each HSCM node. Here the &#8220;environment&#8221; refers to the current sequence of tokens being analyzed by the parser within the context of the application. The activation in our design can be triggered in several ways:</p><list list-type="order"><list-item><p>Anchored triggering&#8211;where a detected base pattern activates associated grammar patterns for an HSCM constituent; For example, the string &#8220;cm&#8221; might activate the HSCM node for size which then activates the grammar for parsing a size expression (e.g., 4cm x 3cm).</p></list-item><list-item><p>Floating triggers&#8212;where grammar patterns are activated in any context. For example, we automatically activate existence phrase grammars for all medical sentences.</p></list-item><list-item><p>Cascading activation&#8211;where a low-level pattern can activate a higher-level semantic frame, which can activate patterns associated with frame&#8217;s attributes and/or entailment relation relatives. For example, the string &#8220;mass&#8221; can activate the HSCM node for tumoral mass, which then triggers all the property attributes associated with a tumoral mass.</p></list-item></list><p>These adaptive activation strategies provide an efficient mechanism for realizing sensible hypotheses for an input sentence associated with plausible HSCM constituents. The activation process also improves global situational awareness of expected information. The framework thus provides the flexibility for integrating a variety of context-sensitive activation schemes that can include features such as application goals, document type, semantic results from prior document sentences, and external medical ontologies [<xref rid="pone.0282882.ref077" ref-type="bibr">77</xref>].</p></sec><sec id="sec020"><title>Agent based architecture</title><p>The conceptual design borrows ideas from distributed agents that act independently. At each level of parser processing, independent software agents are assigned to execute the testing of triggered HSCM hypotheses. Each processing level has a manager that administers these spawned agents. The level manager collects the evidence acquired by each agent to make a global set of actions for the current level of processing. The level manager makes decisions regarding competing hypotheses as well as decides which particular methods for a constituent should be activated. For example, in our work, we have a general semantic grammar for anatomy as well as a specialized more detailed grammar for eye anatomy [<xref rid="pone.0282882.ref078" ref-type="bibr">78</xref>]. The level manager provides the framework to incorporate multiple strategies for explaining away the input level tokens. This framework offers a flexible mechanism for integrating multiple approaches to solve identical problems (e.g., pattern based, probabilistic Markov models, finite state machines, etc.). This global knowledge of available methods and their strengths and weaknesses allows the system to identify the best algorithm for the current level environment and/or apply secondary, more generalized methods in the event that the current methods do not work satisfactorily. For example, ideas of topic centering [<xref rid="pone.0282882.ref079" ref-type="bibr">79</xref>] could be used to interprete residual tokens which are not satisfactorily accommodated by the HSCM grammar.</p></sec><sec id="sec021"><title>Frame-based representation</title><p>Level 2 and higher processing steps implement the key cognitive concept of a semantic frame [<xref rid="pone.0282882.ref080" ref-type="bibr">80</xref>&#8211;<xref rid="pone.0282882.ref082" ref-type="bibr">82</xref>]. Ontologic frames for medical entities are key representational candidates for structuring clinical phenotypes. Anchoring the representation around semantic frames allows the system to take advantage of key ideas such as object-oriented descriptions, recursion, and procedural triggers [<xref rid="pone.0282882.ref083" ref-type="bibr">83</xref>]. The semantic frame representation is used both by the HSCM knowledge base and for characterizing token instances during parser execution.</p></sec><sec id="sec022"><title>Predictive coding</title><p>The predictive coding feature of the parser utilizes a hybrid top-down and bottom-up approach to navigating a sentence through the HSCM. The top-down processing attempts to estimate a forward probability, <italic toggle="yes">P</italic>(<italic toggle="yes">Evidence</italic>|<italic toggle="yes">Hypothesis</italic>), the likelihood, of a given activated hypothesis, which is generally easier to estimate than the inverse probability, <italic toggle="yes">P</italic>(<italic toggle="yes">Hypothesis</italic>|<italic toggle="yes">Evidence</italic>), the posterior. For example, given a concept we wish to articulate, defining a local grammar is easier than testing a sequence of words and testing for every possible HSCM hypothesis. The top-level (&#8220;more cognitive&#8221;) nodes in the HSCM intuitively correspond to increasingly abstract conceptualizations of the world, and these tend to capture or depend upon regularities that span larger text excerpts. The fact that there are many more arrows lower in the hierarchy indicates that the forward problem is generally easier than the reverse problem. The bottom up problem focuses mainly on estimating <italic toggle="yes">P</italic>(<italic toggle="yes">Hypothesis</italic>) priors for HSCM nodes. The semantic activation step reflects an intelligent assignment of priors. The top-down step then focuses on using the semantic grammar for the hypothesis class, to test whether the evidence (i.e., current token sequence) can successively generate the hypothesis. Thus, the predictive coding step inverts the conventional view of bottom-up NLP processing. A successful hypothesis, i.e., one that can be explained away the observed tokens, then allows the priors to be updated to posteriors at the next iteration of processing in conformity with Bayes&#8217; theorem.</p></sec><sec id="sec023"><title>Generative approach</title><p>The generative approach uses the predictive coding strategy to pull itself up the HSCM semantic interpretation hierarchy. The semantic structures at each level provide transparency for explaining how high-level interpretations are derived. This structure makes the framework relatively straightforward to debug. The generative approach provides a path for loosely-connected group efforts to develop a progressively capable system for an expanding scope of topics. Each group could develop shallow grammar models for relevant nodes. As the HSCM model matures and its representation becomes more stable, global optimization methods (e.g., various statistical / neural network models) can be applied.</p></sec></sec></sec><sec sec-type="conclusions" id="sec024"><title>Discussion</title><p>The challenge of bringing a medical text understanding system closer to human capabilities is considerable. In this paper, we discuss a framework which we believe can serve as a foundational architecture for deep understanding of clinical text for diverse clinical problems. The presented framework is primarily knowledge-driven and currently heavily dependent upon manipulating symbolic representations. This framework contrasts the current trend of high performance NLP systems based on data-driven deep learning methods. Below, we present arguments for specific discussion items likely to be of concern regarding our strategic design.</p><sec id="sec025"><title>Comparing the Problem Circumstances of General versus Medical NLU</title><p>The first question one might ask is whether particular issues regarding the medical NLU problem that warrant moving towards a cognitive framework. Six perspective differences are presented below.</p><sec id="sec026"><title>Task-oriented</title><p>With respect to problem definition, the medical NLU system&#8217;s value hinges exclusively on providing the necessary information to accomplish an &#8220;actionable&#8221; task [<xref rid="pone.0282882.ref084" ref-type="bibr">84</xref>]. Medical NLU systems thus are not intended to be general broad coverage applications, but instead targeted agents that are tasked to understand text at sufficient levels of detail and content to correctly guide a clinical or research action. It is important to realize that these tasks can be high-stake and/or mission critical responsibilities, compared to an NLP system that may be searching for information stored on the web or in journal articles. Thus, ignoring tail distribution cases may be unacceptable. For example, suppose the NLU system is tasked to identify patients who should be screened for lung cancer, based on clinical reports describing their chest x-ray findings and smoking habits. Failure to identify such patients should not be hinged on idiosyncratic language including various difficult language phenomena (e.g., ellipsis, coreference resolution, presuppositional inferencing, and linguistic paraphrasing) used within these medical reports. As Dunietz points out, &#8220;the field of natural language processing is chasing the wrong goal&#8221; [<xref rid="pone.0282882.ref085" ref-type="bibr">85</xref>, <xref rid="pone.0282882.ref086" ref-type="bibr">86</xref>]. This message implies that a robust NLU application must consider all possible relevant content in all possible contexts for the driving task. He likens current NLP research as analogous to &#8220;trying to become a professional sprinter by glancing around the gym and adopting any exercises that look hard.&#8221; The paper also emphasizes the importance of staying task-based as opposed to method-based in order to address all possible comprehension intent issues.</p></sec><sec id="sec027"><title>Limited task scope</title><p>Clinical NLU problems focus on tasks with comparatively limited scope of understanding compared to general applications such as a robotics personal assistant application. There have been a number of potential target NLU applications identified across various medical domains [<xref rid="pone.0282882.ref087" ref-type="bibr">87</xref>]. Some examples include: 1) characterization of patient lifestyle habits (e.g., smoking, exercise, diet, alcohol consumption, use of recreational drugs) [<xref rid="pone.0282882.ref088" ref-type="bibr">88</xref>, <xref rid="pone.0282882.ref089" ref-type="bibr">89</xref>]; 2) characterization of mental health conditions (e.g., depression, suicidal, psychiatric syndromes) [<xref rid="pone.0282882.ref090" ref-type="bibr">90</xref>]; 3) characterization of specific clinical findings (e.g., tumoral masses, aneurysms) [<xref rid="pone.0282882.ref091" ref-type="bibr">91</xref>]; 4) identification of patients matching disease screening protocols (e.g., lung cancer) [<xref rid="pone.0282882.ref092" ref-type="bibr">92</xref>]; and 5) characterization of interventions (e.g., tube placement, medications, surgical details) [<xref rid="pone.0282882.ref012" ref-type="bibr">12</xref>, <xref rid="pone.0282882.ref093" ref-type="bibr">93</xref>]. Although the scope of the tasks can be seen as relatively narrow, the performance requirements concerning semantic granularity, explanatory competence, and error frequency and types can be demanding.</p></sec><sec id="sec028"><title>Limited text pool</title><p>The pool of possible sentences to be encountered by any single NLU application is relatively narrow. This limits the vocabulary size and complexity of the grammar compared to general free text. Clinical text, however, can be quite varied with respect to its formality, style, and flow, especially across medical domains. For example, radiology reports typically have a formal declarative language style with complete sentences. Primary physician notes often show abbreviated styles with sentence fragments. Discharge summaries often include lengthy sentences of episodic descriptions in the context of event timelines. An admission note can include a patient&#8217;s own narrative description of their problem using lay language and/or foreign words. The content contained in a given type of report also can vary with respect to the experience of the authoring physician. For example, the reporting style of a novice physician (e.g., resident) can be significantly different from an experience physician (e.g., a novice might generate longer wordier reports that include extraneous descriptions of low-level findings) [<xref rid="pone.0282882.ref094" ref-type="bibr">94</xref>]. The above described variabilities can create challenges for an NLU system to infer the main points of a report communication due to the presence of challenging language aspects such as coordination, coreference resolution and ellipsis.</p></sec><sec id="sec029"><title>Predefined language representation</title><p>The output representation associated with a medical NLU task is predefined and highly structured. There are two main layers of representation: 1) a knowledge representation model associated with the written text per se; and 2) an ontologic based representation focused on the NLU task [<xref rid="pone.0282882.ref095" ref-type="bibr">95</xref>]. The first level builds a semantic representation from the input sentence-level perspective [<xref rid="pone.0282882.ref096" ref-type="bibr">96</xref>]. General knowledge representations for language provide the framework for semantic analysis and an effective structure for constraining the synthesis of semantic constituents [<xref rid="pone.0282882.ref097" ref-type="bibr">97</xref>]. Constituents at this level include word senses, predicate argument structures, and semantic frame definitions. The second level, the application&#8217;s ontologic representation, is intended to directly support queries related to the driving NLU task. This is related to the fact that the output representation is intended to directly support inferencing operations for the clinical decision task in question. For example, well-accepted de-facto reporting models such as BiRADS are specifically designed to infer appropriate patient management strategies [<xref rid="pone.0282882.ref098" ref-type="bibr">98</xref>]. The RECIST model is designed explicitly to standardize the reporting of cancer tumor characteristics in response to treatment [<xref rid="pone.0282882.ref099" ref-type="bibr">99</xref>]. The United States Preventive Services Task Force has defined an information model for patient smoking habits that can be used to infer candidate patients for lung cancer screening procedures [<xref rid="pone.0282882.ref100" ref-type="bibr">100</xref>].</p></sec><sec id="sec030"><title>Speaker-listener model</title><p>There is an underlying speaker-listening coupling that facilitates physician-to-physician communication [<xref rid="pone.0282882.ref101" ref-type="bibr">101</xref>]. That is, the author of a report has in mind the needs of the reader, and the reader has in mind the intentions of the author [<xref rid="pone.0282882.ref102" ref-type="bibr">102</xref>]. This is especially strong among individual physicians who routinely communicate findings and recommendations for given types of patient studies. Societal clinical reporting guidelines can synchronize the expected information content to be communicated between physicians for given types of investigations [<xref rid="pone.0282882.ref103" ref-type="bibr">103</xref>]. This allows the reader of a report to derive interpretations beyond what can be inferred from words alone by leveraging diverse pragmatic knowledge [<xref rid="pone.0282882.ref104" ref-type="bibr">104</xref>]. Thus, although various language complexities are common in medical reports (e.g., lexical and referential ambiguity, ellipsis, and punctuation ambiguity), they can often be mentally corrected from within this overarching expectation model [<xref rid="pone.0282882.ref105" ref-type="bibr">105</xref>]. Contrarily, without the assumed background knowledge, clinicians may be unable to impute the intended meaning of ambiguously written text (&#8220;Curse of knowledge&#8221;) [<xref rid="pone.0282882.ref106" ref-type="bibr">106</xref>]. This can lead to misinterpretation of medical data and, therefore negative patient outcomes [<xref rid="pone.0282882.ref107" ref-type="bibr">107</xref>&#8211;<xref rid="pone.0282882.ref109" ref-type="bibr">109</xref>]. Some examples of various language understanding complexities observed in medical reports include:</p><list list-type="bullet"><list-item><p>Underspecification of terms&#8211;e.g., the phrase &#8220;<italic toggle="yes">left apex</italic>&#8221; in a chest x-ray report refers to the anatomic term &#8220;<italic toggle="yes">apex of the left upper lobe of the lung</italic>.&#8221;</p></list-item><list-item><p>Wrong use of valid terminology&#8211;Physicians may misuse or mis-interpret the meaning of obscure units of measure. For example, consider the sentence, &#8220;<italic toggle="yes">The patient has a cumulative 30 year smoking history of 20 packs per year</italic>.&#8221; The authoring physician, in this case, has misused the units of &#8220;packs per year&#8221;. Since the sentence is a description of cumulative smoking history, the correct unit that should be stated is &#8220;pack-years.&#8221; The two units, although sounding very similar, have very different meanings, with &#8220;pack per year&#8221; describing the rate of smoking behavior while &#8220;pack-years&#8221; is an integrated cumulative value for smoking history. The correct interpretation is essential, since the critical description of &#8220;pack-years&#8221; is used to determine eligibility for lung cancer screening.</p></list-item><list-item><p>Punctuation Mis-use&#8211;In a medical report, physicians may ignore adding full-stop punctuation between sentences. The text is thus seen with multiple sentences running together. The reader&#8217;s basic knowledge of syntax allows sentences to be mentally identified.</p></list-item><list-item><p>Ambiguous pronoun references&#8211;Pronoun reference resolution often depends on the reader having knowledge regarding the physical state and/or dynamics of the referring object. Disambiguation depends on the reader&#8217;s ability to mentally assess real world consistencies and/or test counterfactual hypotheses in order that the formulating interpretations of the text adhere to an expected model of the world [<xref rid="pone.0282882.ref110" ref-type="bibr">110</xref>].</p></list-item><list-item><p>Temporal Ambiguity&#8211;For example, consider the sentence: &#8220;<italic toggle="yes">Patient is widowed since 1972</italic>, <italic toggle="yes">no tobacco</italic>, <italic toggle="yes">no alcohol</italic>, <italic toggle="yes">lives alone</italic>, <italic toggle="yes">smoked 3 packs per day x 17 years</italic>,&#8221; (taken from I2B2 smoking corpus) [<xref rid="pone.0282882.ref111" ref-type="bibr">111</xref>]. Here, the reader should assume that the patient currently does not smoke but previously did smoke for 17 years, with the start time and end time of smoking history unspecified.</p></list-item><list-item><p>Inferred information from practice guidelines&#8211;From a description of a medical conclusion, one can positively infer other useful information. For example, in the sentence: &#8220;<italic toggle="yes">This patient satisfies age and smoking criteria for routine annual screening</italic>.&#8221; This implies that, according to the 2018 American Cancer Society guidelines, that the patient is between 55 and 74 years of age, has a smoking history of at least 30 pack years, and either currently smokes or has quit within the past 15 years [<xref rid="pone.0282882.ref112" ref-type="bibr">112</xref>]. Note that this guideline can change and recently (2021) this guideline is being reviewed for revisions based on the latest scientific evidence.</p></list-item></list><p>This listener-speaker assumption allows the reporting physician to avoid excessive verbiage. The report need not make explicit every level of detail. In some cases, however, physicians can be overly detailed in a negative way. For example, pathologists have been shown to emphasize the completeness of details, but have largely ignored the ability of clinicians to comprehend such detail [<xref rid="pone.0282882.ref113" ref-type="bibr">113</xref>]. This can hinder the intent of the pathologist to convey a more detailed description about the nature of a patient&#8217;s disease state, which could be useful for determining the best management strategies.</p></sec><sec id="sec031"><title>Comprehensive evaluation required by medical NLU systems</title><p>The evaluation procedure for medical NLU applications must go far beyond the technical assessments reported in general NLP studies. This is because the relative importance of various outcome measures is different within an applied field compared to a more basic computing field such as computer science. At the heart of the manner is the fact that in an applied field, development is application specific. By contrast, in a computing field, it is data centric. Thus, in a data-driven field, contributions are targeted toward how much data can be accounted for by the model, as well as the number of applications that can be supported. In contrast, medical NLU applications are evaluated with respect to their effect on clinical care [<xref rid="pone.0282882.ref114" ref-type="bibr">114</xref>]. The general data-driven fields maintains leaderboards for broad tasks, which are scored based on contingency statistics (e.g., precision, recall, AUROC). Performance is evaluated based on models developed on shared pre-defined training and test data. Strategies for handling difficult test cases are rarely reported. Medical NLU applications, however, require not only a technical evaluation component but also are subjected continuously to various levels of scrutiny over the lifetime of its deployment [<xref rid="pone.0282882.ref115" ref-type="bibr">115</xref>&#8211;<xref rid="pone.0282882.ref117" ref-type="bibr">117</xref>]. The evaluation is end-user focused in the sense of what the actual impact the application has on clinical care. Application-centric metrics can take on addressing questions such as the following:</p><list list-type="bullet"><list-item><p>How many patient cases was the NLU system used?</p></list-item><list-item><p>How much time and manpower did the system save?</p></list-item><list-item><p>How much more time was required by the user to review a patient&#8217;s record?</p></list-item><list-item><p>How many times did the system agree with the expert within the context of actual clinical care?</p></list-item><list-item><p>How many unexpected results lead to negative patient outcomes?</p></list-item><list-item><p>How many times did the system improve patient outcomes?</p></list-item><list-item><p>How many times was the system unavailable to provide a satisfactory answer? This might involve the inability of the system to provide a reasonable explanation.</p></list-item><list-item><p>How responsive is the development team to correcting reported errors?</p></list-item><list-item><p>How confident are clinicians in using the application?</p></list-item></list><p>The medical NLU system must be continuously evaluated with respect to its failures and how these failures are addressed. These failures must be evaluated not only from a technology perspective but also from an operational /organizational perspective in which the system is deployed [<xref rid="pone.0282882.ref118" ref-type="bibr">118</xref>].</p></sec></sec><sec id="sec032"><title>Integrating existing knowledge sources and algorithms into the architecture</title><p>NLU at its core involves a number of mapping problems in order to achieve a level of understanding. From this perspective, medical language processing implies the development of mathematical models to represent language phenomena (<italic toggle="yes">e</italic>.<italic toggle="yes">g</italic>., words, meaning, syntactic constructions) and the study of transformations that generatively map such constituents into higher order computer understandable representations that preserve meaning. A fundamental question then relates to exactly what mappings should be performed and how interpretable they should be. The design described in this paper is open to any implementations that satisfy the mapping tasks defined within the HSCM. A clear way to understand the role of existing NLP efforts is to view the NLU system from the Marr Tri-level perspective for complex information processing systems [<xref rid="pone.0282882.ref049" ref-type="bibr">49</xref>, <xref rid="pone.0282882.ref057" ref-type="bibr">57</xref>, <xref rid="pone.0282882.ref119" ref-type="bibr">119</xref>, <xref rid="pone.0282882.ref120" ref-type="bibr">120</xref>]. This perspective includes the: 1) computational level (i.e., what problems the system is faced with, and levels of acceptable uncertainty); 2) algorithmic/representational level (i.e., how the problems can be solved, including for example, Bayesian methods, deep learning methods, and symbolic approaches); and 3) the physical level (i.e., how the system is physically realized). As preliminary work, we reviewed the general and medical NLP literature and conceptually organized NLP subproblems, algorithms, and knowledge sources along the Marr tri-level perspectives (see [<xref rid="pone.0282882.ref058" ref-type="bibr">58</xref>]). The review shows the relationship between the following items: the HSCM semantic layers, the state space of nodes within each layer, the mapping tasks between semantic layers, the sub-problems associated with each mapping class, the common knowledge sources employed within each layer, the typical algorithms and tools associated with various subtasks, and global optimization methods that can be employed. Thus, for example, Layers 0 and 1 of the HSCM identify word level semantics. The state space includes the inventory of all word level semantic descriptions. The subproblems associated with instantiating a node include: spelling correction, morpho-syntactic analysis, part-of-speech tagging, and assignment of word embeddings. The knowledge sources employed for these subtasks consist of probabilistic language models, medical idiomatic expression dictionaries, semantic lexicons, semantic selectional rules, and pre-trained deep learning transformer models. The algorithms and tools that could be employed for these tasks include clustering algorithms, regular expressions pattern matching, finite state machines, hidden Markov models, and neural network-based classifiers. The other layers of the HSCM can also be similarly viewed along these same perspectives. In summary, the HSCM is required to define the mappings for realizing a generative language-understanding framework. The execution strategies of these mappings can take on any best available approaches.</p><sec id="sec033"><title>Technical design evaluation metrics</title><p>The evaluation metrics associated with the architecture can be linked to the described arguments concerning its conceptual advantages and disadvantages. A summary of possible metrics from various perspectives is summarized below.</p></sec><sec id="sec034"><title>Human development effort point of view</title><p>Since the HSCM should parallel how humans model the semantics of words, objects, events, and topics, an important metric is the cost associated with the effort by humans to construct the model. Various aspects per application might include the level of expertise, man-hours required for model development, and level of competence (e.g., errors and consistency) of HSCM authors in following guideline rules.</p></sec><sec id="sec035"><title>From a knowledge engineering perspective</title><p>Evaluation for building the HSCM knowledge base can be expressed in terms of traditional metrics used for ontologies and include expressiveness (representational adequacy), inferential adequacy (ability to infer new information), inferential efficiency, and acquisitional efficiency [<xref rid="pone.0282882.ref121" ref-type="bibr">121</xref>].</p></sec><sec id="sec036"><title>From a software engineering perspective</title><p>The HSCM defines a hierarchical graph based on semantic frames. Thus it embodies the ideas of an object-oriented organization for classes and their associated methods. Thus, the important object-oriented features of inheritance, abstraction, encapsulation, modularity, recursion, and procedural triggers can be easily realized by the architecture. Metrics associated with object-oriented software systems are defined in [<xref rid="pone.0282882.ref122" ref-type="bibr">122</xref>]. Performance metrics that can be defined from these features include time/effort to define new or edit existing HSCM nodes, and time/effort to debug definitional errors. Additional metrics related to the complexity of the HSCM graph include branching complexity, path complexity, data complexity and decisional complexity. These metrics become increasingly important as the breadth of semantic constituents and their complexity rises.</p></sec><sec id="sec037"><title>From a computation perspective</title><p>The general problem of NLU is difficult since it requires a mapping from all possible sentence inputs for a domain to all possible interpretations sanctioned by the software system. This results in a huge state space mapping. To tackle the &#8220;curse of dimensionality&#8221; issue, the system introduces structure in terms of hierarchical semantic composition. This allows the joint problem to be factored into a number of lower dimensional mappings. Computation time for the parser to search the HSCM for an optimal interpretation path is facilitated using a predictive coding algorithm. The search time savings is conceptually reduced from an exhaustive bottom-up search to a controlled hybrid search defined by only plausible hypotheses.</p></sec><sec id="sec038"><title>Comparison of the HSCM and transformer model internal layers</title><p>Transformer models such as BERT have become the state of the art for developing medical NLP applications [<xref rid="pone.0282882.ref123" ref-type="bibr">123</xref>, <xref rid="pone.0282882.ref124" ref-type="bibr">124</xref>]. Deep learning models can generate these pre-trained encoder models in an unsupervised manner using vector based methods within a self-attention architecture [<xref rid="pone.0282882.ref125" ref-type="bibr">125</xref>]. Tenney et al. describes that when probing a BERT transformer model, one can discover that qualitatively the internal layers seem to be encoding raw language properties of input text such as part-of-speech tags, syntactic constituents, syntactic dependencies, semantic roles, co-references, and prototype roles [<xref rid="pone.0282882.ref126" ref-type="bibr">126</xref>]. The layers of the BERT model thus show some similarities to the HSCM layers. As in a traditional NLP pipeline, the lower levels of such encoder models emphasize local syntax, while the upper layers describe increasingly higher-level semantics. Autoencoders in deep learning methods have been shown to promote a hierarchical compositional representation to some degree [<xref rid="pone.0282882.ref127" ref-type="bibr">127</xref>, <xref rid="pone.0282882.ref128" ref-type="bibr">128</xref>]. Although BERT does indeed show these abilities to identify various language-specific properties, relations and constituents, these mappings are made in a fuzzy statistical manner based on word associations using various self-attention mechanisms. In the case of the HSCM, the layering is based on a manually-specified semantic compositional view that reflects how human developers perceive language. The developers can precisely define the semantic granularity of the model that is useful for potential clients of the NLU application. For example, there is a general agreement on how one might create predicate-argument structures, or how a radiologist might define a semantic frame describing the properties of a mass (e.g., structured reporting forms such as BI-RADS [<xref rid="pone.0282882.ref129" ref-type="bibr">129</xref>]). In BERT models, there is no grounding of any constituents to real world ontologic definitions, although in some cases they can approximate this mapping [<xref rid="pone.0282882.ref021" ref-type="bibr">21</xref>]. Given the prolific applicability of BERT for many NLP problems however, it is clear that a sharable high quality language encoding knowledge source can be a core resource for many language-processing tasks. BERT was developed with the spirit of being a general language resource. The HSCM is being developed as a task specific resource. <xref rid="pone.0282882.t002" ref-type="table">Table 2</xref> compares some of the properties associated with the HSCM model versus popular deep learning transformer models such as BERT.</p><table-wrap position="float" id="pone.0282882.t002" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0282882.t002</object-id><label>Table 2</label><caption><title>Comparison of properties of neuro transformer models versus the HSCM.</title></caption><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0282882.t002g" position="float" orientation="portrait" xlink:href="pone.0282882.t002.jpg"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Aspect</th><th align="center" rowspan="1" colspan="1">Transformer Models</th><th align="center" rowspan="1" colspan="1">HSCM</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Description of Layers</td><td align="left" rowspan="1" colspan="1">Can resemble a traditional NLP pipeline, with graded levels of semantic composition. Semantic constituents are coarse-grained. Highly dependent upon training corpus used and internal deep learning parameters.</td><td align="left" rowspan="1" colspan="1">Layers consist of a hierarchy of semantic types with ontological grounding. Constituents, in general, are fine-grained. Semantic composition of meaning consistent with human perspectives. Semantic abstractions can be high-level informational templates common to the medical informatics community (e.g., BiRads, RECIST)</td></tr><tr><td align="left" rowspan="1" colspan="1">Intended Use</td><td align="left" rowspan="1" colspan="1">General resource across diverse domains and tasks.</td><td align="left" rowspan="1" colspan="1">Tailored for each NLU task.</td></tr><tr><td align="left" rowspan="1" colspan="1">Semantic Granularity</td><td align="left" rowspan="1" colspan="1">Varies with training corpus; indeterminate.</td><td align="left" rowspan="1" colspan="1">Controlled by developers per NLU task</td></tr><tr><td align="left" rowspan="1" colspan="1">Effort</td><td align="left" rowspan="1" colspan="1">Data driven, unsupervised (BERT). (Not including decoding top-level classifier development effort per task).</td><td align="left" rowspan="1" colspan="1">Knowledge and data-driven, supervised. Substantial effort required in defining the semantic compositional hierarchy with associated grammars. Requires domain expertise. Development is progressive, benefiting from prior efforts. Parallel development can be relatively straightforward due to the localization of grammars to specific HSCM nodes. Standardization of methods for group development, however, will require community agreement.</td></tr><tr><td align="left" rowspan="1" colspan="1">Capabilities and Long Term Potential</td><td align="left" rowspan="1" colspan="1">Shows good performance for applications that require robust language sequence models. Concerns include a lack of ontologic grounding and awareness of real-world knowledge (e.g., discourse models, situational micro-theories, and clinical context). It is unclear what the necessary parameterization of a network should be to ensure it works for a growing number of medical NLU tasks.</td><td align="left" rowspan="1" colspan="1">Framework conceptually has the potential for interpreting the intensions of authors by incorporating expectation models for targeted clinical communication topics. Concerns include the level of development effort and integration of knowledge sources into the representation.</td></tr><tr><td align="left" rowspan="1" colspan="1">Adaptability / Configurability</td><td align="left" rowspan="1" colspan="1">Transformer encoder models such as BERT are static in the sense that the structure and parameters do not change once they are trained. They are computationally expensive to train limiting the pool of individuals/organizations that can generate such a model.</td><td align="left" rowspan="1" colspan="1">The HSCM is used in a dynamic fashion depending upon the global contextual specifications of the NLU task, and the upward activation patterns (i.e., dynamic routing) fired during the predictive coding steps (i.e., performs adaptive computation depending on local and global contexts).</td></tr><tr><td align="left" rowspan="1" colspan="1">Transparency</td><td align="left" rowspan="1" colspan="1">Relatively opaque; not uncommon for tasks to utilize spurious correlations in data for features.</td><td align="left" rowspan="1" colspan="1">Explanations realized from paths through the HSCM for a given parse of a text excerpt.</td></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec039"><title>Efficiency mechanisms</title><p>Computational efficiencies of the HSCM design are mainly achieved from manifestations of semantic composition (representational efficiency) and hierarchal predictive coding (processing efficiency). Imposing a compositional structure (i.e., factorization) is known to contribute significantly to reducing the dimensionality (i.e., computational complexity) of the parsing problem [<xref rid="pone.0282882.ref130" ref-type="bibr">130</xref>, <xref rid="pone.0282882.ref131" ref-type="bibr">131</xref>]. Efficiencies are gained by factoring the overall NLU problem into a number of lower-dimensional mappings. A compositional structure provides a framework for &#8216;part sharing&#8217; which allows development to proceed in a piece-wise systematic way. This part sharing strategy can lead to an enormous reduction in computational complexity [<xref rid="pone.0282882.ref132" ref-type="bibr">132</xref>, <xref rid="pone.0282882.ref133" ref-type="bibr">133</xref>]. Predictive coding offers processing efficiency since only plausible hypotheses specified within the HSCM need be tested. A combination of bottom-up (hypothesis formulation) and top-down (hypothesis testing) processing conducted within a hierarchical predictive paradigm greatly reduces the search state space for a viable global sentence parse. Note that a purely bottom-up (inverse problem) approach to semantic parsing is regarded as an ill-posed problem [<xref rid="pone.0282882.ref134" ref-type="bibr">134</xref>]. The HSCM model provides semantic compositional constraints to reduce the number of possible interpretations. A full theoretical discussion of how predictive coding can readily solve high-dimensional mapping problems (e.g., all possible input signals to all possible interpretations) using the free-energy theory&#8221; can be found in [<xref rid="pone.0282882.ref135" ref-type="bibr">135</xref>]. Worth mentioning is the relation of predictive coding to backpropagation learning and its efficiencies as employed by neural networks [<xref rid="pone.0282882.ref136" ref-type="bibr">136</xref>, <xref rid="pone.0282882.ref137" ref-type="bibr">137</xref>].</p></sec><sec id="sec040"><title>Importance of compositionality</title><p>Compositionality for language understanding is central in our design on the grounds of two long-standing principles in linguistics: 1) Bottom-up: Principle of Composition&#8211;that the meaning of the whole sentence is a function of the meaning of its parts [<xref rid="pone.0282882.ref031" ref-type="bibr">31</xref>, <xref rid="pone.0282882.ref068" ref-type="bibr">68</xref>, <xref rid="pone.0282882.ref069" ref-type="bibr">69</xref>, <xref rid="pone.0282882.ref138" ref-type="bibr">138</xref>]; and 2) Top-Down: Context Principle&#8211;that words have meaning only as constituents of the sentence [<xref rid="pone.0282882.ref138" ref-type="bibr">138</xref>]. Fillmore described language understanding from the perspective of semantic frames and the idea that contextual regularities can be encapsulated in a grammar [<xref rid="pone.0282882.ref139" ref-type="bibr">139</xref>]. Our design incorporates these ideas by proposing the use of semantic frames for all levels of tokens, attaching grammars for each constituent within the HSCM, and hierarchical incremental parsing to improve context within each processing stage. <xref rid="pone.0282882.g004" ref-type="fig">Fig 4</xref> shows the incremental synthesis of semantic constituents that are aggregated into a unifying sentence-level semantic frame. For a general discussion of computational efficiencies gained from compositional factorization, see [<xref rid="pone.0282882.ref130" ref-type="bibr">130</xref>, <xref rid="pone.0282882.ref132" ref-type="bibr">132</xref>]. Additionally, there has been much discussion within the AI community related to what types of knowledge are required for systems to truly generalize beyond their training data. Central to these discussions is the need for compositionality [<xref rid="pone.0282882.ref035" ref-type="bibr">35</xref>]. Further discussion regarding the benefits of compositionality for NLU can be found in [<xref rid="pone.0282882.ref131" ref-type="bibr">131</xref>], including its benefits with respect to annotation consistency.</p></sec><sec id="sec041"><title>Balance between fine-grained comprehension and general applicability</title><p>Inference models generally experience a familiar trade-off between accuracy and robustness (e.g., recall vs. precision) [<xref rid="pone.0282882.ref140" ref-type="bibr">140</xref>]. A number of design compromises need to be considered for each given task. These considerations include a) performance requirements of the driving NLU task (e.g., error rates, semantic granularity, b) the need for an explanation of answers, c) the types of errors observed (e.g., similar to humans), d) processing speed, and e) text coverage. The weighting placed upon such considerations often depends upon whether the NLU task is population-centric or patient centric. The population class includes medical applications that aim to estimate or improve upon a population parameter. Examples of tasks that prioritize breadth of coverage (i.e., generality) include the identification of patients who match inclusion criteria for assembling teaching cases and discerning patients who are possible candidates for a specific clinical trial. General-purpose language knowledge sources such as BERT can be quite effective in improving targeted performance parameters (e.g., percent of patients enrolled in a clinical trial). If the pool size of the patient population is large, the expectations of an NLU application may allow tail distribution samples to suffer from relatively poor performance. That is, it may be acceptable to have a relaxed expectation of accuracy for rare/difficult language use. However, there are also cases, such as in identification of patients with rare conditions, where it is important to identify specific criteria and/or infer target cases based on causality. In such situations, a system that outputs rich semantics and/or infers causal meaning might be more effective. The second class of problems to consider is patient-centric NLU applications. While robustness across all expected note types, authors, and institutions is desirable, sacrifices in accuracy can be highly detrimental to long-term clinical acceptance. This can be especially true if blatant errors are experienced in, for example, point-of-care applications or patient treatment planning meetings such as tumor boards [<xref rid="pone.0282882.ref141" ref-type="bibr">141</xref>]. To avoid such issues, precise micro-theories that can supplement the required context for text comprehension may be necessary. Such fine-grained modeling can impose real-world semantic constraints on meaning representations [<xref rid="pone.0282882.ref095" ref-type="bibr">95</xref>]. Until various levels of clinical evaluation are performed [<xref rid="pone.0282882.ref115" ref-type="bibr">115</xref>, <xref rid="pone.0282882.ref117" ref-type="bibr">117</xref>], it is often difficult to estimate the required performance parameters of a task until several rounds of efficacy and clinical outcome studies have been performed. This is most evident in the fact that there are a large number of technical evaluations reported in the medical NLP literature, yet the number of implementations in actual clinical use with reported clinical value remains scarce [<xref rid="pone.0282882.ref116" ref-type="bibr">116</xref>, <xref rid="pone.0282882.ref142" ref-type="bibr">142</xref>, <xref rid="pone.0282882.ref143" ref-type="bibr">143</xref>]. Transparency of algorithms and patient safety concerns remain as critical concerns in this regard [<xref rid="pone.0282882.ref142" ref-type="bibr">142</xref>, <xref rid="pone.0282882.ref144" ref-type="bibr">144</xref>].</p></sec><sec id="sec042"><title>Summary of main arguments in favor of a cognitive framework for medical NLU</title><p>This is a difficult question because in making a decision about strategic directions, one must carefully evaluate the growth potential of alternative systems and project which paradigm can best serve as a long-term framework for efficiently deploying medical NLU applications at the highest possible standards, including maximizing patient benefits, minimizing patient harm, and minimizing cost to society.</p><p>The question of whether a data-driven, knowledge-driven, or hybrid system should be the driving paradigm for language understanding has been lively debated for many years [<xref rid="pone.0282882.ref035" ref-type="bibr">35</xref>, <xref rid="pone.0282882.ref145" ref-type="bibr">145</xref>, <xref rid="pone.0282882.ref146" ref-type="bibr">146</xref>]. The two paradigms vary significantly in many respects. Deep learning system development is data-driven, relying of manipulating numeric representations that are continuous. Cognitive system development is largely knowledge-driven, relying on the manipulation of symbolic representations that are discrete in nature [<xref rid="pone.0282882.ref147" ref-type="bibr">147</xref>].</p><p>Much of the discussion regarding the strategic direction to follow centers on the degree to which prior knowledge is required for language understanding, as for example, argued by the rationalist versus empiricist views [<xref rid="pone.0282882.ref148" ref-type="bibr">148</xref>]. In principle, there is agreement that NLU systems need declarative knowledge in order to achieve human levels of understanding [<xref rid="pone.0282882.ref149" ref-type="bibr">149</xref>]. The differences in the two paradigms relates largely to how this knowledge is to be acquired and represented within a software system. A few issues to consider are presented below.</p></sec><sec id="sec043"><title>Amount and acquisition approach of knowledge</title><p>The sheer amount of estimated knowledge can deter what strategic directions one follows. In deep-learning data driven methods, it is typically assumed that the goal of a knowledge base is to serve as a foundational language resource for a broad spectrum of applications [<xref rid="pone.0282882.ref150" ref-type="bibr">150</xref>]. These foundational models thus assume that the application space and associated text are open-ended and ambiguous and that it is not feasible to specify the required knowledge using manual or supervised methods. Self-supervised methods such as autoregressive self-learning (e.g., GPT-3) and auto-encoding self-learning approaches (e.g., BERT) are commonly used. The assumption is that the knowledge will emerge automatically by analyzing a large amount of text using such self-learning algorithms. The base &#8220;genetics&#8221; supplied to these algorithms that dictate how the knowledgebase will evolve from no structure to highly structured (billions of parameters) is, surprisingly, a simple set of rules that are applied iteratively to the training corpora [<xref rid="pone.0282882.ref151" ref-type="bibr">151</xref>]. The mottos of &#8220;attention is all you need&#8221; [<xref rid="pone.0282882.ref125" ref-type="bibr">125</xref>] and &#8220;scale is all you need&#8221; [<xref rid="pone.0282882.ref152" ref-type="bibr">152</xref>] encapsulate the ideas of how such foundational models are realized.</p><p>Conversely, the cognitive approach seeks to adapt or incrementally acquire knowledge on an application-by-application basis. The assumption is that, given the limited scope of each task, it is feasible to manually specify over time a comprehensive metaphysical logical representation of the essential information content required by a driving application. It further assumes that this representation will be relatively stable and can evolve incrementally. The approach emphasizes meaning by grounding semantic constituents to real-world interpretations. New applications are supported by either utilizing views of the model already developed (i.e., part sharing) or adding/modifying new components and linkages to the overall representation.</p><p><italic toggle="yes">Quality of knowledge</italic>. The data-driven approach emphasizes breadth of knowledge, attempting to extract whatever regularities can be inferred using the attention-based rules ingrained by self-learning algorithms. While the breadth of knowledge captured by pre-trained deep learning models appears substantial, their quality is indeterminate. Because of their emergent behavior, deep learning models are hard to understand and control. The quality of the knowledge depends on the locality rules for attention (i.e., close to broad), the training text (e.g., amount, type, and order), the model structure (e.g., network size), and training protocol. While the quality of knowledge captured in pre-trained models such as BERT appears surprisingly exceptional based on their remarkable successes, it is not uniform across the spectrum of knowledge elements intrinsic within the text they are trained on. Current models are designed to solve the language masking problem, which may be unrelated to an applied downstream task. These models seem to be able to learn some types of regularities in language rather accurately (e.g., syntactic relationship) but poorly at others (e.g., temporal reasoning tasks) [<xref rid="pone.0282882.ref153" ref-type="bibr">153</xref>]. Karlgen and Kanerva discuss the theoretical issues limiting the semantic accuracy and semantic similarity abilities of high-dimensional vector representations [<xref rid="pone.0282882.ref154" ref-type="bibr">154</xref>]. Global and irrelevant statistical dependencies can blur local intrinsic relevant features in high-dimensional representations, as noted when computing multi-dimensional centroids (a form of lossy compression). Composition within a deep learning architecture can further exasperate the semantic quality of such latent representations, entangling concepts in a spurious manner [<xref rid="pone.0282882.ref155" ref-type="bibr">155</xref>, <xref rid="pone.0282882.ref156" ref-type="bibr">156</xref>].</p><p>The cognitive approach emphasizes high-quality knowledge that is consistent with views of how the problem domain should perceive the world situation. The semantic granularity of a cognitive model is under the developer&#8217;s control. The modeling process ensures at a logical level that the necessary content for explanation is included. It focuses on including only enough information required to understand the text to support the NLU actionable response. The definition of the logical model however is subjective and is based on the views of the developers and/or adapting communities. In general, it may require numerous iterations to be comprehensive for the target application over many site deployments. The quality of the knowledge to be included is very specific to the micro-world associated with an NLU task in order to address difficulties such as coreference resolution, clarification of ellipsis, interpretation of coordinating conjunctions, and proper assessment of event temporal order. This ontologic grounding of meaning provides the key knowledge substrate for debugging, transparency and explanation. A valid question to be raised about the cognitive paradigm is whether such a comprehensive model can be pre-defined for a given application, and what are the dangers of incomplete or erroneous constraints within the model. Such deficiencies can limit the performance of an NLU application and have a significant impact on the performance of unseen samples [<xref rid="pone.0282882.ref145" ref-type="bibr">145</xref>].</p><p><italic toggle="yes">Integration of external knowledge</italic>. Current transformer models do not have specific mappings to ontologic concepts. Their distributed multi-dimensional representation makes mappings to a specific user-defined view of the domain difficult. The cognitive view emphasizes ontologic representations at various levels of semantic abstraction. Integrating external knowledge sources is conceptually possible to order to increase the scope of queries supported by the knowledgebase. Common sources include thesauruses (e.g., WordNet and UMLS), logical definitions of predicate-argument structures (e.g., PropBank [<xref rid="pone.0282882.ref060" ref-type="bibr">60</xref>, <xref rid="pone.0282882.ref062" ref-type="bibr">62</xref>]), and numerous medically topic-specific ontologies (see, for example, the compilations at The Open Biological and Biomedical Ontology Foundry [<xref rid="pone.0282882.ref157" ref-type="bibr">157</xref>]. At a practical level, integration of heterogeneous ontologies can be challenging due to the standardization of interfaces at both the logical model and processor levels. This overhead is commonly seen in issues related to mismatches in syntax, intended use, node definitions, label ambiguity, and inheritance complexities [<xref rid="pone.0282882.ref158" ref-type="bibr">158</xref>].</p><p><italic toggle="yes">Is required knowledge known to humans</italic>?. A more basic question related to knowledge inclusion is whether or not it can be specified. That is, if it can be formally specified, it can be theoretically implemented in software. For example, deep learning systems for image and signal analysis domains have been able to reach high levels of recognition accuracy because they have the potential to detect complex imaging patterns (e.g., textures, hierarchical layered, periodicities, and self-similarity features) that may not be obvious to human observers. In language, however, humans have an inherent ability to identify relevant content for almost all language understanding tasks, and there is a long and rich academic history of defining representations for language [<xref rid="pone.0282882.ref096" ref-type="bibr">96</xref>]. The point here is that, although we have the practical knowledge to specify a comprehensive semantic substrate for inferring meaning intent for a given NLU task, the trend is to avoid such unfashionable building of this logical symbolic layer through manual means.</p><p><italic toggle="yes">Computational science fields vs</italic>. <italic toggle="yes">medical informatics culture</italic>. The direction of medical natural language processing research has been significantly influenced by the academic culture of traditional computing fields such as computer science and statistics. The computational disciplines value algorithms that are generally applicable to a wide scope of problems, with a balance of effectiveness and efficiency. The estimates of time and space complexities of an algorithm are valued with the assumption that the algorithm will perform complex operations on large amounts of diverse input data. Manual specification of domain knowledge has been traditionally discouraged by criticisms related to algorithm generalizability. Annotation of training examples, which may require domain expertise, is commonly viewed as &#8220;<italic toggle="yes">tedious</italic>,&#8221; &#8220;<italic toggle="yes">expensive</italic>,&#8221; and/or &#8220;<italic toggle="yes">extremely time consuming</italic>.&#8221; This places a high value on unsupervised methods. Feigenbaum comments that this reluctance to avoid domain knowledge is likely related to the skill and interest boundaries between computational-oriented experts (e.g., computer scientists and statisticians) and domain-application experts (e.g., medical informaticians and clinicians) [<xref rid="pone.0282882.ref159" ref-type="bibr">159</xref>]. Within our applied field, adapting these biases simply perpetuates the theory-practice chasm, potentially limiting the abilities of NLU systems to achieve a human-level of comprehension. There is a tendency because of this bias to take a &#8220;do nothing&#8221; approach. Computationalists, we might say, tend toward being generalists, with the goal of applying algorithms to a broad class of data. Informaticists focus on tasks, thereby, operating within the mindset of a specialist, investigating all aspects of a problem in all use scenarios to strive toward a perfected product. The criteria for a good algorithm (e.g., generalizability) are not necessarily applicable to the criteria for a good application. Without a specialist demeanor, an NLU application likely will not survive within a clinical environment as it must perform and be managed according to the needs presented within the realities of a clinical ecosystem. The medical informatics community ultimately values a system that facilitates medical care, regardless of whether a particular solution is computationally fashionable. We cannot selectively filter which issues brought up by users of an NLU application to ignore based on the limitations of preferred methods. We cannot ignore complex language understanding phenomena that may exist in the data because there is no theoretical framework for intentional inference or because of an unwillingness to put effort into solutions that require manual effort. As an applied field, we believe the development of rich medical domain-specific models, which provide the basis and transparency for interpretation, should be promoted. The medical informatics community, in fact, has a long history of enthusiastically pursuing the construction of fine-grain data models and ontologies. Friedman had previously discussed the merits of building sublanguage models for improving the semantic granularity of medical NLP system outputs [<xref rid="pone.0282882.ref160" ref-type="bibr">160</xref>]. Given the relative stability of the concepts, predicates, and communicative goals of a given task, we speculate that these models should be realizable with diligent and persistent efforts from knowledge engineers.</p></sec><sec id="sec044"><title>Hybrid neuro-symbolic directions</title><p>Deep learning is a highly active, rapidly changing field. New directions that emphasize learning compositional models of real-world objects and events are being investigated in order to acquire more human levels of cognition [<xref rid="pone.0282882.ref149" ref-type="bibr">149</xref>]. Hybrid systems that borrow from the strengths of symbolic and deep learning paradigms are being actively pursued [<xref rid="pone.0282882.ref155" ref-type="bibr">155</xref>, <xref rid="pone.0282882.ref161" ref-type="bibr">161</xref>, <xref rid="pone.0282882.ref162" ref-type="bibr">162</xref>]. Leading AI experts have acknowledged the need for NLU systems to integrate knowledge at all levels of comprehension [<xref rid="pone.0282882.ref149" ref-type="bibr">149</xref>, <xref rid="pone.0282882.ref163" ref-type="bibr">163</xref>]. Google Search, for example, uses both a deep learning BERT model and a symbolic knowledge graph to disambiguate word sense. Commonsense knowledge inferred using deep learning methods is an active area of research [<xref rid="pone.0282882.ref164" ref-type="bibr">164</xref>]. Symbolic systems have the advantage of symbol grounding from which various types of logical inference can be performed. Symbolic systems are at risk for lack of coverage and/or context-specific errors in their structural and semantic specifications. Deep learning systems have the advantages of learning complex semantic abstractions as well as contextualizing word/phrase used over broad coverage. Generalizing grammar patterns and/or improving semantic activation within a cognitive paradigm can be significantly supplemented using deep learning features [<xref rid="pone.0282882.ref165" ref-type="bibr">165</xref>]. Dynamic agents can easily then combine symbolic features (e.g., syntactic-semantic word patterns) and deep learning features (e.g., word and graph embeddings) to generalize compositional grammars and/or semantic activation triggers for hypothesis testing and generation. A comprehensive discussion of general arguments in support of a hybrid paradigm for AI is given in [<xref rid="pone.0282882.ref166" ref-type="bibr">166</xref>].</p></sec></sec></sec><sec sec-type="conclusions" id="sec045"><title>Conclusion</title><p>The strategic direction to pursue for medical NLU is a topic that has not been thoroughly discussed. Many have already conceded to the direction of deep learning architectures. However, many of the arguments and biases of a data-driven deep learning approach stated in the general computing field do not necessarily hold within the medical informatics application field. Medical NLU problems typically do not require processing huge amounts of data within a limited time. Medical informatics endeavors do not find it difficult to seek the collaboration of domain experts, but rather always work closely with them. The medical informatics community is not often deterred from constructing comprehensive knowledge sources. It has a long rich history of building metaphysical representation of various medical/biological phenomena. Data-driven claims that applications are &#8220;ephemeral&#8221; are not applicable [see The Data-Centric <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://Manifesto-datacentricmanifesto.org" ext-link-type="uri">Manifesto&#8211;datacentricmanifesto.org</ext-link>]. Medical NLU tasks are motivated by real needs that have relatively stable specifications. Clinical failures are primarily due to implementation issues and not specification of needs [<xref rid="pone.0282882.ref058" ref-type="bibr">58</xref>, <xref rid="pone.0282882.ref117" ref-type="bibr">117</xref>]. Our position is that the knowledge driven cognitive paradigm better address a number of theoretical and practical concerns of data driven methods. The cognitive approach allows each NLU task to define its required level of semantic content and granularity. It defines an organic transparent semantic substrate to support logical inferencing and from which explanations can be derived. It provides a means of integrating various existing ontologies to extend its coverage and inferencing capabilities. Semantic composition allows constituent grammars to be defined locally to each HSCM node, thereby facilitating community development. Composition can also simplify training efforts using grammar-based semantic annotation schemes, which become increasingly important with the complexity of the NLU task [<xref rid="pone.0282882.ref130" ref-type="bibr">130</xref>].</p><p>In conclusion, we present arguments for an NLU architecture that is cognitively inspired. At its core is the HSCM that imposes structural constraints on the expectations of how information is expressed in the targeted language domain. This applied structure allows the system to process input sentences using a predictive coding paradigm. An agent based processing scheme allows various algorithms and inferencing modes to be available for a given NLU subtask. Although we acknowledge that a number of alternative architectures are possible, we believe that this framework has the potential for accommodating important design considerations including:</p><list list-type="order"><list-item><p>Theory&#8211;a foundational architecture should be able to accommodate the best theories of language understanding from linguistics, cognitive science, and neuroscience;</p></list-item><list-item><p>Computation&#8211;the framework must accommodate the most recent advances related to computing the most likely interpretation (in an information-theoretic sense) for a given text input;</p></list-item><list-item><p>Flexibility&#8211;the design needs to be adaptable, allowing for different algorithmic approaches to be explored;</p></list-item><list-item><p>Transparency / Explainability&#8211;It is desirable for an NLU system to be transparent as to how it is making its decisions. The model should be able to explain how it derived its final interpretation in terms of only sanctioned (sub) interpretations as defined by the HSCM.</p></list-item><list-item><p>Applicability&#8211;the architecture must be applicable to diverse domains/applications that may require different degrees of accuracy and coverage and processed in a timely manner;</p></list-item><list-item><p>Interoperability&#8211;the logical compositional model should ultimately be able to semantically interoperate with other knowledge sources (e.g., causal models of disease and various ontologies) in order to perform higher-level inferences at any level of interpretation.</p></list-item><list-item><p>Scope / Scalability&#8211;The architecture should have a high growth potential, evolving into a high-density system of nodes and connections that can be utilized to understand a greater scope of sentences within a greater range of application contexts. The architecture should be able to build upon existing efforts in a theoretically principled and unifying manner.</p></list-item></list><p>Implementation of a prototype system for analyzing descriptions of tumors from radiology reports has been ongoing within our department and has been the driving application for developing many of the ideas of this design. Details of this implementation are planned to be reported in the near future.</p></sec></body><back><ack><p>The author would like to thank the many members of the UCLA Medical Imaging Informatics Graduate Program for their constructive discussions related to the topic of this paper. We would also like to thank Lew Andrada for grammar and style related edits.</p></ack><ref-list><title>References</title><ref id="pone.0282882.ref001"><label>1</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Robinson</surname><given-names>PN</given-names></name>. <article-title>Deep phenotyping for precision medicine.</article-title><source>Human Mutatation</source>. <year>2012</year>;<volume>33</volume>(<issue>5</issue>):<fpage>777</fpage>&#8211;<lpage>780</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/humu.22080</pub-id><pub-id pub-id-type="pmid">22504886</pub-id></mixed-citation></ref><ref id="pone.0282882.ref002"><label>2</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Moreno-De-Luca</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Sanders</surname><given-names>SJ</given-names></name>, <name name-style="western"><surname>Willsey</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Mulle</surname><given-names>JG</given-names></name>, <name name-style="western"><surname>Lowe</surname><given-names>JK</given-names></name>, <etal>et al</etal>. <article-title>Using large clinical data sets to infer pathogenicity for rare copy number variants in autism cohorts</article-title>. <source>Molecular Psychiatry</source>. <year>2013</year>;<volume>18</volume>(<issue>10</issue>):<fpage>1090</fpage>&#8211;<lpage>1095</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/mp.2012.138</pub-id><pub-id pub-id-type="pmid">23044707</pub-id><pub-id pub-id-type="pmcid">PMC3720840</pub-id></mixed-citation></ref><ref id="pone.0282882.ref003"><label>3</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Jensen</surname><given-names>PB</given-names></name>, <name name-style="western"><surname>Jensen</surname><given-names>LJ</given-names></name>, and <name name-style="western"><surname>Brunak</surname><given-names>S</given-names></name>. <article-title>Mining electronic health records: toward better research applications and clinical care</article-title>. <source>Nature Reviews Genetics</source>. <year>2012</year>;<volume>13</volume>:<fpage>395</fpage>&#8211;<lpage>405</lpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/nrg3208</pub-id><pub-id pub-id-type="pmid">22549152</pub-id></mixed-citation></ref><ref id="pone.0282882.ref004"><label>4</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Winslow</surname><given-names>RL</given-names></name>, <name name-style="western"><surname>Trayanova</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Geman</surname><given-names>D</given-names></name>, and <name name-style="western"><surname>Miller</surname><given-names>MI</given-names></name>. <article-title>Computational medicine: Translating models to clinical care</article-title>. <source>Science Translational Medicine</source>. <year>2012</year>;<volume>4</volume>(<issue>158</issue>):<fpage>158rv111</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1126/scitranslmed.3003528</pub-id><pub-id pub-id-type="pmid">23115356</pub-id><pub-id pub-id-type="pmcid">PMC3618897</pub-id></mixed-citation></ref><ref id="pone.0282882.ref005"><label>5</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Katzan</surname><given-names>IL</given-names></name> and <name name-style="western"><surname>Rudick</surname><given-names>RA</given-names></name>. <article-title>Time to integrate clinical and research informatics</article-title>. <source>Science Translational Medicine</source>. <year>2012</year>;<volume>4</volume>(<issue>162</issue>):<fpage>162fs41</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1126/scitranslmed.3004583</pub-id><pub-id pub-id-type="pmid">23197569</pub-id></mixed-citation></ref><ref id="pone.0282882.ref006"><label>6</label><mixed-citation publication-type="other">Roberts K. Chapter 8&#8212;Natural Language Processing. In: Hersh W, editor. Health Informatics, Practical Guide, 8<sup>th</sup> Edition, ISBN 9781435787759, 2022.</mixed-citation></ref><ref id="pone.0282882.ref007"><label>7</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Gao</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Dligach</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Christensen</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Tesch</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Laffin</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Xu</surname><given-names>D</given-names></name>, <etal>et al</etal>. <article-title>A scoping review of publicly available language tasks in clinical natural language processing</article-title>. <source>Journal of the American Medical Informatics Association</source>. <year>2022</year>;<volume>29</volume>(<issue>10</issue>):<fpage>1797</fpage>&#8211;<lpage>1806</lpage>.<pub-id pub-id-type="pmid">35923088</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/jamia/ocac127</pub-id><pub-id pub-id-type="pmcid">PMC9471718</pub-id></mixed-citation></ref><ref id="pone.0282882.ref008"><label>8</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Kim</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Jiang</surname><given-names>X</given-names></name>, and <name name-style="western"><surname>Ohno-Machado</surname><given-names>L</given-names></name>. <article-title>Trends in biomedical informatics: most cited topics from recent years</article-title>. <source>Journal of the American Medical Informatics Association</source>. <year>2011</year>;<volume>18</volume>:<issue>Supp1</issue>:<fpage>i166</fpage>&#8211;<lpage>i170</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1136/amiajnl-2011-000706</pub-id><pub-id pub-id-type="pmid">22180873</pub-id><pub-id pub-id-type="pmcid">PMC3241182</pub-id></mixed-citation></ref><ref id="pone.0282882.ref009"><label>9</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Chen</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Xie</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>FL</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Xu</surname><given-names>J</given-names></name>, and <name name-style="western"><surname>Hao</surname><given-names>T</given-names></name>. <article-title>A bibliometric analysis of natural language processing in medical research.</article-title><source>BMC Medical Informatics and Decision Making.</source><year>2018</year>;<volume>18</volume>(<issue>Supp. 1</issue>):<fpage>14</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12911-018-0594-x</pub-id><pub-id pub-id-type="pmid">29589569</pub-id><pub-id pub-id-type="pmcid">PMC5872501</pub-id></mixed-citation></ref><ref id="pone.0282882.ref010"><label>10</label><mixed-citation publication-type="other">Cohen T, Schvaneveldt R, and Rindflesch TC. Predication-based semantic indexing: permutations as a means to encode predications in semantic space. In: Proceedings of the American Medical Informatics Association Annual Fall Symposium; 2009 Nov 14&#8211;18; San Francisco, CA, USA. American Informatics Association; 2009. p. 114&#8211;118.<pub-id pub-id-type="pmcid">PMC2815384</pub-id><pub-id pub-id-type="pmid">20351833</pub-id></mixed-citation></ref><ref id="pone.0282882.ref011"><label>11</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Simon</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Casella dos Santos</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Fielding</surname><given-names>JM</given-names></name>, and <name name-style="western"><surname>Smith</surname><given-names>B</given-names></name>. <article-title>Formal ontology for natural language processing and the integration of biomedical databases</article-title>. <source>International Journal of Medical Informatics</source>. <year>2006</year>;<volume>75</volume>(<issue>3&#8211;4</issue>):<fpage>224</fpage>&#8211;<lpage>231</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ijmedinf.2005.07.015</pub-id><pub-id pub-id-type="pmid">16153885</pub-id></mixed-citation></ref><ref id="pone.0282882.ref012"><label>12</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Xu</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Stenner</surname><given-names>SP</given-names></name>, <name name-style="western"><surname>Doan</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>KB</given-names></name>, <name name-style="western"><surname>Waitman</surname><given-names>LR</given-names></name>, and <name name-style="western"><surname>Denny</surname><given-names>JC</given-names></name>. <article-title>MedEx: a medication information extraction system for clinical narratives</article-title>. <source>Journal of the American Medical Informatics Association</source>. <year>2010</year>;<volume>17</volume>(<issue>1</issue>):<fpage>19</fpage>&#8211;<lpage>24</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1197/jamia.M3378</pub-id><pub-id pub-id-type="pmid">20064797</pub-id><pub-id pub-id-type="pmcid">PMC2995636</pub-id></mixed-citation></ref><ref id="pone.0282882.ref013"><label>13</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Pathak</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bailey</surname><given-names>KR</given-names></name>, <name name-style="western"><surname>Beebe</surname><given-names>CE</given-names></name>, <name name-style="western"><surname>Bethard</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Carrell</surname><given-names>DS</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>PJ</given-names></name>, <etal>et al</etal>. <article-title>Normalization and standardization of electronic health records for high-throughput phenotyping: the SHARPn consortium</article-title>. <source>Journal of the American Medical Informatics Association</source>. <year>2013</year>;<volume>20</volume>(<issue>e2</issue>):<fpage>e341</fpage>&#8211;<lpage>e348</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1136/amiajnl-2013-001939</pub-id><pub-id pub-id-type="pmid">24190931</pub-id><pub-id pub-id-type="pmcid">PMC3861933</pub-id></mixed-citation></ref><ref id="pone.0282882.ref014"><label>14</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Meystre</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>S</given-names></name>. <name name-style="western"><surname>Jung</surname><given-names>CY</given-names></name>, and <name name-style="western"><surname>Chevrier</surname><given-names>RD</given-names></name>. <article-title>Common data model for natural language processing based on two existing standard information models: CDA+GrAF</article-title>. <source>Journal of Biomedical Informatics</source>. <year>2012</year>;<volume>45</volume>(<issue>4</issue>):<fpage>703</fpage>&#8211;<lpage>710</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jbi.2011.11.018</pub-id><pub-id pub-id-type="pmid">22197801</pub-id></mixed-citation></ref><ref id="pone.0282882.ref015"><label>15</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Tao</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Song</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Sharma</surname><given-names>D</given-names></name>, and <name name-style="western"><surname>Chute</surname><given-names>C</given-names></name>. <article-title>Semantator: semantic annotator for converting biomedical text to linked data</article-title>. <source>Journal of Biomedical Informatics</source>. <year>2013</year>;<volume>46</volume>(<issue>5</issue>):<fpage>882</fpage>&#8211;<lpage>893</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jbi.2013.07.003</pub-id><pub-id pub-id-type="pmid">23867104</pub-id><pub-id pub-id-type="pmcid">PMC4837761</pub-id></mixed-citation></ref><ref id="pone.0282882.ref016"><label>16</label><mixed-citation publication-type="other">OHNLP&#8212;Open Health NLP Consortium - <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://ohnlp.org/index.php/Main-Page" ext-link-type="uri">http://ohnlp.org/index.php/Main-Page</ext-link>. Last accessed June 2020.</mixed-citation></ref><ref id="pone.0282882.ref017"><label>17</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Friedman</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Rindflesch</surname><given-names>TC</given-names></name>, and <name name-style="western"><surname>Corn</surname><given-names>M</given-names></name>. <article-title>Natural language processing: State of the art and prospects for significant progress, a workshop sponsored by the National Library of Medicine.</article-title><source>Journal of Biomedical Informatics.</source><year>2013</year>;<volume>46</volume>:<fpage>765</fpage>&#8211;<lpage>773</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jbi.2013.06.004</pub-id><pub-id pub-id-type="pmid">23810857</pub-id></mixed-citation></ref><ref id="pone.0282882.ref018"><label>18</label><mixed-citation publication-type="book"><name name-style="western"><surname>Doan</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Conway</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Phuong</surname><given-names>TM</given-names></name>, and <name name-style="western"><surname>Ohno-Machado</surname><given-names>L</given-names></name>. <part-title>Natural language processing in biomedicine: a unified system architecture overview. Clinical Bioinformatics, Chapter 16</part-title>. In: <name name-style="western"><surname>Trent</surname><given-names>R</given-names></name> (Ed.), <source>Clinical Bioinformatics</source>. <publisher-name>Springer</publisher-name><publisher-loc>New York, New York</publisher-loc>; <year>2014</year>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/978-1-4939-0847-9_16</pub-id><pub-id pub-id-type="pmid">24870142</pub-id></mixed-citation></ref><ref id="pone.0282882.ref019"><label>19</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Wu</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Roberts</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Datta</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Du</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Ji</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Si</surname><given-names>Y</given-names></name>, <etal>et al</etal>. <article-title>Deep learning in clinical natural language processing: a methodological review</article-title>. <source>Journal of the American Medical Informatics Association</source>. <year>2020</year>;<volume>27</volume>(<issue>3</issue>):<fpage>457</fpage>&#8211;<lpage>470</lpage>.<pub-id pub-id-type="pmid">31794016</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/jamia/ocz200</pub-id><pub-id pub-id-type="pmcid">PMC7025365</pub-id></mixed-citation></ref><ref id="pone.0282882.ref020"><label>20</label><mixed-citation publication-type="journal"><collab>Cambria E and White Bebo</collab>. <article-title>Jumping NLP curves: a review of natural language processing research.</article-title><source>IEEE Computational Intelligence Magazine</source>, p. <fpage>48</fpage>&#8211;<lpage>57</lpage>, <month>May</month><year>2014</year>.</mixed-citation></ref><ref id="pone.0282882.ref021"><label>21</label><mixed-citation publication-type="other">Bender EM and Koller A. Climbing toward NLU: on meaning, form, and understanding in the age of data. In: Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics; 2020 July 5&#8211;10, Virtual meeting. 2020. p. 5185&#8211;5198.</mixed-citation></ref><ref id="pone.0282882.ref022"><label>22</label><mixed-citation publication-type="other">Bisk Y, Holtzman A, Thomason J, Andreas J, Bengio Y, Chai J, et al. Experience grounds language. In: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, 2020 Nov 16&#8211;20, Association for Computational Linguistics; 2020. p. 8718&#8211;8735.</mixed-citation></ref><ref id="pone.0282882.ref023"><label>23</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Lewis</surname><given-names>AG</given-names></name> and <name name-style="western"><surname>Bastiaansen</surname><given-names>M</given-names></name>. <article-title>A predictive coding framework for rapid neural dynamics during sentence-level language comprehension.</article-title><source>Cortex</source>. <year>2015</year>;<volume>68</volume>:<fpage>155</fpage>&#8211;<lpage>168</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.cortex.2015.02.014</pub-id><pub-id pub-id-type="pmid">25840879</pub-id></mixed-citation></ref><ref id="pone.0282882.ref024"><label>24</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Fujii</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Maesawa</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Ishiai</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Iwami</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Futamura</surname><given-names>M</given-names></name>, and <name name-style="western"><surname>Saito</surname><given-names>K</given-names></name>. <article-title>Neural basis of language: an overview of an evolving model.</article-title><source>Neurologia Medico-Chirurgica (Tokyo).</source><year>2016</year>;<volume>56</volume>(<issue>7</issue>):<fpage>379</fpage>&#8211;<lpage>386</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2176/nmc.ra.2016-0014</pub-id><pub-id pub-id-type="pmid">27087195</pub-id><pub-id pub-id-type="pmcid">PMC4945596</pub-id></mixed-citation></ref><ref id="pone.0282882.ref025"><label>25</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Huth</surname><given-names>AG</given-names></name>, <name name-style="western"><surname>Nishimoto</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Vu</surname><given-names>AT</given-names></name>, and <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name>. <article-title>A continuous semantic space describes the representation for thousands of objects and action categories across the human brain</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>76</volume>(<issue>6</issue>):<fpage>1210</fpage>&#8211;<lpage>1224</lpage>.<pub-id pub-id-type="pmid">23259955</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuron.2012.10.014</pub-id><pub-id pub-id-type="pmcid">PMC3556488</pub-id></mixed-citation></ref><ref id="pone.0282882.ref026"><label>26</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Zentall</surname><given-names>TR</given-names></name>, <name name-style="western"><surname>Wasserman</surname><given-names>EA</given-names></name>, and <name name-style="western"><surname>Urcuioli</surname><given-names>PJ</given-names></name>. <article-title>Associative concept learning in animals</article-title>. <source>Journal of Experimental Analysis of Behavior</source>. <year>2014</year>;<volume>101</volume>(<issue>1</issue>):<fpage>130</fpage>&#8211;<lpage>151</lpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/jeab.55</pub-id><pub-id pub-id-type="pmcid">PMC3927728</pub-id><pub-id pub-id-type="pmid">24170540</pub-id></mixed-citation></ref><ref id="pone.0282882.ref027"><label>27</label><mixed-citation publication-type="book"><name name-style="western"><surname>Elman</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Bates</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>MH</given-names></name>, <name name-style="western"><surname>Karmiloff-Smith</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Parisi</surname><given-names>D</given-names></name>, and <name name-style="western"><surname>Plunkett</surname><given-names>K</given-names></name>. <source>Rethinking innateness</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press;</publisher-name><year>1996</year>.</mixed-citation></ref><ref id="pone.0282882.ref028"><label>28</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Tomasello</surname><given-names>M.</given-names></name><article-title>Do young children have adult syntactic competence?</article-title><source>Cognition</source>. <year>2000</year>;<volume>74</volume>:<fpage>209</fpage>&#8211;<lpage>253</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/s0010-0277(99)00069-4</pub-id><pub-id pub-id-type="pmid">10640571</pub-id></mixed-citation></ref><ref id="pone.0282882.ref029"><label>29</label><mixed-citation publication-type="other">Happel H-J and Seedorf, Applications of ontologies in software engineering. In: Kendall EF, Oberle D, Pan JZ, Tetlow P, Sabbouh M, and Knublauch H, editors. Proceedings of the 2nd International Workshop on Semantic Web Enabled Software Engineering / 5th International Semantic Web Conference; 2006 Nov 5&#8211;9; Athens, Georgia, USA. 2006. p. 5&#8211;9.</mixed-citation></ref><ref id="pone.0282882.ref030"><label>30</label><mixed-citation publication-type="other">Blaisure JC and Ceusters W. Improving the &#8216;Fitness for Purpose&#8217; of common data models through realism based ontology. In: Proceedings of the American Medical Informatics Association; 2017 Nov 4&#8211;7; Washington DC, USA. 2017. p. 440&#8211;447.<pub-id pub-id-type="pmcid">PMC5977618</pub-id><pub-id pub-id-type="pmid">29854108</pub-id></mixed-citation></ref><ref id="pone.0282882.ref031"><label>31</label><mixed-citation publication-type="book"><name name-style="western"><surname>Montague</surname><given-names>R.</given-names></name><source>Formal philosophy, selected papers of Richard Montague</source>. <publisher-loc>New Haven</publisher-loc>: <publisher-name>Yale University Press;</publisher-name><year>1974</year>.<volume>6</volume></mixed-citation></ref><ref id="pone.0282882.ref032"><label>32</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Partee</surname><given-names>BH</given-names></name>. <article-title>Formal semantics: Origins, issues, early impact.</article-title><source>Baltic International Yearbook of Cognition, Logic and Communication.</source><year>2011</year>;<volume>6</volume>:<fpage>1</fpage>&#8211;<lpage>52</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref033"><label>33</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Hinton</surname><given-names>GE</given-names></name>. <article-title>Learning multiple layers of representation.</article-title><source>Trends in Cognitive Sciences</source>. <year>2007</year>;<volume>11</volume>(<issue>10</issue>):<fpage>428</fpage>&#8211;<lpage>434</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.tics.2007.09.004</pub-id><pub-id pub-id-type="pmid">17921042</pub-id></mixed-citation></ref><ref id="pone.0282882.ref034"><label>34</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Budiu</surname><given-names>R.</given-names></name><article-title>Interpretation-based processing: a unified theory of semantic sentence comprehension</article-title>. <source>Cognitive Science</source>. <year>2004</year>;<volume>28</volume>(<issue>1</issue>):<fpage>1</fpage>&#8211;<lpage>44</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref035"><label>35</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Tenenbaum</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Kemp</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Griffiths</surname><given-names>TL</given-names></name>, and <name name-style="western"><surname>Goodman</surname><given-names>ND</given-names></name>. <article-title>How to grow a mind: statistics, structure, and abstraction</article-title>. <source>Science</source>. <year>2011</year>;<volume>331</volume>:<fpage>1279</fpage>&#8211;<lpage>1285</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1126/science.1192788</pub-id><pub-id pub-id-type="pmid">21393536</pub-id></mixed-citation></ref><ref id="pone.0282882.ref036"><label>36</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Bahlmann</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Schubotz</surname><given-names>RI</given-names></name>, and <name name-style="western"><surname>Friederici</surname><given-names>AD</given-names></name>. <article-title>Hierarchical artificial grammar processing engages Broca&#8217;s area.</article-title><source>NeuroImage</source>. <year>2008</year>;<volume>42</volume>:<fpage>525</fpage>&#8211;<lpage>534</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.04.249</pub-id><pub-id pub-id-type="pmid">18554927</pub-id></mixed-citation></ref><ref id="pone.0282882.ref037"><label>37</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Waterfall</surname><given-names>HR</given-names></name>, <name name-style="western"><surname>Sandbank</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Onnis</surname><given-names>L</given-names></name>, and <name name-style="western"><surname>Edelman</surname><given-names>S</given-names></name>. <article-title>An empirical generative framework for computational modeling of language acquisition</article-title>. <source>Journal of Child Language</source>. <year>2010</year>;<volume>37</volume>:<fpage>671</fpage>&#8211;<lpage>703</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1017/S0305000910000024</pub-id><pub-id pub-id-type="pmid">20420744</pub-id></mixed-citation></ref><ref id="pone.0282882.ref038"><label>38</label><mixed-citation publication-type="other">Ettinger A, Elgohary A, and Resnik P. Probing for semantic evidence of composition by means of simple classification tasks. In: Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP; 2016 Aug 7&#8211;12, Berlin, Germany. Association for Computational Linguistics; 2016. p. 134&#8211;139.</mixed-citation></ref><ref id="pone.0282882.ref039"><label>39</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Anderson</surname><given-names>JR</given-names></name>. <article-title>A spreading activation theory of memory</article-title>. <source>Journal of Verbal Learning and Verbal Behavior</source>. <year>1983</year>;<volume>22</volume>:<fpage>261</fpage>&#8211;<lpage>295</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref040"><label>40</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Collins</surname><given-names>AM</given-names></name> and <name name-style="western"><surname>Loftus</surname><given-names>EF</given-names></name>. <article-title>A spreading-activation theory of semantic processing.</article-title><source>Psychological Review</source>. <year>1975</year>;<volume>82</volume>(<issue>6</issue>):<fpage>407</fpage>&#8211;<lpage>428</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref041"><label>41</label><mixed-citation publication-type="book"><name name-style="western"><surname>Quillian</surname><given-names>RM</given-names></name>. <part-title>Semantic memory</part-title>. In: <name name-style="western"><surname>Minsky</surname><given-names>M</given-names></name>, editor. <source>Semantic information processing.</source><publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press;</publisher-name><year>1968</year>. p. <fpage>227</fpage>&#8211;<lpage>270</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref042"><label>42</label><mixed-citation publication-type="book"><name name-style="western"><surname>Brinton</surname><given-names>LJ</given-names></name>. <part-title>The structure of modern English: A linguistic introduction</part-title>. <source>Illustrated edition</source>. <publisher-name>John Benjamins Publishing Company;</publisher-name><year>2000</year>. p. <fpage>112</fpage>.</mixed-citation></ref><ref id="pone.0282882.ref043"><label>43</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Ouellette</surname><given-names>J.</given-names></name><article-title>Sand pile model of the mind grows in popularity</article-title>. <source>Quanta Magazine</source>. <year>2014</year><month>April</month><day>7</day>.</mixed-citation></ref><ref id="pone.0282882.ref044"><label>44</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Lee</surname><given-names>TS</given-names></name> and <name name-style="western"><surname>Mumford</surname><given-names>D</given-names></name>. <article-title>Hierarchical Bayesian inference in the visual cortex</article-title>. <source>Journal of the Optical Society of America</source>. <year>2003</year>;<volume>20</volume>(<issue>7</issue>):<fpage>1434</fpage>&#8211;<lpage>1448</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1364/josaa.20.001434</pub-id><pub-id pub-id-type="pmid">12868647</pub-id></mixed-citation></ref><ref id="pone.0282882.ref045"><label>45</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Willems</surname><given-names>RM</given-names></name>, <name name-style="western"><surname>Frank</surname><given-names>SL</given-names></name>, <name name-style="western"><surname>Nijhof</surname><given-names>AD</given-names></name>, <name name-style="western"><surname>Hagoort</surname><given-names>P</given-names></name>, and <name name-style="western"><surname>van den Bosch</surname><given-names>A</given-names></name>. <article-title>Prediction during natural language comprehension</article-title>. <source>Cerebral Cortex</source>. <year>2016</year>;<volume>26</volume>:<fpage>2506</fpage>&#8211;<lpage>2516</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/cercor/bhv075</pub-id><pub-id pub-id-type="pmid">25903464</pub-id></mixed-citation></ref><ref id="pone.0282882.ref046"><label>46</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Efron</surname><given-names>B.</given-names></name><article-title>Empirical Bayes methods for combining likelihoods</article-title>. <source>Journal of the American Statistical Association</source>. <year>2006</year>;<volume>91</volume>(<issue>434</issue>):<fpage>538</fpage>&#8211;<lpage>550</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref047"><label>47</label><mixed-citation publication-type="other">Halle M and Stevens K. Analysis by synthesis. In: W. Wathen-Dunn W, Woods LE, editors. Proceedings of the Seminar on Speech Compression and Processing. USAF Camb. Res. Ctr. 1959;2: paper D7.</mixed-citation></ref><ref id="pone.0282882.ref048"><label>48</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Yuille</surname><given-names>A</given-names></name> and <name name-style="western"><surname>Kersten</surname><given-names>D</given-names></name>. <article-title>Vision as Bayesian inference: analysis by synthesis?</article-title><source>Trends in Cognitive Science</source>. <year>2006</year>;<volume>10</volume>(<issue>7</issue>):<fpage>302</fpage>&#8211;<lpage>308</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.tics.2006.05.002</pub-id><pub-id pub-id-type="pmid">16784882</pub-id></mixed-citation></ref><ref id="pone.0282882.ref049"><label>49</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Chater</surname><given-names>N</given-names></name> and <name name-style="western"><surname>Manning</surname><given-names>CD</given-names></name>. <article-title>Probabilistic models of language processing and acquisition</article-title>. <source>Trends in Cognitive Science</source>. <year>2006</year>;<volume>10</volume>(<issue>7</issue>):<fpage>335</fpage>&#8211;<lpage>344</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.tics.2006.05.006</pub-id><pub-id pub-id-type="pmid">16784883</pub-id></mixed-citation></ref><ref id="pone.0282882.ref050"><label>50</label><mixed-citation publication-type="book"><name name-style="western"><surname>Mumford</surname><given-names>D.</given-names></name><part-title>Pattern theory: A unifying perspective</part-title>. In: <name name-style="western"><surname>Joseph</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Mignot</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Murat</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Prum</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Rentschler</surname><given-names>R</given-names></name>. editors. <source>First European Congress of Mathematics. Progress in Mathematics</source>, vol <volume>3</volume>. <publisher-loc>Basel, Switzerland</publisher-loc>: <publisher-name>Birkh&#228;user</publisher-name>; <year>1994</year>.</mixed-citation></ref><ref id="pone.0282882.ref051"><label>51</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Hobbs</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Stickel</surname><given-names>ME</given-names></name>, <name name-style="western"><surname>Appelet</surname><given-names>DE</given-names></name>, and <name name-style="western"><surname>Martin</surname><given-names>P</given-names></name>. <article-title>Interpretation as abduction</article-title>. <source>Artificial Intelligence</source>. <year>1993</year>;<volume>63</volume>(<issue>1&#8211;2</issue>):<fpage>69</fpage>&#8211;<lpage>142</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref052"><label>52</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Rao</surname><given-names>RPN</given-names></name> and <name name-style="western"><surname>Ballard</surname><given-names>DH</given-names></name>. <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive field effects</article-title>. <source>Nature Neuroscience</source>. <year>1999</year>;<volume>2</volume>:<fpage>79</fpage>&#8211;<lpage>87</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/4580</pub-id><pub-id pub-id-type="pmid">10195184</pub-id></mixed-citation></ref><ref id="pone.0282882.ref053"><label>53</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Friston</surname><given-names>K.</given-names></name><article-title>Learning and inference in the brain</article-title>. <source>Neural Network</source>. <year>2003</year>;<volume>16</volume>:<fpage>1325</fpage>&#8211;<lpage>1352</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neunet.2003.06.005</pub-id><pub-id pub-id-type="pmid">14622888</pub-id></mixed-citation></ref><ref id="pone.0282882.ref054"><label>54</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Friston</surname><given-names>K.</given-names></name><article-title>The history of the future of the Bayesian brain</article-title>. <source>NeuroImage</source>. <year>2012</year>;<volume>62</volume>:<fpage>1230</fpage>&#8211;<lpage>1233</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.10.004</pub-id><pub-id pub-id-type="pmid">22023743</pub-id><pub-id pub-id-type="pmcid">PMC3480649</pub-id></mixed-citation></ref><ref id="pone.0282882.ref055"><label>55</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Friston</surname><given-names>K.</given-names></name><article-title>Does predictive coding have a future?</article-title><source>Nature Neuroscience</source>. <year>2018</year>;<volume>21</volume>:<fpage>1019</fpage>&#8211;<lpage>1026</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41593-018-0200-7</pub-id><pub-id pub-id-type="pmid">30038278</pub-id></mixed-citation></ref><ref id="pone.0282882.ref056"><label>56</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Smith</surname><given-names>B</given-names></name> and <name name-style="western"><surname>Brochhausen</surname><given-names>M</given-names></name>. <article-title>Putting biomedical ontologies to work</article-title>. <source>Methods of Information in Medicine</source>. <year>2010</year>;<volume>49</volume>(<issue>2</issue>):<fpage>135</fpage>&#8211;<lpage>140</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3414/ME9302</pub-id><pub-id pub-id-type="pmid">20135080</pub-id><pub-id pub-id-type="pmcid">PMC3116518</pub-id></mixed-citation></ref><ref id="pone.0282882.ref057"><label>57</label><mixed-citation publication-type="book"><name name-style="western"><surname>Marr</surname><given-names>D.</given-names></name><source>Vision: A computational investigation into the human representation and processing of visual information</source>. <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>WH Freeman;</publisher-name><year>1982</year>.</mixed-citation></ref><ref id="pone.0282882.ref058"><label>58</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Taira</surname><given-names>RK</given-names></name> and <name name-style="western"><surname>Arnold</surname><given-names>CW</given-names></name>. <article-title>Hierarchical semantic structures for medical NLP.</article-title><source>Studies in Health Technology and Informatics</source>. <year>2013</year>;<volume>192</volume>:<fpage>1194</fpage>. <pub-id pub-id-type="pmid">23920968</pub-id></mixed-citation></ref><ref id="pone.0282882.ref059"><label>59</label><mixed-citation publication-type="book"><name name-style="western"><surname>Martin</surname><given-names>J.</given-names></name><source>System design from provably correct constructs</source>. <publisher-loc>New Jersey</publisher-loc>: <publisher-name>Prentice-Hall, Inc., Englewood Cliffs;</publisher-name><year>1985</year>.</mixed-citation></ref><ref id="pone.0282882.ref060"><label>60</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Palmer</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Gildea</surname><given-names>D</given-names></name>, and <name name-style="western"><surname>Kingsbury</surname><given-names>P</given-names></name>. <article-title>The Proposition Bank: An annotated corpus of semantic roles.</article-title><source>Computational Linguistics.</source><year>2005</year>;<volume>31</volume>(<issue>1</issue>):<fpage>71</fpage>&#8211;<lpage>106</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref061"><label>61</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Wu</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kaggal</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Dligach</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Masanz</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Becker</surname><given-names>L</given-names></name>, <etal>et al</etal>. <article-title>A common type system for clinical natural language processing</article-title>. <source>Journal of Biomedical Semantics</source>. <year>2013</year>;<volume>4</volume>(<issue>1</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/2041-1480-4-1</pub-id><pub-id pub-id-type="pmid">23286462</pub-id><pub-id pub-id-type="pmcid">PMC3575354</pub-id></mixed-citation></ref><ref id="pone.0282882.ref062"><label>62</label><mixed-citation publication-type="other">Banarescu L, Bonial C, Cai S, Georgescu M, Griffitt K, Hermjakob, U, et al. Abstract meaning representation for Sembanking. In: Pareja-Lora A, Liakata M, and Dipper S editors. In: Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse; 2013 Aug 8&#8211;9; Sofia, Bulgaria. Association for Computational Linguistics; 2013. p. 178&#8211;186.</mixed-citation></ref><ref id="pone.0282882.ref063"><label>63</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Baneyx</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Charlet</surname><given-names>J</given-names></name>, and <name name-style="western"><surname>Jaulent</surname><given-names>M-C</given-names></name>. <article-title>Building an ontology of pulmonary disease with natural language processing tools using tectual corpora.</article-title><source>Int J. Medical Informatics</source>. <year>2007</year>:<volume>76</volume>(<issue>203</issue>):<fpage>208</fpage>&#8211;<lpage>215</lpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.ijmedinf.2006.05.031</pub-id><pub-id pub-id-type="pmid">16797227</pub-id></mixed-citation></ref><ref id="pone.0282882.ref064"><label>64</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Doing-Harris</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Livnat</surname><given-names>Y</given-names></name>, and <name name-style="western"><surname>Meystre</surname><given-names>S</given-names></name>. <article-title>Automated concept and relationship extraction for the semi-automated ontology management (SEAM) system.</article-title><source>J. Biomedical Semantics</source>. <year>2015</year>;<volume>6</volume>:<fpage>15</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s13326-015-0011-7</pub-id><pub-id pub-id-type="pmid">25874077</pub-id><pub-id pub-id-type="pmcid">PMC4396714</pub-id></mixed-citation></ref><ref id="pone.0282882.ref065"><label>65</label><mixed-citation publication-type="other">Lossio-Ventura JA, Hogan W, Modave F, Hicks A, Hanna J, Guo Y, et al. Towards an obesity-cancer knoweldge base: biomedical entity identification and relation detection. In: Proceedings of the IEEE International Conference on Bioinformatics and Biomedicine. 2016 Dec 15&#8211;18; Shenzhen, China. 2016. p. 1081&#8211;1088.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/BIBM.2016.7822672</pub-id><pub-id pub-id-type="pmcid">PMC5426361</pub-id><pub-id pub-id-type="pmid">28503356</pub-id></mixed-citation></ref><ref id="pone.0282882.ref066"><label>66</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Wattarujeekrit</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Shah</surname><given-names>PK</given-names></name>, and <name name-style="western"><surname>Collier</surname><given-names>N</given-names></name>. <article-title>PASBio: predicate-argument structures or event extraction in molecular biology</article-title>. <source>BMC Bioinformatics</source>. <year>2004</year>;<volume>5</volume>:<fpage>155</fpage>.<pub-id pub-id-type="pmid">15494078</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1186/1471-2105-5-155</pub-id><pub-id pub-id-type="pmcid">PMC535924</pub-id></mixed-citation></ref><ref id="pone.0282882.ref067"><label>67</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Rimell</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Lippincott</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Verspoor</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>HL</given-names></name>, and <name name-style="western"><surname>Korhonen</surname><given-names>A</given-names></name>. <article-title>Acquisition and evaluation of verb subcategorization resporces for biomedicine.</article-title><source>J Biomedical Informatics</source>. <year>2013</year>;<volume>46</volume>(<issue>2</issue>):<fpage>228</fpage>&#8211;<lpage>237</lpage>.<pub-id pub-id-type="pmid">23347886</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.jbi.2013.01.001</pub-id></mixed-citation></ref><ref id="pone.0282882.ref068"><label>68</label><mixed-citation publication-type="book"><name name-style="western"><surname>Cresswell</surname><given-names>M.</given-names></name><source>Logics and languages</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Methuen</publisher-name>; <year>1973</year>.</mixed-citation></ref><ref id="pone.0282882.ref069"><label>69</label><mixed-citation publication-type="book"><name name-style="western"><surname>Fodor</surname><given-names>J</given-names></name> and <name name-style="western"><surname>LePore</surname><given-names>E</given-names></name>. <source>Holism: A shopper&#8217;s guide</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Blackwell;</publisher-name><year>1992</year>.</mixed-citation></ref><ref id="pone.0282882.ref070"><label>70</label><mixed-citation publication-type="other">Dridan R and Oepen S. Tokenization: returning to a long solved problem a survey, contrastive experiment, recommendations, and toolkit, In: Li H, Lin C-Y, Osborne M, Lee GG, Park JC, editors. Proceedings of the 50<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers); 2012 Jul 8&#8211;14; Jeju Island, South Korea. Association for Computational Linguistics; 2012. p. 378&#8211;382.</mixed-citation></ref><ref id="pone.0282882.ref071"><label>71</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Taira</surname><given-names>RK</given-names></name>, <name name-style="western"><surname>Soderland</surname><given-names>S</given-names></name> and <name name-style="western"><surname>Jakobovits</surname><given-names>R</given-names></name>. <article-title>Automatic structuring of radiology free text reports.</article-title><source>Radiographics</source>. <year>2001</year>;<volume>21</volume>:<fpage>237</fpage>&#8211;<lpage>245</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1148/radiographics.21.1.g01ja18237</pub-id><pub-id pub-id-type="pmid">11158658</pub-id></mixed-citation></ref><ref id="pone.0282882.ref072"><label>72</label><mixed-citation publication-type="other">Wermter J and Hahn U. You can&#8217;t beat frequency (unless you use linguistic knowledge)&#8211;a qualitative evaluation of association measures for collocation and term extraction, In: Calzolari N, Cardie C, Isabelle P, editors. Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics; 2006 Jul 17&#8211;21; Sydney, Australia. Association for Computational Linguistics; 2006. p. 785&#8211;792.</mixed-citation></ref><ref id="pone.0282882.ref073"><label>73</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Bui</surname><given-names>AAT</given-names></name>, <name name-style="western"><surname>Aberle</surname><given-names>DR</given-names></name>, and <name name-style="western"><surname>Kangarloo</surname><given-names>H</given-names></name>. <article-title>TimeLine: Visualizing integrated patient records</article-title>. <source>IEEE Transactions on Information Technology in Biomedicine</source>. <year>2007</year>;<volume>11</volume>(<issue>4</issue>):<fpage>462</fpage>&#8211;<lpage>473</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/titb.2006.884365</pub-id><pub-id pub-id-type="pmid">17674629</pub-id></mixed-citation></ref><ref id="pone.0282882.ref074"><label>74</label><mixed-citation publication-type="book"><name name-style="western"><surname>Taira</surname><given-names>RK</given-names></name>. <part-title>Chapter 6: Natural Language Processing of Medical Reports</part-title>. In: <name name-style="western"><surname>Bui</surname><given-names>AAT</given-names></name>, <name name-style="western"><surname>Taira</surname><given-names>RK</given-names></name>, editors. <source>Medical imaging informatics</source>. <publisher-loc>New York, Dordrecht, Heidelberg, London</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2010</year>.</mixed-citation></ref><ref id="pone.0282882.ref075"><label>75</label><mixed-citation publication-type="book"><name name-style="western"><surname>Pearl</surname><given-names>J</given-names></name> and <name name-style="western"><surname>Mackenzie</surname><given-names>D</given-names></name>. <source>The Book of Why</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Basic Books</publisher-name>; <year>2018</year>.</mixed-citation></ref><ref id="pone.0282882.ref076"><label>76</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Lindeberg</surname><given-names>T.</given-names></name><article-title>Scale-space theory: a basic tool for analyzing structures at different scales</article-title>. <source>Journal of Applied Statistics</source>. <year>1994</year>;<volume>21</volume>(<issue>1&#8211;2</issue>):<fpage>225</fpage>&#8211;<lpage>270</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref077"><label>77</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Duch</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Matykiewicz</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Pestian</surname><given-names>J</given-names></name>. <article-title>Neurolinguistic apporoach to natural language processing with applications to medical text analysis.</article-title><source>Neural Networks</source>. <year>2008</year>;<volume>21</volume>(<issue>10</issue>):<fpage>1500</fpage>&#8211;<lpage>1510</lpage>.<pub-id pub-id-type="pmid">18614334</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neunet.2008.05.008</pub-id><pub-id pub-id-type="pmcid">PMC2633093</pub-id></mixed-citation></ref><ref id="pone.0282882.ref078"><label>78</label><mixed-citation publication-type="other">Taira RK, Ogunyemi L, and Kim H. Lexically grounded ontologic frames for medical NLP, In: Proceedings of the American Medical Informatics Association Annual Symposium; 2018 Nov 3&#8211;7; San Francisco, CA. American Medical Informatics Association; 2018. p. 2171.</mixed-citation></ref><ref id="pone.0282882.ref079"><label>79</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Barzilay</surname><given-names>R</given-names></name> and <name name-style="western"><surname>Lapata</surname><given-names>M</given-names></name>. <article-title>Modeling local coherence: an entity-based approach.</article-title><source>Computational Linguistics</source>. <year>2008</year>;<volume>34</volume>(<issue>1</issue>):<fpage>1</fpage>&#8211;<lpage>34</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref080"><label>80</label><mixed-citation publication-type="other">Schank RC and Abelson RP. Scripts, plans, and knowledge. In: Proceedings of the 4<sup>th</sup> International Joint Conference on Artificial Intelligence, Volume 1; 1975 Sept 13&#8211;18; Tbilisi Georgia, USSR. San Francisco CA: Morgan Kaufmann; 1975. p. 151&#8211;157.</mixed-citation></ref><ref id="pone.0282882.ref081"><label>81</label><mixed-citation publication-type="book"><name name-style="western"><surname>Minsky</surname><given-names>M.</given-names></name><part-title>A framework for representing knowledge</part-title>, In: <name name-style="western"><surname>Winston</surname><given-names>P</given-names></name>, editor. <source>The psychology of computer vision</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>; <year>1975</year>.</mixed-citation></ref><ref id="pone.0282882.ref082"><label>82</label><mixed-citation publication-type="other">Fillmore CJ. Frame semantics and the nature of language. In: Annals of the New York Academy of Sciences: Conference on the Origin and Development of Language and Speech, 1976;280:20&#8211;32.</mixed-citation></ref><ref id="pone.0282882.ref083"><label>83</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Traxler</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Foss</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Seely</surname><given-names>RE</given-names></name>, <name name-style="western"><surname>Kaup</surname><given-names>B</given-names></name>, and <name name-style="western"><surname>Morris</surname><given-names>RK</given-names></name>. <article-title>Priming in sentence processing: intralexical spreading activation, schemas, and situation models</article-title>. <source>Journal of Psycholinguistics Research</source>. <year>2000</year>;<volume>29</volume>(<issue>6</issue>):<fpage>581</fpage>&#8211;<lpage>595</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1023/a:1026416225168</pub-id><pub-id pub-id-type="pmid">11196064</pub-id></mixed-citation></ref><ref id="pone.0282882.ref084"><label>84</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Lederman</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Lederman</surname><given-names>R</given-names></name> and <name name-style="western"><surname>Verspoor</surname><given-names>K</given-names></name>. <article-title>Tasks as needs: reframing the paradigm of clinical natural language processing research for real-world decision support</article-title>. <source>Journal of the American Medical Informatics Association</source>. <year>2022</year>;<volume>29</volume>(<issue>10</issue>):<fpage>1810</fpage>&#8211;<lpage>1817</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/jamia/ocac121</pub-id><pub-id pub-id-type="pmid">35848784</pub-id><pub-id pub-id-type="pmcid">PMC9471702</pub-id></mixed-citation></ref><ref id="pone.0282882.ref085"><label>85</label><mixed-citation publication-type="other">Dunietz J, Burnham G, Bharadwaj A, Rambow O, Chu-Carroll J, and Ferrucci D. To test machine comprehension, start by defining comprehension. In: Proceedings of the 58<sup>th</sup> Annual Meeting of the Association for Computational Linguistics, 2020 July; Association for Computational Linguistics; 2020. p. 7839&#8211;7859.</mixed-citation></ref><ref id="pone.0282882.ref086"><label>86</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Dunietz</surname><given-names>J.</given-names></name><article-title>The field of natural language processing is chasing the wrong goal</article-title>. <source>MIT Technology Review</source>. <month>July</month>, <day>31</day>, <year>2020</year>.</mixed-citation></ref><ref id="pone.0282882.ref087"><label>87</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Rastegar-Mojarad</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Moon</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Shen</surname><given-names>F</given-names></name>, <etal>et al</etal>. <article-title>Clinical information extraction applications: A literature review</article-title>. <source>Journal of Biomedical Informatics</source>. <year>2018</year>;<volume>77</volume>:<fpage>34</fpage>&#8211;<lpage>49</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jbi.2017.11.011</pub-id><pub-id pub-id-type="pmid">29162496</pub-id><pub-id pub-id-type="pmcid">PMC5771858</pub-id></mixed-citation></ref><ref id="pone.0282882.ref088"><label>88</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Palmer</surname><given-names>EL</given-names></name>, <name name-style="western"><surname>Hassanpour</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Higgins</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Doherty</surname><given-names>JA</given-names></name> and <name name-style="western"><surname>Oriega</surname><given-names>T</given-names></name>. <article-title>Building a tobacco user registry by extracting multiple smoking behaviors from clinical notes.</article-title><source>BMC Medical Informatics and Decision Making</source>. <year>2019</year>;<volume>19</volume>:<fpage>143</fpage>.<pub-id pub-id-type="pmid">31340796</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1186/s12911-019-0863-3</pub-id><pub-id pub-id-type="pmcid">PMC6657102</pub-id></mixed-citation></ref><ref id="pone.0282882.ref089"><label>89</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Shoenbill</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Song</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Gress</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>M</given-names></name>, and <name name-style="western"><surname>Medonca</surname><given-names>EA</given-names></name>. <article-title>Natural language processing of lifestyle modification documentation</article-title>. <source>Health Informatics Journal</source>. <year>2020</year>;<volume>26</volume>(<issue>1</issue>): <fpage>388</fpage>&#8211;<lpage>405</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1177/1460458218824742</pub-id><pub-id pub-id-type="pmid">30791802</pub-id><pub-id pub-id-type="pmcid">PMC6722039</pub-id></mixed-citation></ref><ref id="pone.0282882.ref090"><label>90</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Viani</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Botelle</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Kerwin</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Yin</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Patel</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Stewart</surname><given-names>R</given-names></name>, <etal>et al</etal>. <article-title>A natural language processing approach for identifying temporal disease onset information from mental heathcare text</article-title>. <source>Nature Scientific Reports</source>. <year>2021</year>;<volume>11</volume>:<fpage>757</fpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-020-80457-0</pub-id><pub-id pub-id-type="pmcid">PMC7804184</pub-id><pub-id pub-id-type="pmid">33436814</pub-id></mixed-citation></ref><ref id="pone.0282882.ref091"><label>91</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Savova</surname><given-names>GK</given-names></name>, <name name-style="western"><surname>Danciu</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Alamudun</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Miller</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Lin</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Bitterman</surname><given-names>DS</given-names></name>, <etal>et al</etal>. <article-title>Use of natural language processing to extract clinical cancer phenotypes from electronic medical records</article-title>. <source>Cancer Research</source>. <year>2019</year>;<volume>79</volume>(<issue>21</issue>):<fpage>5463</fpage>&#8211;<lpage>5470</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1158/0008-5472.CAN-19-0579</pub-id><pub-id pub-id-type="pmid">31395609</pub-id><pub-id pub-id-type="pmcid">PMC7227798</pub-id></mixed-citation></ref><ref id="pone.0282882.ref092"><label>92</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Johnson</surname><given-names>ML</given-names></name>, <name name-style="western"><surname>Blakemore</surname><given-names>BE</given-names></name>, <name name-style="western"><surname>Baxter</surname><given-names>TM</given-names></name>, <name name-style="western"><surname>Ashiq</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Moor</surname><given-names>SP</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>PG</given-names></name>, <etal>et al</etal>. <article-title>Natural language processing (NLP) software use in the discovery of incidental lung cancers.</article-title><source>Journal of Clinical Oncology</source>. <year>2016</year>;<volume>34</volume>(<issue>15 supplement</issue>):<fpage>1559</fpage>&#8211;<lpage>1559</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref093"><label>93</label><mixed-citation publication-type="other">Rubin D, Wang D, Chambers D, Chambers J, South B, and Goldstein M. Natural language processing for lines and devices in portable chest x-rays. In: Proceedings of the Annual Symposium of the American Medical Informatics Association; 2010 Nov 13&#8211;17; Washington DC, USA. 2010. p. 692&#8211;696.<pub-id pub-id-type="pmcid">PMC3041297</pub-id><pub-id pub-id-type="pmid">21347067</pub-id></mixed-citation></ref><ref id="pone.0282882.ref094"><label>94</label><mixed-citation publication-type="other">Langlotz CP. The radiology report: a guide to thoughtful communication for radiologists and other medical professionals. 2015, ISBN: 978&#8211;1515174080.</mixed-citation></ref><ref id="pone.0282882.ref095"><label>95</label><mixed-citation publication-type="book"><name name-style="western"><surname>McShane</surname><given-names>M</given-names></name> and <name name-style="western"><surname>Nirenburg</surname><given-names>S</given-names></name>. <source>Linguistics for the Age of AI</source>. <publisher-name>MIT Press;</publisher-name><year>2021</year>.</mixed-citation></ref><ref id="pone.0282882.ref096"><label>96</label><mixed-citation publication-type="book"><name name-style="western"><surname>Iwa&#324;ska</surname><given-names>LM</given-names></name> and <name name-style="western"><surname>Shapiro</surname><given-names>SC</given-names></name>, editors. <source>Natural Language Processing and Knowledge Representation: Language for Knowledge and Knowledge for Language</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press;</publisher-name><year>2000</year>.</mixed-citation></ref><ref id="pone.0282882.ref097"><label>97</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Dahl</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Tessaris</surname><given-names>S</given-names></name>, and <name name-style="western"><surname>De Sousa Bispo</surname><given-names>M</given-names></name>. <article-title>Parsing as semantically guided constraint solving: the role of ontologies</article-title>. <source>Annals of Mathematics and Artificial Intelligence</source><year>2018</year>;<volume>82</volume>:<fpage>161</fpage>&#8211;<lpage>185</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref098"><label>98</label><mixed-citation publication-type="book"><name name-style="western"><surname>Sickles</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>D&#8217;Orsi</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Bassett</surname><given-names>LW</given-names></name>, <etal>et al</etal>. <source>ACR BI-RADS<sup>&#174;</sup> Mammography. In: ACR BI-RADS<sup>&#174;</sup> Atlas, Breast Imaging Reporting and Data System</source>. <publisher-loc>Reston, VA</publisher-loc>, <publisher-name>American College of Radiology;</publisher-name><year>2013</year>.</mixed-citation></ref><ref id="pone.0282882.ref099"><label>99</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Schwartz</surname><given-names>LH</given-names></name>, <name name-style="western"><surname>Liti&#232;re</surname><given-names>S</given-names></name>, <name name-style="western"><surname>de Vries</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Ford</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Gwyther</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Mandrekar</surname><given-names>S</given-names></name>, <etal>et al</etal>. <article-title>RECIST 1.1-Update and clarification: From the RECIST committee</article-title>. <source>European Journal of Cancer</source>. <year>2016</year><month>Jul</month>;<volume>62</volume>:<fpage>132</fpage>&#8211;<lpage>7</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ejca.2016.03.081</pub-id> Epub 2016 May 14. ; PMCID: PMC5737828.<pub-id pub-id-type="pmid">27189322</pub-id><pub-id pub-id-type="pmcid">PMC5737828</pub-id></mixed-citation></ref><ref id="pone.0282882.ref100"><label>100</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Jonas</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Reuland</surname><given-names>DS</given-names></name>, <name name-style="western"><surname>Reddy</surname><given-names>SM</given-names></name>, <etal>et al</etal>. <source>Screening for Lung Cancer With Low-Dose Computed Tomography: An Evidence Review for the U.S. Preventive Services Task Force2020</source>,&#8221; <month>July</month><day>22th</day>, <year>2020</year>. Available online at: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.uspreventiveservicestaskforce.org/uspstf/document/draft-evidence-review/lung-cancer-screening-2020" ext-link-type="uri">https://www.uspreventiveservicestaskforce.org/uspstf/document/draft-evidence-review/lung-cancer-screening-2020</ext-link><pub-id pub-id-type="pmid">33750087</pub-id></mixed-citation></ref><ref id="pone.0282882.ref101"><label>101</label><mixed-citation publication-type="book"><name name-style="western"><surname>Rumelhart</surname><given-names>DE</given-names></name>. <source>Toward an Interactive Model of Reading. In: Theoretical Models and Processes of Reading.</source><publisher-loc>Newark, DE</publisher-loc>: <publisher-name>International Reading Association;</publisher-name><year>1977</year>. p. <fpage>722</fpage>&#8211;<lpage>750</lpage>. <pub-id pub-id-type="doi">10.1111/j.1540-4781.1989.tb05321.x</pub-id></mixed-citation></ref><ref id="pone.0282882.ref102"><label>102</label><mixed-citation publication-type="other">Stephens GJ, Silbert LJ, and Hasson U. Speaker-listener neural coupling underlies successful communication. Proceedings of the National Academy of Science. 2010;107(32):14425&#8211;14430.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1073/pnas.1008662107</pub-id><pub-id pub-id-type="pmcid">PMC2922522</pub-id><pub-id pub-id-type="pmid">20660768</pub-id></mixed-citation></ref><ref id="pone.0282882.ref103"><label>103</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Bueno</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Landeras</surname><given-names>L</given-names></name>, and <name name-style="western"><surname>Chung</surname><given-names>JH</given-names></name>. <article-title>Updated Fleischner Society guidelines for managing incidental pulmonary nodules: common questions and challenging scenarios.</article-title><source>RadioGraphics</source>. <year>2018</year>;<volume>38</volume>:<fpage>1137</fpage>&#8211;<lpage>1350</lpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1148/rg.2018180017</pub-id><pub-id pub-id-type="pmid">30207935</pub-id></mixed-citation></ref><ref id="pone.0282882.ref104"><label>104</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Rohde</surname><given-names>H</given-names></name> and <name name-style="western"><surname>Kurumada</surname><given-names>C</given-names></name>. <article-title>Alternatives and inferences in the communication of meaning.</article-title><source>Psychology of Learning and Motivation</source>. <year>2018</year>;<volume>68</volume>:<fpage>215</fpage>&#8211;<lpage>261</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref105"><label>105</label><mixed-citation publication-type="book"><name name-style="western"><surname>Lobner</surname><given-names>S.</given-names></name><source>Understanding Semantics.</source><publisher-loc>London</publisher-loc>: <publisher-name>Hodder Education</publisher-name>, <edition designator="2">2<sup>nd</sup> Edition</edition>; <year>2013</year>.</mixed-citation></ref><ref id="pone.0282882.ref106"><label>106</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Lourenco</surname><given-names>AP</given-names></name> and <name name-style="western"><surname>Baird</surname><given-names>GL</given-names></name>. <article-title>Optimizing radiology reports for patients and referring physicians: mitigating the curse of knowledge</article-title>. <source>Academic Radiology</source>. <year>2020</year>;<volume>27</volume>(<issue>3</issue>):<fpage>436</fpage>&#8211;<lpage>439</lpage>.<pub-id pub-id-type="pmid">31064727</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.acra.2019.03.026</pub-id></mixed-citation></ref><ref id="pone.0282882.ref107"><label>107</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Wright</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Jansen</surname><given-names>C</given-names></name>, and <name name-style="western"><surname>Wyatt</surname><given-names>J</given-names></name>. <article-title>How to limit clinical errors in interpretation of data</article-title>. <source>Lancet</source>. <year>1998</year>;<volume>352</volume>:<fpage>1539</fpage>&#8211;<lpage>43</lpage>.<pub-id pub-id-type="pmid">9820319</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/S0140-6736(98)08308-1</pub-id></mixed-citation></ref><ref id="pone.0282882.ref108"><label>108</label><mixed-citation publication-type="other">Codish S and Shiffman RN. A model of ambiguity and vagueness in clinical practice guideline recommendations. In: Proceedings of the American Medical Informatics Association Annual Fall Symposium; 2005 Oct 22&#8211;26; Washington, DC, USA. 2005. p. 146&#8211;50.<pub-id pub-id-type="pmcid">PMC1560665</pub-id><pub-id pub-id-type="pmid">16779019</pub-id></mixed-citation></ref><ref id="pone.0282882.ref109"><label>109</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Stallinga</surname><given-names>HA</given-names></name>, <name name-style="western"><surname>ten Napel</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Jansen</surname><given-names>GJ</given-names></name>, <name name-style="western"><surname>Geertzen</surname><given-names>JH</given-names></name>, <name name-style="western"><surname>de Vries Robb&#233;</surname><given-names>PF</given-names></name>, and <name name-style="western"><surname>Roodbol</surname><given-names>PF</given-names></name>. <article-title>Does language ambiguity in clinical practice justify the introduction of standard terminology? An integrative review</article-title>. <source>Journal of Clinical Nursing</source>. <year>2015</year>;<volume>24</volume>(<issue>3&#8211;4</issue>):<fpage>344</fpage>&#8211;<lpage>52</lpage>.<pub-id pub-id-type="pmid">24813851</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1111/jocn.12624</pub-id></mixed-citation></ref><ref id="pone.0282882.ref110"><label>110</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Sagi</surname><given-names>E</given-names></name> and <name name-style="western"><surname>Rips</surname><given-names>LJ</given-names></name>. <article-title>Identity, causality, and pronoun ambiguity</article-title>. <source>Topics in Cognitive Science</source>. <year>2014</year>;<volume>6</volume>:<fpage>663</fpage>&#8211;<lpage>680</lpage>.<pub-id pub-id-type="pmid">25131648</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1111/tops.12105</pub-id></mixed-citation></ref><ref id="pone.0282882.ref111"><label>111</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Uzuner</surname><given-names>&#214;</given-names></name>, <name name-style="western"><surname>Goldstein</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Luo</surname><given-names>Y</given-names></name>, and <name name-style="western"><surname>Kohane</surname><given-names>I</given-names></name>. <article-title>Identifying patient smoking status from medical discharge records</article-title>. <source>Journal of the American Medical Informatics Association</source>. <year>2008</year>;<volume>15</volume>(<issue>1</issue>):<fpage>15</fpage>&#8211;<lpage>24</lpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1197/jamia.M2408</pub-id><pub-id pub-id-type="pmcid">PMC2274873</pub-id><pub-id pub-id-type="pmid">17947624</pub-id></mixed-citation></ref><ref id="pone.0282882.ref112"><label>112</label><mixed-citation publication-type="book"><name name-style="western"><surname>Smith</surname><given-names>RA</given-names></name>, <name name-style="western"><surname>Andrews</surname><given-names>KS</given-names></name>, <name name-style="western"><surname>Brooks</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Fedewa</surname><given-names>SA</given-names></name>, <name name-style="western"><surname>Manassaram-Baptiste</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Saslow</surname><given-names>D</given-names></name>, <etal>et al</etal>. <source>Cancer screening in the United States, 2018: A review of current American Cancer Society guidelines and current issues in cancer screening.</source><publisher-loc>CA</publisher-loc>: <publisher-name>A Cancer Journal for Clinicians</publisher-name>. <year>2018</year>;<volume>68</volume>:<fpage>297</fpage>&#8211;<lpage>316</lpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.3322/caac.21446</pub-id><pub-id pub-id-type="pmid">29846940</pub-id></mixed-citation></ref><ref id="pone.0282882.ref113"><label>113</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Powsner</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Costa</surname><given-names>J</given-names></name>, and <name name-style="western"><surname>Homer</surname><given-names>RJ</given-names></name>. <article-title>Clinicians are from Mars and pathologists are from Venus.</article-title><source>Archives of Pathology &amp; Laboratory Medicine.</source><year>2000</year>;<volume>124</volume>(<issue>7</issue>):<fpage>1040</fpage>&#8211;<lpage>1046</lpage>.<pub-id pub-id-type="pmid">10888781</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.5858/2000-124-1040-CAFMAP</pub-id></mixed-citation></ref><ref id="pone.0282882.ref114"><label>114</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Kelly</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Karthikesalingam</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Suleyman</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Key challenges for delivering clinical impact with artificial intelligence</article-title>. <source>BMC Med</source><volume>17</volume>, <fpage>195</fpage> (<year>2019</year>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12916-019-1426-2</pub-id><pub-id pub-id-type="pmid">31665002</pub-id><pub-id pub-id-type="pmcid">PMC6821018</pub-id></mixed-citation></ref><ref id="pone.0282882.ref115"><label>115</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Fryback</surname><given-names>DG</given-names></name> and <name name-style="western"><surname>Thornbury</surname><given-names>JR</given-names></name>. <article-title>The efficacy of diagnostic imaging.</article-title><source>Medical Decision Making</source>. <year>1991</year>;<volume>11</volume>(<issue>2</issue>):<fpage>88</fpage>&#8211;<lpage>94</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1177/0272989X9101100203</pub-id><pub-id pub-id-type="pmid">1907710</pub-id></mixed-citation></ref><ref id="pone.0282882.ref116"><label>116</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Bae</surname><given-names>J-M</given-names></name>. <article-title>Value-based medicine: concepts and application.</article-title><source>Epidemiology and Health</source>. <year>2015</year>;<volume>37</volume>:<fpage>e2015014</fpage>, <lpage>5</lpage> pages. <comment>doi: </comment><pub-id pub-id-type="doi">10.4178/epih/e2015014</pub-id><pub-id pub-id-type="pmid">25773441</pub-id><pub-id pub-id-type="pmcid">PMC4398974</pub-id></mixed-citation></ref><ref id="pone.0282882.ref117"><label>117</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Park</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Jackson</surname><given-names>GP</given-names></name>, <name name-style="western"><surname>Foreman</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Gruen</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Hu</surname><given-names>J</given-names></name>, and <name name-style="western"><surname>Das</surname><given-names>AK</given-names></name>. <article-title>Evaluating artificial intelligence in medicine: phases of clinical research.</article-title><source>Journal of the American Medical Informatics Association Open.</source><year>2020</year>;<volume>3</volume>(<issue>3</issue>):<fpage>326</fpage>&#8211;<lpage>331</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/jamiaopen/ooaa033</pub-id><pub-id pub-id-type="pmid">33215066</pub-id><pub-id pub-id-type="pmcid">PMC7660958</pub-id></mixed-citation></ref><ref id="pone.0282882.ref118"><label>118</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Lebcir</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Hill</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Atun</surname><given-names>R</given-names></name>, and <name name-style="western"><surname>Cubric</surname><given-names>M</given-names></name>. <article-title>Stakeholders&#8217; views on the organizational factors affecting application of artificial intelligence in healthcare: a scoping review protocol.</article-title><source>BMJ Open</source>. <year>2021</year><month>Mar</month>;<day>22</day>;<volume>11</volume>(<issue>3</issue>):<fpage>e044074</fpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1136/bmjopen-2020-044074</pub-id><pub-id pub-id-type="pmcid">PMC7986948</pub-id><pub-id pub-id-type="pmid">33753441</pub-id></mixed-citation></ref><ref id="pone.0282882.ref119"><label>119</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Stevens</surname><given-names>KA</given-names></name>. <article-title>The vision of David Marr.</article-title><source>Perception</source>. <year>2012</year>;<volume>41</volume>:<fpage>1061</fpage>&#8211;<lpage>1072</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1068/p7297</pub-id><pub-id pub-id-type="pmid">23409372</pub-id></mixed-citation></ref><ref id="pone.0282882.ref120"><label>120</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Poggio</surname><given-names>T.</given-names></name><article-title>The levels of understanding framework, revised</article-title>. Perception. <year>2012</year>;<volume>41</volume>:<fpage>1017</fpage>&#8211;<lpage>1023</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1068/p7299</pub-id><pub-id pub-id-type="pmid">23409366</pub-id></mixed-citation></ref><ref id="pone.0282882.ref121"><label>121</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Smith</surname><given-names>B.</given-names></name><article-title>From concepts to clinical reality: an essay on the benchmarking of biomedical terminologies</article-title>. <source>Journal of Biomedical Informatics</source>. <year>2006</year>;<volume>39</volume>(<issue>3</issue>):<fpage>288</fpage>&#8211;<lpage>298</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jbi.2005.09.005</pub-id><pub-id pub-id-type="pmid">16293444</pub-id></mixed-citation></ref><ref id="pone.0282882.ref122"><label>122</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Chidamber</surname><given-names>SR</given-names></name>, <name name-style="western"><surname>Kemerer</surname><given-names>CF</given-names></name>. <article-title>A metrics suite for object oriented design</article-title>. <source>IEEE Transactions on Software Engineering</source>. <year>1994</year>;<volume>20</volume>(<issue>6</issue>):<fpage>476</fpage>&#8211;<lpage>493</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref123"><label>123</label><mixed-citation publication-type="other">Devlin J, Chang M.-W, Lee K, and Toutanova K. BERT: Pretraining of deep bidirectional transformers for language understanding, In: Burstein J, Doran C, Solorio T, editors. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers); Jun 2&#8211;7; Minneapolis, Minnesota. Association for Computational Linguistics; 2019. p. 4171&#8211;4186.</mixed-citation></ref><ref id="pone.0282882.ref124"><label>124</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Lee</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Yoon</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>S</given-names></name>, <name name-style="western"><surname>So</surname><given-names>CH</given-names></name>, <etal>et al</etal>. <article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics</source>. <year>2020</year>;<volume>36</volume>(<issue>4</issue>):<fpage>1234</fpage>&#8211;<lpage>1240</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz682</pub-id><pub-id pub-id-type="pmid">31501885</pub-id><pub-id pub-id-type="pmcid">PMC7703786</pub-id></mixed-citation></ref><ref id="pone.0282882.ref125"><label>125</label><mixed-citation publication-type="other">Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, et al. Attention is all you need. In: NIPS&#8217;17: Proceedings of the 31st International Conference on Neural Information Processing Systems, December 2017. p. 6000&#8211;6010.</mixed-citation></ref><ref id="pone.0282882.ref126"><label>126</label><mixed-citation publication-type="other">Tenney I, Das D, and Pavlick E. BERT rediscovers the classical NLP pipeline. In: Proceedings of the 57<sup>th</sup> Annual Meeting of the Association for Computational Linguistics; 2019 July 28-August 2; Florence, Italy. 2019. p. 4593&#8211;4601.</mixed-citation></ref><ref id="pone.0282882.ref127"><label>127</label><mixed-citation publication-type="other">Vincent P, Larochelle H, Bengio Y, and Manzagol P-A. Extracting and composing robust features with denoising autoencoders. In: Proceedings of the International Conference on Machine Learning; 2008 July 5&#8211;9; Helsinki, Finland. Association of Computing Machinery; 2008. p. 1096&#8211;1103.</mixed-citation></ref><ref id="pone.0282882.ref128"><label>128</label><mixed-citation publication-type="other">Kingma DP and Welling M. Auto-encoding variational Bayes. In: Proceedings of the International Conference on Learning Representations; 2014 April 14&#8211;16; Banff, Canada. 2014.</mixed-citation></ref><ref id="pone.0282882.ref129"><label>129</label><mixed-citation publication-type="book"><name name-style="western"><surname>D&#8217;Orsi</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Sickles</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>Mendelson</surname><given-names>EB</given-names></name>, <name name-style="western"><surname>Morris</surname><given-names>EA</given-names></name>, <etal>et al</etal>. <source>ACR BI-RADS<sup>&#174;</sup> Atlas, Breast Imaging Reporting and Data System.</source><publisher-loc>Reston, VA</publisher-loc>, <publisher-name>American College of Radiology</publisher-name>; <year>2013</year>.</mixed-citation></ref><ref id="pone.0282882.ref130"><label>130</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Geman</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Potter</surname><given-names>D</given-names></name>, and <name name-style="western"><surname>Chi</surname><given-names>Z</given-names></name>. <article-title>Composition systems.</article-title><source>Quarterly of Applied Mathematics</source>. <year>2002</year>;<volume>60</volume>(<issue>4</issue>):<fpage>707</fpage>&#8211;<lpage>736</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref131"><label>131</label><mixed-citation publication-type="other">Bender EM, Flickinger D, Oepen S, and Packard W. Layers of interpretation: on grammar and compositionality. In: Proceedings of the 11th International Conference on Computational Semantics; 2015 April 15&#8211;17; London, United Kingdom. 2015. p. 239&#8211;249.</mixed-citation></ref><ref id="pone.0282882.ref132"><label>132</label><mixed-citation publication-type="other">Yuille AL and Mottaghi R. (2013) Complexity of representation and inference in compositional models with part sharing. In: Proceedings of the 1st International Conference on Learning Representations; 2013 May 2&#8211;4; Scottsdale, Arizona. 2013. p. 1&#8211;13.</mixed-citation></ref><ref id="pone.0282882.ref133"><label>133</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Poggio</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Anselmi</surname><given-names>F</given-names></name>, and <name name-style="western"><surname>Rosasco</surname><given-names>L</given-names></name>. <article-title>I-theory on depth vs width: hierarchical functional composition. CBMM Memo 041, Center for Brains Minds and Machines</article-title>. <source>Massachusetts Institute of Technology</source>, <month>December</month><year>2015</year>.</mixed-citation></ref><ref id="pone.0282882.ref134"><label>134</label><mixed-citation publication-type="book"><name name-style="western"><surname>Barton</surname><given-names>EG</given-names></name>, <name name-style="western"><surname>Berwick</surname><given-names>RC</given-names></name>, and <name name-style="western"><surname>Ristad</surname><given-names>ES</given-names></name>. <part-title>Computational Complexity and Natural Language</part-title>. <source>Bradford Books</source>, <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press;</publisher-name><year>1987</year>.</mixed-citation></ref><ref id="pone.0282882.ref135"><label>135</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Friston</surname><given-names>K</given-names></name>, <name name-style="western"><surname>FitzGerald</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Rigoli</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Schwartenbeck</surname><given-names>P</given-names></name> and <name name-style="western"><surname>Pezzulo</surname><given-names>G</given-names></name>. <article-title>Active inference: a process theory.</article-title><source>Neural Computation</source>. <year>2017</year>;<volume>29</volume>:<fpage>1</fpage>&#8211;<lpage>49</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/NECO_a_00912</pub-id><pub-id pub-id-type="pmid">27870614</pub-id></mixed-citation></ref><ref id="pone.0282882.ref136"><label>136</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Whittington</surname><given-names>JCR</given-names></name> and <name name-style="western"><surname>Bogacz</surname><given-names>R</given-names></name>. <article-title>An approximation of the error backpropagation algorithm in a predictive coding network with local Hebbian synaptic plasticity.</article-title><source>Neural Computation</source>. <year>2017</year>;<volume>29</volume>(<issue>5</issue>):<fpage>1229</fpage>&#8211;<lpage>1262</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/NECO_a_00949</pub-id><pub-id pub-id-type="pmid">28333583</pub-id><pub-id pub-id-type="pmcid">PMC5467749</pub-id></mixed-citation></ref><ref id="pone.0282882.ref137"><label>137</label><mixed-citation publication-type="other">Song Y, Lukasiewicz, Xu Z and Bogacz R. Can the brain do backpropagation?&#8212;Exact implementation of backpropagation in predictive coding networks. In: Proceedings of the Neural Information Processing Systems (NeurIPS) Conference; 2020 Dec 6&#8211;12; (virtual only). 2020.<pub-id pub-id-type="pmcid">PMC7610561</pub-id><pub-id pub-id-type="pmid">33840988</pub-id></mixed-citation></ref><ref id="pone.0282882.ref138"><label>138</label><mixed-citation publication-type="book"><name name-style="western"><surname>Dummett</surname><given-names>M.</given-names></name><source>Frege: Philosophy of Language</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <source>Harvard University Press</source>; <year>1973</year>.</mixed-citation></ref><ref id="pone.0282882.ref139"><label>139</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Fillmore</surname><given-names>CJ</given-names></name>. <article-title>Frames and the semantics of understanding.</article-title><source>Quaderni di Semantica.</source><year>1985</year>;<volume>6</volume>(<issue>2</issue>):<fpage>222</fpage>&#8211;<lpage>254</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref140"><label>140</label><mixed-citation publication-type="book"><name name-style="western"><surname>Flickinger</surname><given-names>D.</given-names></name><name name-style="western"><surname>Accuracy</surname><given-names>vs</given-names></name>. <part-title>robustness in grammar engineering.</part-title> In: <name name-style="western"><surname>Bender</surname><given-names>EM</given-names></name> and <name name-style="western"><surname>Arnold</surname><given-names>JE</given-names></name> (Eds.), <source>Language from a Cognitive Perspective: Grammar, Usage, and Processing.</source><publisher-loc>Stanford</publisher-loc>: <publisher-name>CSLI Publications</publisher-name>; <year>2011</year>. p. <fpage>31</fpage>&#8211;<lpage>50</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref141"><label>141</label><mixed-citation publication-type="journal"><collab>PULSE+IT</collab>. <article-title>The SAN using AI to automate multidisciplinary team meetings.</article-title><source>PULSE+IT Magazine.</source><month>June</month><day>18</day>, <year>2020</year>. <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.pulseitmagazine.com.au/news/australian-ehealth/5558-the-san-using-ai-to-automate-multidisciplinary-team-meetings" ext-link-type="uri">https://www.pulseitmagazine.com.au/news/australian-ehealth/5558-the-san-using-ai-to-automate-multidisciplinary-team-meetings</ext-link>.</mixed-citation></ref><ref id="pone.0282882.ref142"><label>142</label><mixed-citation publication-type="journal"><name name-style="western"><surname>He</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Baxter</surname><given-names>SL</given-names></name>, <name name-style="western"><surname>Xu</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Xu</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Zhou</surname><given-names>X</given-names></name>, and <name name-style="western"><surname>Zhange</surname><given-names>K</given-names></name>. <article-title>The practical implementation of artificial intelligence technologies in medicine</article-title>. <source>Nature Medicine</source>. <year>2019</year>;<volume>25</volume>:<fpage>30</fpage>&#8211;<lpage>36</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41591-018-0307-0</pub-id><pub-id pub-id-type="pmid">30617336</pub-id><pub-id pub-id-type="pmcid">PMC6995276</pub-id></mixed-citation></ref><ref id="pone.0282882.ref143"><label>143</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Sun</surname><given-names>TQ</given-names></name> and <name name-style="western"><surname>Medaglia</surname><given-names>R</given-names></name>. <article-title>Mapping the challenges of artificial intelligence in the public sector: evidence from public healthcare</article-title>. <source>Government Information Quarterly</source>. <year>2019</year>;<volume>36</volume>:<fpage>368</fpage>&#8211;<lpage>83</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref144"><label>144</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Shortliffe</surname><given-names>EH</given-names></name> and <name name-style="western"><surname>Sepulveda</surname><given-names>MJ</given-names></name>. <article-title>Clinical decision support in the era of artificial intelligence</article-title>. <source>JAMA</source>. <year>2018</year>;<volume>320</volume>(<issue>21</issue>):<fpage>2199</fpage>&#8211;<lpage>200</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1001/jama.2018.17163</pub-id><pub-id pub-id-type="pmid">30398550</pub-id></mixed-citation></ref><ref id="pone.0282882.ref145"><label>145</label><mixed-citation publication-type="other">LeCun Y and Manning C. What innate priors should we build into the architecture of deep learning systems? <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.youtube.com/watch?v=fKk9KhGRBdI" ext-link-type="uri">https://www.youtube.com/watch?v=fKk9KhGRBdI</ext-link>, 2018. Last accessed August 2020.</mixed-citation></ref><ref id="pone.0282882.ref146"><label>146</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Hao</surname><given-names>K.</given-names></name><article-title>A debate between AI experts shows a battle over the technology&#8217;s future</article-title>. <source>MIT Technology Review</source>. <month>March</month><volume>27</volume>, <fpage>2020</fpage>.</mixed-citation></ref><ref id="pone.0282882.ref147"><label>147</label><mixed-citation publication-type="book"><name name-style="western"><surname>Haugeland</surname><given-names>J.</given-names></name><source>Artificial Intelligence: The Very Idea</source>. <publisher-name>MIT Press</publisher-name><year>1985</year>.</mixed-citation></ref><ref id="pone.0282882.ref148"><label>148</label><mixed-citation publication-type="book"><name name-style="western"><surname>Manning</surname><given-names>C</given-names></name> and <name name-style="western"><surname>Sch&#252;tze</surname><given-names>H</given-names></name>. <source>Foundations of Statistical Natural Language Processing, Chapter 1</source>, <publisher-loc>Cambridge, MA</publisher-loc>: <collab>The MIT Press</collab>; <year>1999</year>.</mixed-citation></ref><ref id="pone.0282882.ref149"><label>149</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Bengio</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Lecun</surname><given-names>Y</given-names></name>, and <name name-style="western"><surname>Hinton</surname><given-names>G</given-names></name>. <article-title>Deep learning for AI</article-title>. <source>Communications of the ACM</source>. <year>2021</year>;<volume>64</volume>(<issue>7</issue>):<fpage>58</fpage>&#8211;<lpage>65</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref150"><label>150</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Bommasani</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Hudson</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Adeli</surname><given-names>E</given-names></name>, <etal>et al</etal>. <article-title>On the opportunities and risks of foundation models.</article-title><source>ArXiv ID 2108</source>.<volume>07258</volume>, <year>2021</year>. p. <fpage>1</fpage>&#8211;<lpage>212</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref151"><label>151</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Hiesinger</surname><given-names>PR</given-names></name>. <article-title>The Self-Assembling Brain: How Neural Networks Grow Smarter</article-title>. <source>Princeton University Press</source>; <year>2021</year>.</mixed-citation></ref><ref id="pone.0282882.ref152"><label>152</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Petrov</surname><given-names>S.</given-names></name><source>Is scale all we need? presented at the Workshop on Foundational Models, Stanford University, Virtual Event</source>, <month>August</month><day>24</day>, <year>2021</year>.</mixed-citation></ref><ref id="pone.0282882.ref153"><label>153</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Zhang</surname><given-names>T</given-names></name> and <name name-style="western"><surname>Hashimoto</surname><given-names>T</given-names></name>. <article-title>On the inductive bias of masked language modeling: from statistical to syntactic dependencies.</article-title><source>arXiv</source>:<volume>2104</volume>.<issue>05694</issue>, <year>2021</year>.</mixed-citation></ref><ref id="pone.0282882.ref154"><label>154</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Karlgen</surname><given-names>J</given-names></name> and <name name-style="western"><surname>Kanerva</surname><given-names>P</given-names></name>. <article-title>Semantics in high-dimensional space</article-title>. <source>Frontiers in Artificial Intelligence</source>. <year>2021</year>;<volume>4</volume>:<fpage>1</fpage>&#8211;<lpage>6</lpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.3389/frai.2021.698809</pub-id><pub-id pub-id-type="pmcid">PMC8439276</pub-id><pub-id pub-id-type="pmid">34532704</pub-id></mixed-citation></ref><ref id="pone.0282882.ref155"><label>155</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Garnelo</surname><given-names>M</given-names></name> and <name name-style="western"><surname>Shanahan</surname><given-names>M</given-names></name>. <article-title>Reconciling deep learning with symbolic artificial intelligence: representing objects and relations</article-title>. <source>Current Opinion in Behavioral Sciences</source>. <year>2019</year>;<volume>29</volume>:<fpage>17</fpage>&#8211;<lpage>23</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref156"><label>156</label><mixed-citation publication-type="other">Mamou J, Le H, Del Rio MA, Stephenson C, Tang H, Kim Y, et al. Emergence of separable manifolds in deep language representations. In: Proceedings of the 37<sup>th</sup> International Conference on Machine Learning ICML; 2020 July 12&#8211;18; Vienna, Austria. 2020;16814:6669&#8211;6679.</mixed-citation></ref><ref id="pone.0282882.ref157"><label>157</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Smith</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Ashburner</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Rosse</surname><given-names>C</given-names></name>, <etal>et al</etal>. <article-title>The OBO Foundry: coordinated evolution of ontologies to support biomedical data integration</article-title>. <source>Nature Biotechnology</source>. <year>2007</year>;<volume>25</volume>:<fpage>1251</fpage>&#8211;<lpage>1255</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nbt1346</pub-id><pub-id pub-id-type="pmid">17989687</pub-id><pub-id pub-id-type="pmcid">PMC2814061</pub-id></mixed-citation></ref><ref id="pone.0282882.ref158"><label>158</label><mixed-citation publication-type="other">Wache H, Voegele T, Visser U, Stuckenschmidt H, Schuster G, Neumann H, et al. Ontology-based integration of information&#8212;A survey of existing approaches. In: Proceedings of the IJCAI-01 Workshop on Ontologies and Information Sharing; 2001 Aug 4&#8211;5; Seattle, WA. 2001. p. 108&#8211;118.</mixed-citation></ref><ref id="pone.0282882.ref159"><label>159</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Feigenbaum</surname><given-names>EA</given-names></name>. <article-title>Some challenges and grand challenges for computational intelligence</article-title>. <source>Journal of the Association for Computational Machinery</source>. <year>2003</year>;<volume>50</volume>(<issue>1</issue>):<fpage>32</fpage>&#8211;<lpage>40</lpage>.</mixed-citation></ref><ref id="pone.0282882.ref160"><label>160</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Friedman</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Kra</surname><given-names>P</given-names></name>, and <name name-style="western"><surname>Rzhetsky</surname><given-names>A</given-names></name>. <article-title>Two biomedical sublanguages: a description based on the theories of Zellig Harris</article-title>. <source>Journal of Biomedical Informatics</source>. <year>2002</year>;<volume>35</volume>(<issue>4</issue>):<fpage>222</fpage>&#8211;<lpage>235</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/s1532-0464(03)00012-1</pub-id><pub-id pub-id-type="pmid">12755517</pub-id></mixed-citation></ref><ref id="pone.0282882.ref161"><label>161</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Garcez</surname><given-names>AA</given-names></name>, <name name-style="western"><surname>Gori</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Lamb</surname><given-names>LC</given-names></name>, <name name-style="western"><surname>Serafini</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Spranger</surname><given-names>M</given-names></name>, and <name name-style="western"><surname>Tran</surname><given-names>S</given-names></name>. <article-title>Neural-symbolic computing: An effective methodology for principled integration of machine learning and reasoning.</article-title><source>arXiv</source>:1905.06088, <month>May</month><day>15</day>, <year>2019</year>.</mixed-citation></ref><ref id="pone.0282882.ref162"><label>162</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Garcez</surname><given-names>AA</given-names></name> and <name name-style="western"><surname>Lamb</surname><given-names>LC</given-names></name>. <article-title>Neurosymbolic AI: The 3<sup>rd</sup> wave.</article-title><source>arXiv</source>:2012.05876, <month>December</month><year>2020</year>.</mixed-citation></ref><ref id="pone.0282882.ref163"><label>163</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name>. <article-title>Artificial intelligence&#8211;the revolution hasn&#8217;t happened yet</article-title>. <source>Harvard Data Science Review</source>. <year>2019</year>;<volume>1</volume>(<issue>1</issue>).</mixed-citation></ref><ref id="pone.0282882.ref164"><label>164</label><mixed-citation publication-type="other">Hwang JD, Bhagavatula C, Le Bras R, Da J, Sakaguchi K, Bosselut A, et al. (COMET-)ATOMIC-2020: On symbolic and neural commonsense knowledge graphs. In: Proceedings of the 35<sup>th</sup> AAAI Conference on Artificial Intelligence (AAAI-21); virtual only. 2021. p. 6384&#8211;6392.</mixed-citation></ref><ref id="pone.0282882.ref165"><label>165</label><mixed-citation publication-type="other">Caucheteux C and King J_R. Language processing in brains and deep neural networks: computational convergence and its limits. bioRxiv preprint <pub-id pub-id-type="doi">10.1101/2020.07.03.186288</pub-id>, July 4, 2020.</mixed-citation></ref><ref id="pone.0282882.ref166"><label>166</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Marcus</surname><given-names>G.</given-names></name><article-title>The next decade of AI: Four steps towards robust artificial intelligence</article-title>. <source>arXiv</source>:2002.06177, <month>February</month><year>2020</year>.</mixed-citation></ref></ref-list></back><sub-article article-type="aggregated-review-documents" id="pone.0282882.r001" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0282882.r001</article-id><title-group><article-title>Decision Letter 0</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Safro</surname><given-names initials="I">Ilya</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#169; 2023 Ilya Safro</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Ilya Safro</copyright-holder><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0282882" id="rel-obj001" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>0</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">6 May 2021</named-content>
</p><p>PONE-D-20-39301</p><p>Design considerations for a hierarchical semantic compositional framework for medical natural language understanding</p><p>PLOS ONE</p><p>Dear Dr. Taira,</p><p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE&#8217;s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p><p>Please submit your revised manuscript by June-4, 2021. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at <email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p><p>Please include the following items when submitting your revised manuscript:</p><p>
<list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list>
</p><p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p><p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see:&#160;<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">http://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at&#160;<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link>.</p><p>We look forward to receiving your revised manuscript.</p><p>Kind regards,</p><p>Ilya Safro, Ph.D.</p><p>Academic Editor</p><p>PLOS ONE</p><p>Journal Requirements:</p><p>When submitting your revision, we need you to address these additional requirements.</p><p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at</p><p><underline><ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link></underline> and</p><p>
<underline>
<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
</underline>
</p><p>2. Thank you for stating in your Funding Statement:</p><p>'This work was funded in part by funds from the National Institutes of Health grants R01-CA226079, R01-LM012309, R01-CA1575533, R01-LM011333, and U24-AI117966.</p><p>RKT was the recipient of funds from these sources in the role of an investigator.&#160; The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.'</p><p>a. Please provide an amended statement that declares *all* the funding or sources of support (whether external or internal to your organization) received during this study, as detailed online in our guide for authors at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="about:blank" ext-link-type="uri">http://journals.plos.org/plosone/s/submit-now</ext-link></p><p>Please also include the statement &#8220;There was no additional external funding received for this study.&#8221; in your updated Funding Statement.</p><p>b. Please include your amended Funding Statement within your cover letter. We will change the online submission form on your behalf.</p><p>[Note: HTML markup is below. Please do not edit.]</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>

<bold>Comments to the Author</bold>
</p><p>1. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p><p>Reviewer #1:&#160;Partly</p><p>Reviewer #2:&#160;Yes</p><p>Reviewer #3:&#160;Partly</p><p>**********</p><p>2. Has the statistical analysis been performed appropriately and rigorously? </p><p>Reviewer #1:&#160;N/A</p><p>Reviewer #2:&#160;N/A</p><p>Reviewer #3:&#160;N/A</p><p>**********</p><p>3. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#8212;e.g. participant privacy or use of data from a third party&#8212;those must be specified.</p><p>Reviewer #1:&#160;Yes</p><p>Reviewer #2:&#160;Yes</p><p>Reviewer #3:&#160;No</p><p>**********</p><p>4. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p><p>Reviewer #1:&#160;Yes</p><p>Reviewer #2:&#160;Yes</p><p>Reviewer #3:&#160;Yes</p><p>**********</p><p>5. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p><p>Reviewer #1:&#160;The paper described design of a semantic model and an associated parser used to transform a free-text sentence into a logical representation of the meaning of clinical text. The main contribution of this paper is to enhance machine understanding clinical text semantically. While the four-point framework aims to provide a structure for designing NLU system, some points had relatively similar concepts in natural language processing, e.g. both &#8220;Predefined Semantic Representations&#8221; and &#8220;Semantic Activation Networks&#8221; are both similar to knowledge models in medical knowledgebases and ontologies. Overall, the paper lacks comparison to other NLP concepts, tasks and systems.</p><p>Besides, there are several major problems:</p><p>1. The structure of the paper is confusing, &#8220;we first introduce the overall NLU problem highlighting the need for a predefined compositional structure&#8221; &#8211; this should be defined in the Introduction.</p><p>2. The author should also highlight major deliverable of the paper &#8220;Hierarchical Semantic Compositional Model (HSCM)&#8221; earlier in the manuscript as well as in the abstract.</p><p>3. Definition of &#8220;surface words&#8221; is not clear.</p><p>4. How is Semantic Layer 4-6 different from each other?</p><p>5. &#8220;This structure enables a more efficient process of encoding sentence meaning, by facilitating a generative model.&#8221; &#8211; how do you measure efficiency? Do you compare your parser with other semantic parsers?</p><p>6. &#8220;Our design involves explicitly defining this structure in a way that parallels the manner in which human compose meaning.&#8221; &#8211; how is your methods different from other NLP tasks that extract information from unstructured clinical text and create a structured output.</p><p>Reviewer #2:&#160;This manuscript proposes a new framework for NLU (natural; language understanding) based mostly on semantic analysis (semantic memory, composition, activation and hierarchical predictive coding). This interesting framework is based on a few human cognition characteristics and contrasted with current deep learning-based approaches. The manuscript is very well written, but the framework description remains quite vague in several aspects and leaves most details and possible implementations to be defined. This vagueness might keep it more flexible and technology-agnostic but also makes understanding several aspects of the proposed framework quite difficult.</p><p>The following revisions are recommended:</p><p>Major Compulsory Revisions:</p><p>1. The framework proposes an approach that is presented as applicable to all clinical narratives and their possible content, but also mention that circumscribing the scope of this possible semantic content is part of the modeling process. This is a critical issue and balance to find between a very specific semantic field specific to one specialty, note type, institution and even individual author, and broad biomedical and general knowledge. More discussions around this issue and strategies to address it should be added.</p><p>2. As mentioned above, the complexity of certain aspects of the proposed framework and the vague description make understanding sometimes difficult. A few punctual examples are provided, but a more complete and realistic example (maybe broader than the radiology report examples provided) used throughout the different steps of the proposed NLU process would significantly help understand the concepts proposed.</p><p>3. Among desirable characteristics of NLU/NLP frameworks, generalizability is among the top and is a very current problem, but mostly ignored in your manuscript; it is not even mentioned in its list of qualities. On page 11, you state that you favor topic-centric and corpus-based approaches (with specific note types); this strategy might allow for better performance in this specific field, but also tends to generalize to other domains with difficulty.</p><p>4. Word sense disambiguation is an important step in the semantic analysis of clinical text, and how it could be implemented remains unclear. Would it be part of semantic layer 1 (e.g., for abbreviations expansion)? Or another one for eponyms for example? Similarly, analysis of the local context of the information/concepts identified (e.g., negation) is critical but not clearly part of your semantic constituents; layer 4? Or 5?</p><p>5. The discussion contracting the proposed framework with deep learning-based approaches using word embeddings etc. is very important nowadays and should be expanded with more structure and concrete examples. Demonstrating the proposed superiority of your approach would rely on it.</p><p>Minor Essential Revisions:</p><p>1. Stating that automated deep understanding of clinical notes remains elusive and generally far from human abilities is probably correct, but requires evidence (e.g., cited bibliographic references) and would benefit from a more detailed description of specific limitations your proposed framework would address.</p><p>2. On page 5 last line, &#8220;lexical level&#8221; would match the other levels mentioned better than &#8220;at the level of words&#8221;.</p><p>3. On page 32, stating that the clinical language is more restrictive than &#8220;open-ended&#8221; text might be true for radiology reports but has been demonstrated as less restrictive in other domains and note types. Some clarification is needed.</p><p>Reviewer #3:&#160;It is refreshing to see described, a proposed system design drawing from well-researched theories in the cognitive sciences, and practical considerations in the medical imaging reporting domain, that attempts to performs knowledge synthesis and inference similar to specialized human experts. This is in sharp contrast to many leading conference and medical NLP workshop papers in recent times employing the latest state of the art deep learning methods, but all of which read very much the same.</p><p>This work could definitely be poised to become a unique and important contribution in the area of medical NLU, however there are some key aspects of completeness that must be addressed first. The main thrust of the article seems to be around the premise that "compositionality" plays a key role in the human-like understanding by machines, of complex sentence structure, stating perhaps rightly that we would not lose any information given in the sentence by factoring it into components that are themselves meaningful at various levels of semantic abstraction. These components seemingly could even be at the level of ontological primitives and propositions besides characters, tokens or phrases. However, little is presented in terms of evidence or experiments to support this claim or hypothesis.</p><p>The introduction and background sections give the reader a solid overview of the different elements that will go into the design of the framework, such as semantic composition, semantic activation networks and hierarchical predictive coding. However, the paper structure, while it is meant to be about the design considerations for such a framework, lacks the structure of a clear hypothesis and supporting (even preliminary) experiments, analysis, or initial prototype, that serves to "inform" such a design.</p><p>It is good to see models such as BERT, BioBERT cited in references, however the necessary comparisons as to how the proposed framework is at least "different" if not better, than these, by way of just some simple examples or analysis is lacking. E.g. if the authors are familiar with the recent work "BERT rediscovers the classical NLP pipeline." by Tenney et al. that source could have been cited and appropriate comparisons presented. E.g. this aforementioned paper talks about how internal BERT architecture layers are found to perform increasingly complex tasks, viz. part-of-speech tagging, parsing, entity recognition, semantic roles, and finally coreference, in that order, towards NLU. This is reminiscent of the various level managers in Figure 4 of this draft. Thus a simple comparison by means of a chart or a table between the framework in Figure 4, and BERT, could have been provided, highlighting side-by-side, how existing language models of the day such as BERT, or its fine-tuned variants like BioBERT process and understand language at each level, compared to the proposed HSCM framework. This might give the reader an immediate intuition of how and why HSCM can be expected to perform better and perhaps produce more human-like inferences. At the least it would highlight the benefits and drawbacks of each paradigm. Also, while the implementation details of each piece of the framework has been left to the user, it is not clear what sort of time complexity considerations are at play, for encoding and decoding/inference functions of the framework, e.g. steps 1,2,3 and 4 of Figure 5. This may lead the reader to assume deep learning-based systems are at a greater advantage, at a fraction of the representation, training and inference cost. Some estimate of what time and space complexity each layer/piece of the framework involves by way of some simple example, might give the reader a better idea.</p><p>The claim of greater interpretability possible with the HSCM framework and how it arrives at final decisions in terms of "true intended meaning" of a parse has not been entirely elaborated either. Also, the authors seem to suggest that HSCM can better handle out-of-vocabulary concept formulation and meaning understanding by way of semantic activation network. An illustration of this can again be provided via a comparison table or graphic visualization using a simple/concrete example that shows how HSCM is expected to handle an unseen term, "concept", or "semantic abstraction" versus skip-gram word2vec, for example. This is an opportunity to highlight how HSCM can provide superior human-like understanding compared to simple inference using word2vec. Perhaps HSCM is able to leverage embedding-based representations at its various levels, which gives users of the framework best of both worlds. This aspect could also be elaborated on. Finally, I believe that the work should be presented for publication after some very basic observations and outcomes are gathered and evaluated from an initial prototype. Overall, the paper outlines some powerful ideas that seem to have the potential to "truly" solve NLU for the medical domain, however it must be presented in the context of what current medical NLP/IR systems based on deep-learned representations do not yet have the capacity to solve, and by showing via example or anecdote from the HSCM framework, as to how a system based on this framework has a better chance of solving that specific NLU problem.</p><p>**********</p><p>6. PLOS authors have the option to publish the peer review history of their article (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p><p>If you choose &#8220;no&#8221;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.</p><p>Reviewer #1:&#160;No</p><p>Reviewer #2:&#160;No</p><p>Reviewer #3:&#160;No</p><p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p><p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool,&#160;<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at&#160;<email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p></body></sub-article><sub-article article-type="author-comment" id="pone.0282882.r002"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0282882.r002</article-id><title-group><article-title>Author response to Decision Letter 0</article-title></title-group><related-article xmlns:xlink="http://www.w3.org/1999/xlink" related-article-type="editor-report" id="rel-obj002" xml:lang="en" ext-link-type="doi" xlink:href="10.1371/journal.pone.0282882"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="author-response-date">17 Nov 2021</named-content>
</p><p>We have included responses to each concern of all the reviewers in the "Response to Reviewer" document.</p><supplementary-material id="pone.0282882.s001" position="float" content-type="local-data" orientation="portrait"><label>Attachment</label><caption><p>Submitted filename: <named-content content-type="submitted-filename">Response to Reviewers.docx</named-content></p></caption><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0282882.s001.docx" position="float" orientation="portrait"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></body></sub-article><sub-article article-type="aggregated-review-documents" id="pone.0282882.r003" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0282882.r003</article-id><title-group><article-title>Decision Letter 1</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Safro</surname><given-names initials="I">Ilya</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#169; 2023 Ilya Safro</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Ilya Safro</copyright-holder><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article xmlns:xlink="http://www.w3.org/1999/xlink" related-article-type="reviewed-article" id="rel-obj003" xml:lang="en" ext-link-type="doi" xlink:href="10.1371/journal.pone.0282882"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">19 Jul 2022</named-content>
</p><p>PONE-D-20-39301R1Design considerations for a hierarchical semantic compositional framework for medical natural language understandingPLOS ONE</p><p>Dear Dr. Taira,</p><p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE&#8217;s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p><p>Please submit your revised manuscript by September 2, 2022. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at&#160;<email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p><p>Please include the following items when submitting your revised manuscript:<list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list></p><p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p><p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link>.</p><p>We look forward to receiving your revised manuscript.</p><p>Kind regards,</p><p>Ilya Safro, Ph.D.</p><p>Academic Editor</p><p>PLOS ONE</p><p>[Note: HTML markup is below. Please do not edit.]</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>

<bold>Comments to the Author</bold>
</p><p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the &#8220;Comments to the Author&#8221; section, enter your conflict of interest statement in the &#8220;Confidential to Editor&#8221; section, and submit your "Accept" recommendation.</p><p>Reviewer #1:&#160;(No Response)</p><p>Reviewer #4:&#160;(No Response)</p><p>**********</p><p>2. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p><p>Reviewer #1:&#160;Partly</p><p>Reviewer #4:&#160;No</p><p>**********</p><p>3. Has the statistical analysis been performed appropriately and rigorously? </p><p>Reviewer #1:&#160;N/A</p><p>Reviewer #4:&#160;N/A</p><p>**********</p><p>4. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#8212;e.g. participant privacy or use of data from a third party&#8212;those must be specified.</p><p>Reviewer #1:&#160;Yes</p><p>Reviewer #4:&#160;Yes</p><p>**********</p><p>5. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p><p>Reviewer #1:&#160;Yes</p><p>Reviewer #4:&#160;Yes</p><p>**********</p><p>6. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p><p>Reviewer #1:&#160;1. In "Dicussion", the author mentioned that clinical text "varied with respect to their formality, style, and flow". However, it is not clear how this varaibility bring problems to existing NLU systems.</p><p>2. In "Speaker-Listener Model" section, it is not clear what the model is. Is it a mediator between Speaker-Listener or something else. This paragraph is confusing.</p><p>3. The example provided in the "Wrong use of valid terminology", I don't think this is a good example, it is just a non-standardized unit measure and a standardized unit quantity can be calculated.</p><p>4. "Punctuation Mis-use" was mentioned as examples of language complexities in medical reports. However, does this bring problems to NLU system at all? Normally NLP systems would remove punctuations at a certain stage of data processing.</p><p>5. Example in "Temporal Ambiguity" is also not really ambiguity. It has to do with information not captured by the physiciian.</p><p>6. "Inferred information from practice guidelines" is not a examples of language complexities, but rather a knowledge complexity which will require periodic update of the knowledgebase or proper version control. I think it should be discussed separately as an essential part of system design.</p><p>7. The author compared Cognitive Framework with deep learning based framework for NLU. While I do see the similarities between the two frameworks in terms of hierachical structure, a more fair comparison would be with other previous content-based systems (or there can be other names used e.g., scenario-specific systems, systems enabling spatial and temporal constraints).</p><p>Reviewer #4:&#160;This paper describes a concept design of a hierarchical semantic compositional framework to provide an internal model for guiding the interpretation process. Overall, this concept paper reviews some ideas that might be useful for achieving a &#8220;deep and true&#8221; understanding of clinic texts, however, it lacks a detailed review for the applicable contexts and tasks. For a successful publication, I believe that this paper shall provide either theoretical or empirical contributions. I would strongly suggest that it shall include empirical support to justify the performance of the proposed framework. Also, developing metrics for the proposed framework&#8217;s evaluation is important and human experts&#8217; evaluations seem to be also essential in this matter. However, this paper only presents a general summary of evaluation required by medical NLU systems in P35. It is uncertain for the HSCM&#8217;s evaluation and so to its real effectiveness.</p><p>Main concerns:</p><p>Introduction</p><p>Research motivations:</p><p>The authors stated &#8220;&#8230; NLP/NLU of clinical reports is an important area in medical informatics &#8230; However, it is challenging to perform deep understanding of clinical notes by computers &#8230;&#8221; without giving a clear definition of &#8220;deep understanding&#8221;, what does it mean? Since this is the motivation of designing such framework, it is necessary to define the level of understanding the filed expects rather than simply saying &#8220;closer to human capabilities&#8221;.</p><p>Also, &#8220;true intended meaning&#8221; in such context lacks a clear definition. It will be good to give examples for some texts derived from the clinic reports and show both &#8220;wrong interpretations&#8221; VS &#8220;true intended meaning&#8221;.</p><p>Design:</p><p>The HSCM is designed for a sentence-level understanding, what is the reason for picking this level? Semantic understanding is important as stated in the Background section, so defining the semantics used in the HSCM model is essential for its success. Performing pilot studies to test the length of words will be helpful in this matter. The sentence-level model processing might not be an optimal selection, because the clinic texts/reports might be very context-sensitive, such as a good understanding only can be achieved via reading several paragraphs, thus, there might be some misunderstanding due to the selection of the unit.</p><p>The introduction section lacks a statement of findings and a summary of contributions.</p><p>Medical NLP studies have lots of applications. This paper in general does not include an overview of the NLP/NLU systems, which is especially important for conducting a systematic knowledge of the NLP concepts, tasks, performance in the medical domain.</p><p>Definitions for performance metrics are missing. This paper proposes a framework (a concept paper) without conducting any experiments using &#8220;real clinic data&#8221;, so the argument &#8220;This structure enables a more efficient process of encoding sentence meaning, by facilitating a generative model.&#8221; is not supported from the overall study.</p><p>It is not clear that the innovative aspects of the HSCM, how does it different from other NLU methods that could effectively process clinic texts? As the authors stated, unstructured clinical texts need to be carefully handled to create a structured output, but why HSCM could potentially outperform other existing systems? Here is a lack of justification.</p><p>Also, any potential implications and applications will be further developed based on the HSCM framework?</p><p>Figures:</p><p>Figure 4, describing the model architecture with various level managers, has many abbreviations, however, there is a lack of explanation for their meanings.</p><p>Minor concerns:</p><p>Writing:</p><p>There is an underline for the word &#8220;understanding&#8221; on P3 line 55, which looks weird.</p><p>Please insert figures to the corresponding places of the manuscript. The authors put all the figures at the end of the manuscript which causes large inconvenience for reading.</p><p>**********</p><p>7. PLOS authors have the option to publish the peer review history of their article (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p><p>If you choose &#8220;no&#8221;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.</p><p>Reviewer #1:&#160;No</p><p>Reviewer #4:&#160;No</p><p>**********</p><p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p><p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool,&#160;<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at&#160;<email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p></body></sub-article><sub-article article-type="author-comment" id="pone.0282882.r004"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0282882.r004</article-id><title-group><article-title>Author response to Decision Letter 1</article-title></title-group><related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0282882" id="rel-obj004" related-article-type="editor-report"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>2</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="author-response-date">17 Sep 2022</named-content>
</p><p>Design considerations for a hierarchical semantic compositional framework for medical natural language understanding</p><p>Response to Reviewers</p><p>The authors would like to sincerely thank the reviewers for their efforts in providing critical and helpful comments for this paper re-submission. Below we address each point of concern from each reviewer.</p><p>Reviewer #1:</p><p>Q-01: In "Discussion", the author mentioned that clinical text "varied with respect to their formality, style, and flow". However, it is not clear how this variability bring problems to existing NLU systems.</p><p>This statement on page 32 was made in relation to understanding the knowledge expectations and inference strategies that would be required for deciphering the meaning of clinical text when presented with different language styles and levels of semantic complexity. NLP models based on word sequences (e.g., topic models, Markov chains, and deep learning transformer models) are applicable to all grammatical styles and topic areas, but have limitations with respect to their ability to ground meaning to real world concepts. The degree to which NLU systems can infer intended meaning vary with respect to text writing styles. </p><p>For example, radiology reports tend to be authored using well-formed grammar in a detailed declarative writing style and, as such, are relatively straightforward to process [Langlotz 2014]. Conversely, physician notes often present a telegraphic style of writing in which a number of abbreviations and word sequence fragments are observed [Stallinga 2015]. In such cases, the main points of the communication can be difficult to infer due to lack of details that must be inferred based on the clinical context. With respect to the narrative flow, reports such as discharge summaries can include complex descriptions of the patient&#8217;s episodic timeline, that require information over many sentences to be comprehended and connected. In such narrative reports, various difficult language aspects are common, including coordination, coreference resolution, and ellipsis.</p><p>Langlotz CP. The radiology report: a guide to thoughtful communication for radiologists and other medical professionals. 2015, ISBN: 978-1515174080.</p><p>Stallinga HA, ten Napel H, Jansen GJ, Geertzen JH, de Vries Robb&#233; PF, and Roodbol PF. Does language ambiguity in clinical practice justify the introduction of standard terminology? An integrative review. Journal of Clinical Nursing. 2015;24(3-4):344-52.</p><p>We have added text in the Discussion section to clarify these points.</p><p>---------------------------------</p><p>Q-02: In "Speaker-Listener Model" section, it is not clear what the model is. Is it a mediator between Speaker-Listener or something else. This paragraph is confusing.</p><p>The &#8220;Speaker-Listener Model&#8221; is a long-standing model for language comprehension that describes how information might be conveyed from a report writer to a report reader in the presence of a noisy channel that might include inaccurate and/or incomplete signals (e.g., words). It describes how a listener and reader require some form of synchrony in terms of the expected communications and context from which the dialogue is made [Stephens 2010]. With respect to medical reports, we see a wide variety of language styles (formal English, terse sentence fragments, etc.) that are unambiguous to the reader due to the common understanding between author and reader regarding the clinical context (e.g., procedure type, prior communications) and general domain knowledge in which the observations, events, and recommendations were made. The point we make is that such an expectation model may potentially be required for comprehending such abbreviated patient reports. We have included the reference below to provide the reader with a link to pursue further details on this concept.</p><p>Stephens GJ, Silbert LJ, and Hasson U. &#8220;Speaker-listener neural coupling underlies successful communication,&#8221; PNAS 107(32):14425-14430, 2010.</p><p>---------------------------------</p><p>Q-03: The example provided in the "Wrong use of valid terminology", I don't think this is a good example, it is just a non-standardized unit measure and a standardized unit quantity can be calculated.</p><p>Thank you for this comment. We have added text to clarify the main point of this example.</p><p>This example on page 34 is one we have encountered frequently in analyzing text describing patient smoking behavior. Here, we observe that physicians often use the units of &#8220;packs per year&#8221; which in general is a valid property. However, in the context of describing cumulative smoking history, the correct unit is &#8220;pack-years&#8221; defined as the number of packs smoked per day multiplied by the number of years smoked. Physicians and/or transcribers often confuse the meaning of these two properties. However, the readers of the reports typically understand that the convention is to report &#8220;pack-years&#8221; and understand that the mention of &#8220;packs-per-year&#8221; is often misused. (Pack-year descriptions are used to determine eligibility for lung cancer screening and as such is the important information the reporting physician is trying to communicate). A language understanding program for extracting patient smoking history thus needs to be able to correctly infer the intended meaning conveyed by the reporting physician despite the misuse of unit terminology.</p><p>---------------------------------</p><p>Q-04: "Punctuation Mis-use" was mentioned as examples of language complexities in medical reports. However, does this bring problems to NLU system at all? Normally NLP systems would remove punctuations at a certain stage of data processing.</p><p>In general, there is a variety of cases where consideration of punctuation can improve the effectiveness of an NLP application. For example, certain punctuation is expected for indicating sentence and phrasal boundaries that are required inputs for tasks such as syntactic parsing. Without such expected punctuation, specific NLP routines such as sentence boundary detection (periods, question marks, exclamations, and ellipses), section boundary detection (e.g., colons), syntactic parsing, and symbolic expression interpretation (e.g., slashes, dashes, colons) can fail. Furthermore, punctuation marks themselves are often activations for triggering a particular type of analysis. </p><p>---------------------------------</p><p>Q-05: Example in "Temporal Ambiguity" is also not really ambiguity. It has to do with information not captured by the physician. </p><p>The NLU problem is distinguished from general NLP in that it is tasked with inferring conveyed meaning, often with the support of real-world situational pragmatic knowledge. Thus, in addition to dealing with language specific issues, it also must be able to infer meaning of text in the light of a common knowledge understanding between writer and reader. For the example given on page 35, the information required by the reader managing the patient is whether the patient is a current smoker or not. (This is needed in order to determine if the patient needs smoking cessation counseling). This information needs to be rationalized based on the information of &#8220;no tobacco&#8221; and &#8220;smoked 3 packs per day x 17 years&#8221;. The correct temporal information that is inferred in this example is that the patient is not a current smoker, but previously smoked for 17 years.</p><p>---------------------------------</p><p>Q-06: "Inferred information from practice guidelines" is not an examples of language complexities, but rather a knowledge complexity which will require periodic update of the knowledgebase or proper version control. I think it should be discussed separately as an essential part of system design.</p><p>As mentioned above, we include the requirement for integrating real world knowledge in order to infer the intent of the authoring physician (The NLU problem vs the NLP problem). The NLP problem only addresses language issues. The NLU problem must include the machinery to infer speaker intent, and as such we include rich pragmatic knowledge bases as part of the NLU architecture. The intent in this example (page 35) is to convey the severity of the patients smoking history in order to provide additional evidence for assessing lung cancer risk. </p><p>---------------------------------</p><p>Q-07: The author compared Cognitive Framework with deep learning based framework for NLU. While I do see the similarities between the two frameworks in terms of hierarchical structure, a more fair comparison would be with other previous content-based systems (or there can be other names used e.g., scenario-specific systems, systems enabling spatial and temporal constraints).</p><p>Thank you for this suggestion. There are a number of systems built for information retrieval, robotics, and question-answering applications that utilize situational context and pragmatic knowledge for optimizing end-user experience. While a comparison of the types of knowledge, their representation, and their methods for inferencing could provide valuable insight into the strengths and weaknesses of our design, we feel this comparison is beyond the scope of this paper. In this paper, we aim to emphasize the four foundational ideas of semantic memory, semantic composition, semantic activation, and hierarchical predictive coding. We provided conceptual illustrations of what each component involves, the rational for their inclusion, and an operational description of how they might be incorporated in a medical NLU implementation. We are writing, however, a follow-up paper on the implementation of our design for analyzing radiology reports and in that paper, we will provide a detailed comparison of related knowledge-based systems, as per your suggestion. </p><p>Reviewer #4:</p><p>Q08: Overall, this concept paper reviews some ideas that might be useful for achieving a &#8220;deep and true&#8221; understanding of clinic texts, however, it lacks a detailed review for the applicable contexts and tasks. For a successful publication, I believe that this paper shall provide either theoretical or empirical contributions. I would strongly suggest that it shall include empirical support to justify the performance of the proposed framework. </p><p>Thank you for this suggestion. In regard to the applicable contexts and tasks, we have included a recent reference to a comprehensive book chapter [Roberts 2022]. The chapter presents the traditional NLP tasks and various classes of Healthcare applications that have been research within the field over the past many decades. We also provide a summary list of common application areas on page 32 of the paper with several references.</p><p>Roberts K. Chapter 8 - Natural Language Processing, in Health Informatics, Practical Guide, 8th Edition, (William Hersh, ed.), ISBN 9781435787759, 2022</p><p>In regard to including empirical evidence, we initially drafted the paper showing a prototype of the system with a fully described semantic hierarchical knowledge based tuned for analysis of sentences describing tumoral masses and patient smoking habits. The analysis was based on 36K tumor description sentences and 10K smoking behavior sentences. Our internal review of the paper however led us to the conclusion of separately describing three viewpoints including the conceptual architectural design, the implementation methods, and application evaluation. In this paper, we chose to avoid the technical details of the implementation since it would distract from the theoretical discussions of the cognitive-inspired narrative of our design. Separate papers are planned for describing the implementation of a prototype implementation and for the evaluation of the approach in two clinical application areas (viz., characterization of radiographic tumoral descriptions and characterization of patient smoking behavior). In this paper, our goal was to make theoretical arguments for moving toward a cognitive architecture. We feel it is first necessary to explain to the medical informatics community the conceptual framework including its underlying foundational principles and their major strategic long-term advantages and disadvantages. </p><p>---------------------------------</p><p>Q09: Also, developing metrics for the proposed framework&#8217;s evaluation is important and human experts&#8217; evaluations seem to be also essential in this matter. However, this paper only presents a general summary of evaluation required by medical NLU systems in P35. It is uncertain for the HSCM&#8217;s evaluation and so to its real effectiveness. </p><p>Thank you for this question. The metrics associated with the architecture can be linked to the described arguments concerning its conceptual advantages and disadvantages. We have included a summarized of metrics from various perspectives in the Discussion section of the paper and summarized below: </p><p>Human development effort point of view: Since the HSCM should parallel how humans model the semantics of words, objects, events, and topics, we envision much of its implementation will be manually defined by humans. The metrics to quantify this manual effort per application might include level of expertise, man-hours required for model development, and level of competence (e.g., errors, consistence) of HSCM authors in following guideline rules. </p><p>From a knowledge engineering perspective: Evaluation metrics for building the HSCM knowledge base can be expressed in terms of traditional evaluation metrics used for ontologies and include expressiveness (representational adequacy), inferential adequacy (ability to infer new information), inferential efficiency, and acquisitional efficiency [Smith 2006].</p><p>Smith B. &#8220;From concepts to clinical reality: an essay on the benchmarking of biomedical terminologies,&#8221; Journal of Biomedical Informatics 39(3):288-298, 2006.</p><p>From a software engineering perspective: The HSCM defines a hierarchical graph that is based on semantic frames. It thus very much embodies the ideas of an object-oriented organization for classes and their associated methods. Thus, the important object-oriented features of inheritance, abstraction, encapsulation, modularity, recursion, and procedural triggers can be easily realized by the architecture. Metrics associated with object-oriented software systems are defined in [Chidamber 1994]. Performance metrics that can be defined from these features include time/effort to define new or edit existing HSCM nodes, and time/effort to debug definitional errors. Additional metrics related to the complexity of the HSCM graph include branching complexity, path complexity, data complexity and decisional complexity. These metrics become increasingly important as the breath of semantic constituents and their complexity rises.</p><p>Chidamber, S.R.; Kemerer, C.F. &#8220;A metrics suite for object oriented design,&#8221; IEEE Transactions on Software Engineering Volume 20, Issue 6, Jun 1994 Page(s):476 - 493</p><p>From a computation perspective: The general problem of NLU is difficult since it requires a mapping from all possible sentence inputs for a domain to all possible interpretations sanctioned by the software system. This results in a huge state space mapping. To tackle the &#8220;curse of dimensionality&#8221; issue, the system introduces structure in terms of hierarchical semantic composition. This allows the joint problem to be factored into a number of lower dimensional mappings. Computation time for the parser to search the HSCM for an optimal interpretation path is facilitated using a predictive coding algorithm. The search time savings is conceptually reduced from an exhaustive bottom-up search to a controlled hybrid search defined by only plausible hypotheses.</p><p>From an end-user clinical application perspective: See the evaluation metrics summarized on pages 35-36.</p><p>---------------------------------</p><p>Q-10: The authors stated &#8220;&#8230; NLP/NLU of clinical reports is an important area in medical informatics &#8230; However, it is challenging to perform deep understanding of clinical notes by computers &#8230;&#8221; without giving a clear definition of &#8220;deep understanding&#8221;, what does it mean? Since this is the motivation of designing such framework, it is necessary to define the level of understanding the filed expects rather than simply saying &#8220;closer to human capabilities&#8221;. </p><p>Thank you for pointing out this omission. We have included a more precise explanation for the goals of a deep understanding system as applied to medical text. Specifically, we have directed the reader to the section of the paper the details how performance requirements of an NLU system are defined with respect to the actionable task it is supporting, and the input text domain it intends to operate on.</p><p>The phrase deep understanding as common in NLU literature refers to systems that have the goal of human level understanding of a text. This requires situational awareness and generally implies the ability to infer meaning utilizing a wide range of language and domain knowledge. It is commonly distinguished between self-learning systems (e.g., deep learning architectures) that have been characterized as having &#8220;a mouth without a brain&#8221; and &#8220;statistical parrots&#8221; [Lederman 2022]. Bender has argued that deep learning systems lack the fundamental mechanisms for inferring speaker intention and thus the limitations of such architectures [Bender 2020].</p><p>Lederman A, Lederman R and Verspoor K. &#8220;Tasks as needs: reframing the paradigm of clinical natural language processing research for real-world decision support,&#8221; Journal of the American Medical Informatics Association, 29(10):1810-1917, 2022.</p><p>Bender EM and Koller A. Climbing toward NLU: on meaning, form, and understanding in the age of data,&#8221; Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, (Best Theme Paper), Pages 5185-5198, July 2020.</p><p>The problems that require natural language &#8220;understanding&#8221; (i.e., intended meaning) are those tied to patient outcomes. One important distinction within the medical informatics field is that the NLU system&#8217;s worth hinges on providing the necessary information to accomplish an &#8220;actionable&#8221; task. Medical NLU systems thus are not intended to be general broad coverage agents, but rather targeted agents that are tasked to understand text at sufficient levels of detail and content to correctly guide a clinical or research action. It is important to realize that these tasks can be high-stake and/or mission critical responsibilities, compared to an NLP system that may be searching for information stored in the web or in journal articles. For example, we have worked on applications for identifying patients who should be screened for lung cancer. Failure to identify such patients should not hinge on idiosyncratic language used in a medical report. Thus, ignoring tail distribution cases is often unacceptable. These difficult cases often require rich models of medical entities and procedures. Having a logical semantic substrate to integrate pragmatic and global situational models will improve an NLU ability to handle complex language phenomena (e.g., ellipses, coreference resolution, and linguistic paraphrasing). </p><p>---------------------------------</p><p>Q-11: Also, &#8220;true intended meaning&#8221; in such context lacks a clear definition. It will be good to give examples for some texts derived from the clinic reports and show both &#8220;wrong interpretations&#8221; VS &#8220;true intended meaning&#8221;.</p><p>Thank you for this suggestion. In the Introduction, we have now provided a note to the reader to see the Discussion Section, under Speaker-Listener Model of the paper which lists examples of various ambiguities that can lead to misunderstanding of clinical text. We describe various classes of ambiguity and potential situations for erroneous interpretations in this discussion. </p><p>---------------------------------</p><p>Q-12: The HSCM is designed for a sentence-level understanding, what is the reason for picking this level? Semantic understanding is important as stated in the Background section, so defining the semantics used in the HSCM model is essential for its success. Performing pilot studies to test the length of words will be helpful in this matter. The sentence-level model processing might not be an optimal selection, because the clinic texts/reports might be very context-sensitive, such as a good understanding only can be achieved via reading several paragraphs, thus, there might be some misunderstanding due to the selection of the unit.</p><p>Thank you for this important concern. The NLU problem involves synthesizing lower complexity representations to build increasingly complex and comprehensive meanings. Each structural level (words, phrases, clauses, sentences, paragraphs, reports, etc.) require different NLU methods to handle the particular semantic synthesis tasks presented within the text. We believe the sentence level is an appropriate central level of abstraction for building meaning for the following reasons. Firstly, there are strong regularities that can be exploited including syntax and topic focus. Secondly, the majority of logical semantic building blocks that are defined at the sentence level (concepts, objects, relations, events) cover a wide spectrum of what are needed to represent text over larger spans. Thirdly, methods for connecting thoughts across sentences (e.g., coreference resolution) involve making associations between logical representations at the sentence level. These methods involve semantic selectional constraints, object description plausibility, and situational expectations [McShane 2021]. The highest representations of the HSCM (e.g., e.g., discourse models, situational models) are intended to encode such knowledge required for resolving, for example, anaphoric ambiguities between nearby sentences.</p><p>---------------------------------</p><p>Q-13: The introduction section lacks a statement of findings and a summary of contributions.</p><p>Thank you for this oversite. We have included the main contribution points of the paper in the Introduction.</p><p>---------------------------------</p><p>Q-14: Medical NLP studies have lots of applications. This paper in general does not include an overview of the NLP/NLU systems, which is especially important for conducting a systematic knowledge of the NLP concepts, tasks, performance in the medical domain.</p><p>This intended audience for this paper is directed toward researchers within the medical NLP domain. We have briefly described some common tasks and methods used during the prior decades of the field. To limit the length of this paper, we have included a reference to a recent book chapter summarizing various topics applications of concern within the field [Roberts 2022] as well as a review paper on this topic [Gao 2022].</p><p>Roberts K. Chapter 8 - Natural Language Processing, in Health Informatics, Practical Guide, 8th Edition, (William Hersh, ed.), ISBN 9781435787759, 2022</p><p>Gao Y, Dligach D, Christensen L, Tesch S, Laffin R, Xu D, Miller T, Uzuner O, Churpek MM, and Afshar M. &#8220;A scoping review of publicly available language tasks in clinical natural language processing,&#8221; Journal of the American Medical Informatics Association 29(10:1797-1806, 2022.</p><p>---------------------------------</p><p>Q-15: Definitions for performance metrics are missing. This paper proposes a framework (a concept paper) without conducting any experiments using &#8220;real clinic data&#8221;, so the argument &#8220;This structure enables a more efficient process of encoding sentence meaning, by facilitating a generative model.&#8221; is not supported from the overall study.</p><p>Please see the response to Q-09 in regard to performance metrics.</p><p>In making the statement &#8220;This structure enables a more efficient process of encoding sentence meaning by facilitating a generative model,&#8221; was made based on two theoretical grounds: composition (representational efficiency) and hierarchical predictive coding (processing efficiency). Imposing a compositional structure (i.e., factorization) is known to contribute significantly to reducing the dimensionality (i.e., computational complexity) of the parsing problem [see references by Geman 2002 and Yuille 2013]. It provides a framework for &#8216;part sharing&#8217; which allows development to proceed in a piece-wise systematic way. (Of course, the up-front cost of such an approach is in curating this HSCM knowledge source for the target clinical application). As described in Yuille, this part sharing can lead to an enormous reduction in complexity. Predictive coding offers processing efficiency since only plausible hypotheses specified within the HSCM grammar need be tested. A combination of top-down (hypothesis formulation) and bottom up (hypothesis testing) processing conducted within a hierarchical predictive paradigm greatly reduces the search state space for a viable global sentence parse. Note that a purely bottom up (inverse problem) approach to semantic parsing is regarded as an ill-posed problem [Barton 1987]. The HSCM model provides the additional constraints in order to rule out a large number of interpretation possibilities.</p><p>S. Geman, D. Potter, and Z. Chi. Composition systems. Quarterly of Applied Mathematics, 60(4):707&#8211;736, 2002.</p><p>Yuille, A. L. and Mottaghi, R. (2013) &#8216;Complexity of representation and inference in compositional models with part sharing&#8217;, 1st International Conference on Learning Representations, ICLR 2013 - Conference Track Proceedings, pp. 1&#8211;13.</p><p>Barton EG, Berwick RC, and Ristad ES. Computational Complexity and Natural Language, Bradford Books, Cambridge, MA, MIT Press, 1987.</p><p>In terms of application, we have implemented a prototype system that performs a semantic parse of descriptions of tumoral masses. This work has been on-going for the past several years and is the main reason we have confidence in the ideas of this paper. We initially drafted a paper that described the tools and HSCM model for this application. However, we thought it best to separate the conceptual design issues from the detailed implementation and tools in order to concentrate on the issues from these separate perspectives. Our plan is to first publish this concept design paper with subsequent papers that will describe a prototype implementation of the design and applications of the system for tumoral mass descriptions and patient smoking behavior. </p><p>---------------------------------</p><p>Q-16: It is not clear that the innovative aspects of the HSCM, how does it different from other NLU methods that could effectively process clinic texts? As the authors stated, unstructured clinical texts need to be carefully handled to create a structured output, but why HSCM could potentially outperform other existing systems? Here is a lack of justification.</p><p>There are very few papers that describe the design architecture for incorporating the machinery required for deep understanding of clinical text. Most medical NLP systems today are based on either traditional pipeline architectures that include sentence boundary detection, tokenization, morphological analysis, syntactic analysis, semantic analysis, and discourse processing [Soan 2014, Roberts 2022] or deep learning architectures [Wu 2020]. As far as we know, there are no reports of cognitive-inspired architectures for medical text processing that incorporate the ideas of symbol grounding, semantic activation, semantic composition, and hierarchical predictive coding. Much of the Discussion section of the paper is directed towards the justification for these ideas specifically for handing the performance requirements within a clinical environment and as a flexible long-term design that can support group community development of applications. (See &#8220;Summary of Main Arguments in Favor of a Cognitive Framework for Medical NLU&#8221; in the Discussion Section of the paper). We have included the references below for readers to further compare NLP architectures currently in development.</p><p>Doan S, Conway M, Phuong TM, and Ohno-Machado L. &#8220;Natural language processing in biomedicine: a unified system architecture overview,&#8221; Clinical Bioinformatics, Chapter 16, R Trent (Ed.), Clinical Bioinformatics, Springer New York, New York, NY (2014), pp. 275-294</p><p>Roberts K. Chapter 8 - Natural Language Processing, in Health Informatics, Practical Guide, 8th Edition, (William Hersh, ed.), ISBN 9781435787759, 2022</p><p>Wu S, Roberts K, Datta S, Du J, Ji Z, Si Y, Soni S, Wang Q, Wei Q, Xiang Y, Zhao B, and Xu H. &#8220;Deep learning in clinical natural language processing: a methodological review,&#8221; Journal of the American Medical Informatics Association 27(3):457-470, 2020.</p><p>---------------------------------</p><p>Q-17: Also, any potential implications and applications will be further developed based on the HSCM framework?</p><p>In the Conclusion section of the paper, we have stated that we will be reporting on the application of the system for analyzing tumoral mass descriptions in radiology reports. We will also be describing an application for analyzing patient smoking behavior.</p><p>---------------------------------</p><p>Q-18: Figure 4, describing the model architecture with various level managers, has many abbreviations, however, there is a lack of explanation for their meanings.</p><p>Thank you for this comment. The many abbreviations shown in Figure 4 are the frame labels we assigned to the various semantic nodes within the HSCM. We have included descriptions of the frame labels within the caption of Figure 4.</p><p>&#8226; pName.size &#8211; property name size</p><p>&#8226; Ont.Cnpt &#8211; Ontologic concept</p><p>&#8226; Num.real &#8211; real number</p><p>&#8226; PName &#8211; property name</p><p>&#8226; PValue &#8211; property value</p><p>&#8226; Ont.E-Frame &#8211; Ontologic entity frame</p><p>&#8226; POS.<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://art.indef" ext-link-type="uri">art.indef</ext-link> &#8211; Part-of-Speech, article, indefinite</p><p>&#8226; Locative.prep &#8211; locative preposition</p><p>---------------------------------</p><p>Q-19: There is an underline for the word &#8220;understanding&#8221; on P3 line 55, which looks weird.</p><p>We have removed the underline.</p><p>---------------------------------</p><p>Q-20: Please insert figures to the corresponding places of the manuscript. The authors put all the figures at the end of the manuscript which causes large inconvenience for reading.</p><p>We apologize for the inconvenience. However, this format is the style stated in the PLOS-ONE author&#8217;s manual.</p><supplementary-material id="pone.0282882.s002" position="float" content-type="local-data" orientation="portrait"><label>Attachment</label><caption><p>Submitted filename: <named-content content-type="submitted-filename">Response to Reviewers 2022.docx</named-content></p></caption><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0282882.s002.docx" position="float" orientation="portrait"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></body></sub-article><sub-article article-type="editor-report" id="pone.0282882.r005" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0282882.r005</article-id><title-group><article-title>Decision Letter 2</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Safro</surname><given-names initials="I">Ilya</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#169; 2023 Ilya Safro</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Ilya Safro</copyright-holder><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0282882" id="rel-obj005" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>2</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">27 Feb 2023</named-content>
</p><p>Design considerations for a hierarchical semantic compositional framework for medical natural language understanding</p><p>PONE-D-20-39301R2</p><p>Dear Dr. Taira,</p><p>We&#8217;re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p><p>Within one week, you&#8217;ll receive an e-mail detailing the required amendments. When these have been addressed, you&#8217;ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p><p>An invoice for payment will follow shortly after the formal acceptance. To ensure an efficient process, please log into Editorial Manager at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.editorialmanager.com/pone/" ext-link-type="uri">http://www.editorialmanager.com/pone/</ext-link>, click the 'Update My Information' link at the top of the page, and double check that your user information is up-to-date. If you have any billing related questions, please contact our Author Billing department directly at <email>authorbilling@plos.org</email>.</p><p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they&#8217;ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email>onepress@plos.org</email>.</p><p>Kind regards,</p><p>Ilya Safro, Ph.D.</p><p>Academic Editor</p><p>PLOS ONE</p></body></sub-article><sub-article article-type="editor-report" id="pone.0282882.r006" specific-use="acceptance-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0282882.r006</article-id><title-group><article-title>Acceptance letter</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Safro</surname><given-names initials="I">Ilya</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#169; 2023 Ilya Safro</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Ilya Safro</copyright-holder><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0282882" id="rel-obj006" related-article-type="reviewed-article"/></front-stub><body><p>
<named-content content-type="letter-date">6 Mar 2023</named-content>
</p><p>PONE-D-20-39301R2 </p><p>Design considerations for a hierarchical semantic compositional framework for medical natural language understanding </p><p>Dear Dr. Taira:</p><p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department. </p><p>If your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact <email>onepress@plos.org</email>.</p><p>If we can help with anything else, please email us at <email>plosone@plos.org</email>. </p><p>Thank you for submitting your work to PLOS ONE and supporting open access. </p><p>Kind regards, </p><p>PLOS ONE Editorial Office Staff</p><p>on behalf of</p><p>Dr. Ilya Safro </p><p>Academic Editor</p><p>PLOS ONE</p></body></sub-article></article></pmc-articleset>