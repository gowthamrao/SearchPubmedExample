<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" article-type="research-article" xml:lang="en" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">J Ovarian Res</journal-id><journal-id journal-id-type="iso-abbrev">J Ovarian Res</journal-id><journal-id journal-id-type="pmc-domain-id">786</journal-id><journal-id journal-id-type="pmc-domain">jovares</journal-id><journal-title-group><journal-title>Journal of Ovarian Research</journal-title></journal-title-group><issn pub-type="epub">1757-2215</issn><publisher><publisher-name>BMC</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC11539702</article-id><article-id pub-id-type="pmcid-ver">PMC11539702.1</article-id><article-id pub-id-type="pmcaid">11539702</article-id><article-id pub-id-type="pmcaiid">11539702</article-id><article-id pub-id-type="pmid">39506832</article-id><article-id pub-id-type="doi">10.1186/s13048-024-01544-8</article-id><article-id pub-id-type="publisher-id">1544</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Machine learning models in evaluating the malignancy risk of ovarian tumors: a comparative study</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>He</surname><given-names initials="X">Xin</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Bai</surname><given-names initials="XH">Xiang-Hui</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" corresp="yes"><name name-style="western"><surname>Chen</surname><given-names initials="H">Hui</given-names></name><address><email>ch11516@rjh.com.cn</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes"><name name-style="western"><surname>Feng</surname><given-names initials="WW">Wei-Wei</given-names></name><address><email>fww12066@rjh.com.cn</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.16821.3c</institution-id><institution-id institution-id-type="ISNI">0000 0004 0368 8293</institution-id><institution>Department of Obstetrics and Gynecology, </institution><institution>Ruijin Hospital, Shanghai Jiaotong University School of Medicine, </institution></institution-wrap>Shanghai, 200025 P.R. China </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02zhqgq86</institution-id><institution-id institution-id-type="GRID">grid.194645.b</institution-id><institution-id institution-id-type="ISNI">0000 0001 2174 2757</institution-id><institution>Department of Obstetrics and Gynaecology, School of Clinical Medicine, Li Ka Shing Faculty of Medicine, </institution><institution>The University of Hong Kong, Hong Kong Special Administrative Region, </institution></institution-wrap>Hong Kong, P.R. China </aff><aff id="Aff3"><label>3</label>Philips Health Technology (China) Co., Ltd. Shanghai Branch, 718 Lingshi Road, Shanghai, 200072 P.R. China </aff></contrib-group><pub-date pub-type="epub"><day>6</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><volume>17</volume><issue-id pub-id-type="pmc-issue-id">452109</issue-id><elocation-id>219</elocation-id><history><date date-type="received"><day>21</day><month>6</month><year>2024</year></date><date date-type="accepted"><day>23</day><month>10</month><year>2024</year></date></history><pub-history><event event-type="pmc-release"><date><day>06</day><month>11</month><year>2024</year></date></event><event event-type="pmc-live"><date><day>06</day><month>11</month><year>2024</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2024-11-08 12:25:32.213"><day>08</day><month>11</month><year>2024</year></date></event></pub-history><permissions><copyright-statement>&#169; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article&#8217;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#8217;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>.</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="13048_2024_Article_1544.pdf"/><abstract id="Abs1"><sec><title>Objectives</title><p id="Par1">The study aimed to compare the diagnostic efficacy of the machine learning models with expert subjective assessment (SA) in assessing the malignancy risk of ovarian tumors using transvaginal ultrasound (TVUS).</p></sec><sec><title>Methods</title><p id="Par2">The retrospective single-center diagnostic study included 1555 consecutive patients from January 2019 to May 2021. Using this dataset, Residual Network(ResNet), Densely Connected Convolutional Network(DenseNet), Vision Transformer(ViT), and Swin Transformer models were established and evaluated separately or combined with Cancer antigen 125 (CA 125). The diagnostic performance was then compared with SA.</p></sec><sec><title>Results</title><p id="Par3">Of the 1555 patients, 76.9% were benign, while 23.1% were malignant (including borderline). When differentiating the malignant from ovarian tumors, the SA had an AUC of 0.97 (95% CI, 0.93&#8211;0.99), sensitivity of 87.2%, and specificity of 98.4%. Except for Vision Transformer, other machine learning models had diagnostic performance comparable to that of the expert. The DenseNet model had an AUC of 0.91 (95% CI, 0.86&#8211;0.95), sensitivity of 84.6%, and specificity of 95.1%. The ResNet50 model had an AUC of 0.91 (0.85&#8211;0.95). The Swin Transformer model had an AUC of 0.92 (0.87&#8211;0.96), sensitivity of 87.2%, and specificity of 94.3%. There was a statistically significant difference between the Vision Transformer and SA, and between the Vision Transformer and Swin Transformer models (AUC: 0.87 vs. 0.97, <italic toggle="yes">P</italic>&#8201;=&#8201;0.01; AUC: 0.87 vs. 0.92, <italic toggle="yes">P</italic>&#8201;=&#8201;0.04). Adding CA125 did not improve the diagnostic performance of the models in distinguishing benign and malignant ovarian tumors.</p></sec><sec><title>Conclusion</title><p id="Par4">The deep learning model of TVUS can be used in ovarian cancer evaluation, and its diagnostic performance is comparable to that of expert assessment.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Ovarian cancer</kwd><kwd>Ultrasound</kwd><kwd>Machine learning</kwd><kwd>Diagnostic models</kwd></kwd-group><funding-group><award-group><funding-source><institution>Medical Innovation Project of Shanghai Science and Technology Commission</institution></funding-source><award-id>20Y11914000</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>82172601</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution>Natural Science Foundation of Shanghai Science and Technology Commission</institution></funding-source><award-id>20ZR1433700</award-id></award-group></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#169; BioMed Central Ltd., part of Springer Nature 2024</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p id="Par5">Ovarian Cancer (OC) is a major concern for women, with the highest mortality rate among gynecological cancers [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Accurate classification of these groups prior to surgery is vital for determining appropriate treatment [<xref ref-type="bibr" rid="CR3">3</xref>]. Precise laboratory test such as CA125, a protein biomarker, is commonly used in clinical practice to assess ovarian cancer [<xref ref-type="bibr" rid="CR4">4</xref>]. Elevated levels of CA125 can indicate the presence of ovarian cancer, however, it is important to note that CA125 levels can be elevated in non-cancerous conditions as well, namely endometriosis or pelvic inflammatory disease and not all ovarian cancers produce high levels of CA125 [<xref ref-type="bibr" rid="CR5">5</xref>]. As a consequence, ultrasound (US) is currently the preferred imaging modality for evaluating ovarian cancer due to its convenience, sensitivity, and affordability [<xref ref-type="bibr" rid="CR6">6</xref>]. The great disadvantage of ultrasound is the strong operator dependence, an expert&#8217;s subjective assessment is still the most reliable evaluation of adnexal pathology [<xref ref-type="bibr" rid="CR7">7</xref>]. To resolve this issue, The diagnostic ultrasound approach has undergone significant advancements, transitioning from subjective experience-based evaluation to more structural evidence-based algorithms such as Simple Rules (SR), the ADNEX, LR1, LR2 risk models [<xref ref-type="bibr" rid="CR8">8</xref>&#8211;<xref ref-type="bibr" rid="CR11">11</xref>].</p><p id="Par6">Machine learning, especially deep learning domain is a fascinating and powerful tool for computer vision. It becomes a promising and robust tool in ultrasound imaging classification, detection, and segmentation [<xref ref-type="bibr" rid="CR12">12</xref>]. In a study by Christiansen et al., two innovative deep neural networks were constructed for diagnosing ovarian cancer [<xref ref-type="bibr" rid="CR13">13</xref>]. Ovry-Dx1 achieved a sensitivity of 96.0% and a specificity comparable to clinical experts, while Ovry-Dx2 demonstrated a sensitivity of 97.1% and a specificity of 93%. Combined with expert evaluation, they significantly increased overall sensitivity (96.0%) and specificity (89.3%).Additionally, a collaborative study with 10 hospitals revealed that the machine learning model outperformed the average diagnostic level of radiologists matched the level of expert ultrasound image readers for ovarian tumors [<xref ref-type="bibr" rid="CR14">14</xref>]. Furthermore, our previous research involving 422 patients found that the ResNet performed comparably to expert subjective assessments (SA) and the Ovarian-Adnexal Reporting and Data System [<xref ref-type="bibr" rid="CR15">15</xref>].</p><p id="Par7">In recent years, advancements in powerful hardware, new optimized techniques, software libraries, and large datasets has accelerated its growth and led to the emergence of new architectures such as the transformer. The Transformer, an attention mechanism-based model, has shown exceptional performance in various computer vision tasks, including tumor segmentation and classification [<xref ref-type="bibr" rid="CR16">16</xref>]. In our study, we harnessed the potential of four cutting-edge deep learning pre-trained architectures, namely ResNet, DenseNet, Vision Transformer, and Swin Transformer, to differentiate the malignancy risk of ovarian tumors in ultrasound images and compare them to subjective assessment performed by an expert. Additionally, we explored the integration of CA125 for joint diagnosis purposes.</p></sec><sec id="Sec2"><title>Methods</title><sec id="Sec3"><title>Patients</title><p id="Par8">This single-center, retrospective, diagnostic accuracy study was conducted at the Department of Obstetrics and Gynecology at Ruijin Hospital in Shanghai, China, a tertiary referral oncology center. Between January 2019 and May 2021, 1,632 patients with an ultrasound diagnosis of an adnexal mass were consecutively enrolled. Inclusion criteria included the presence of at least one non-physiologic adnexal mass detected by transvaginal or transrectal ultrasonography, patient willingness to undergo surgery, less than 30 days between ultrasound and surgery, and no previous history of ovarian cancer. Exclusion criteria were histopathologic analysis&#8211;confirmed uterine sarcomas or non-gynecologic tumors, inconclusive histopathologic results, lack of medical records, or poor US image quality.</p></sec><sec id="Sec4"><title>Data collection</title><p id="Par9">Preoperative transvaginal ultrasonography was performed on all patients, with transabdominal ultrasound added if malignancy was suspected or if the mass was too large for transvaginal assessment alone. Ultrasound machines used were GE Voluson E10(GE Healthcare) and Philips IU22 and Philips A70 and EPIQ5(Philips Healthcare) with 5.0&#8211;9.0&#160;MHz, and 3.0&#8211; 10.0&#160;MHz transvaginal probes, respectively, and 1.0&#8211;5.0&#160;MHz transabdominal probes. Clinical data including age, cancer antigen 125(CA125), pathologic results and ultrasonographic findings were recorded for each patient.</p></sec><sec id="Sec5"><title>Subjective assessment</title><p id="Par10">An experienced ultrasound expert (H.C.) with 11 years of clinical experience and 16 years of US experience assessed the sonographic tumor morphology according to the IOTA Group [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR17">17</xref>].</p><p id="Par11">In cases where multiple adnexal masses were present in a patient, the mass with the most complex ultrasound morphology was selected for risk estimation, if the masses had similar morphology, the largest tumor was chosen for inclusion in the study [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. The expert subjectively evaluated the malignancy of tumors, as following: 1, certainly benign; 2, probably benign; 3, uncertain but most likely benign; 4, uncertain but most likely malignant; 5, probably malignant; and 6, certainly malignant with criteria defined by Meys et al. [<xref ref-type="bibr" rid="CR18">18</xref>].</p></sec><sec id="Sec6"><title>Machine learning algorithm</title><p id="Par12">In this paper, four deep leaning models were utilized for ovarian tumor risk stratification on ultrasound, which are:</p><p id="Par13">
<list list-type="bullet"><list-item><p id="Par14">Residual Network(ResNet) [<xref ref-type="bibr" rid="CR19">19</xref>]: ResNet introduces the concept of residual learning to address the degradation problem faced by very deep neural networks. The basic building block of ResNet is the residual block, which contains skip connections (shortcuts) that allow gradients to flow more directly during training. By using residual connections, ResNet can train very deep networks (e.g., hundreds of layers) without suffering from vanishing gradients or degradation in performance.</p></list-item><list-item><p id="Par15">Densely Connected Convolutional Network(DenseNet) [<xref ref-type="bibr" rid="CR20">20</xref>]: DenseNet introduces dense connections between layers, where each layer receives direct input from all preceding layers and passes its own feature maps to all subsequent layers. Dense connections facilitate feature reuse and promote feature propagation throughout the network. By densely connecting layers, DenseNet encourages feature reuse, reduces the number of parameters, and enhances gradient flow, leading to improved performance and efficiency.</p></list-item><list-item><p id="Par16">Vision Transformer(ViT) [<xref ref-type="bibr" rid="CR21">21</xref>]: ViT applies the transformer architecture, originally designed for sequence processing tasks like natural language processing (NLP), to image classification. ViT breaks down an image into fixed-size patches and flattens them into sequences, which are then fed into a transformer encoder. The transformer encoder processes these patches with self-attention mechanisms, capturing global dependencies and relationships between patches to make classification decisions. ViT has shown strong performance on image classification tasks, especially when pre-trained on large-scale datasets.</p></list-item><list-item><p id="Par17">Swin Transformer [<xref ref-type="bibr" rid="CR22">22</xref>]: Swin Transformer is an extension of the transformer architecture specifically designed for vision tasks, aiming to handle both local and global dependencies efficiently. Unlike ViT, Swin Transformer adopts a hierarchical design with multiple stages, each containing a set of layers with local self-attention mechanisms. Swin Transformer employs shifted windows for self-attention computation, allowing it to capture both local and global information effectively. By leveraging hierarchical structures and shifted windows, Swin Transformer achieves strong performance on various vision tasks, including image classification, object detection, and segmentation.</p></list-item></list>
</p><p id="Par18">For these four machine learning model development, we used Python 3.8 along with the PyTorch 2.1.2 deep learning library. Additionally, the models were pretrained on ImageNet-1&#160;K dataset and finetuned with ovary ultrasound images. Three categories of US images were taken as input for the Deep learning(DL) algorithms, including gray scale US images depicting the plane with the maximum dimension and its orthogonal plane (two images per patient), color Doppler US images (one to three images per patient), and gray scale US images showing the maximum size of the solid component and its orthogonal plane (two images per patient if a solid component was present). In cases where there was no solid component, a blank image filled with zeros was used. The annotated images, where the region of the lesion and its solid component were manually segmented, were generated by the author (H.X.), using an open-source labeling tool (LabelMe).</p><p id="Par19">To ensure unbiased results and model generalization, we followed a rigorous approach to divide the dataset into training, validation, and test sets. The dataset was stratified based on pathology results (benign vs. malignant) to ensure an even distribution of both benign and malignant cases across the subsets. We randomly split the data into training (80%), validation (10%), and test (10%) sets.</p><p id="Par20">To further mitigate the risk of bias, we repeated the random splitting multiple times and evaluated the model performance on different random test sets. This approach ensured that the model performance was not reliant on any specific partition of the dataset.</p><p id="Par21">Before input to the neural network, several preprocessing operations were applied to the original image which include:</p><p id="Par22">
<list list-type="bullet"><list-item><p id="Par23">Crop: this operation is used to crop the region of ovary from the original ultrasound image,</p></list-item><list-item><p id="Par24">Resize: this operation resizes the cropped image to 256px x 256px;</p></list-item><list-item><p id="Par25">Remove caliper: this operation uses image processing method to remove measurement calipers burned on the image.</p></list-item></list>
</p><p id="Par26">For model training, cross entropy loss were used with Adam optimizer. The learning rates were set from 1e-5 to 1e-4 and for different models, it took 50 to 100 epochs to train the models.</p><p id="Par27">The image processing procedure is illustrated in Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref>. Three categories of US images were input to the network after preprocessing operations. DL models output the malignancy score for every input image and all these scores were averaged pooled to obtain the final prediction probabilities for each case. The final decision of benign or malignant was determined by comparing the output malignancy probability with a preselected cutoff threshold. This threshold aimed to achieve an optimal balance between sensitivity and specificity, maximizing the Youden Index value.</p><p id="Par28">To better illustrate which part of the ultrasound image that most impact the classification result, this section utilizes Grad-CAM [<xref ref-type="bibr" rid="CR23">23</xref>] to present heat maps depicting the regions of interest that the model concentrates on.</p><p id="Par29">
<fig id="Fig1" position="float" orientation="portrait"><label>Fig. 1</label><caption><p>Machine learning models flowcharts</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="d33e351" position="float" orientation="portrait" xlink:href="13048_2024_1544_Fig1_HTML.jpg"/></fig>
</p></sec><sec id="Sec7"><title>Reference standard</title><p id="Par30">Histopathological diagnosis post-surgical removal was the reference standard. All patients underwent surgery, and final pathology results were obtained. Excised tissues were examined histologically according to the World Health Organization guidelines for tumor classification [<xref ref-type="bibr" rid="CR24">24</xref>] and staged based on the International Federation of Gynecology and Obstetrics criteria [<xref ref-type="bibr" rid="CR25">25</xref>]. In the final diagnosis, the masses were classified into two types: benign, and malignant, including BOT, Stage-I&#8211;IV OC and secondary metastatic cancer.</p></sec><sec id="Sec8"><title>Statistical analysis</title><p id="Par31">SPSS version 22.0 (IBM Corp) and MedCalc version 15.2.2 (MedCalc Software) were used for statistical analysis. Sensitivity, specificity, positive predictive value, negative predictive value, positive likelihood ratio, negative likelihood ratio, and diagnostic odds ratiowere calculated. To compare the diagnostic performances among machine learning (ML) models and expert assessment, receiver operating characteristic curves(ROCs) were constructed and the areas under the receiver operating characteristic curves (AUCs) were calculated. Comparisons between AUCs were made by using the DeLong test. Cutoff values with optimal balance between sensitivity and specificity that maximize the Youden index in receiver operating characteristic curves were used to dichotomize the test set (i.e., the mass was classified as malignant when the scores extracted from ML models, and expert assessment were higher than the cutoff value). Tumor characteristics, patient features, and tumor marker levels were compared using appropriate statistical tests. All the statistical calculations were performed with 95% CIs and statistical significance was set at <italic toggle="yes">P</italic>&#8201;&lt;&#8201;0.05. For the purposes of statistical analyses, borderline ovarian tumors were classified as malignant [<xref ref-type="bibr" rid="CR26">26</xref>].</p></sec><sec id="Sec9"><title>Ethical statement</title><p id="Par32">This study was approved by the Ruijin Hospital, Shanghai Jiaotong University School of Medicine institutional ethics committee with exemption to obtain informed consent from individual patients (Grant No.2023-21). Written informed consent was waived due to the retrospective data collection. The study followed Good Clinical Practice (GCP) guidelines and the Netherlands Code of Conduct for Research Integrity.</p></sec></sec><sec id="Sec10" sec-type="results"><title>Results</title><sec id="Sec11"><title>Patient characteristics</title><p id="Par33">In this study, a total of 1,632 patients with adnexal tumors detected by ultrasound examination at the Department of Obstetrics and Gynecology, Ruijin Hospital affiliated to Shanghai Jiao Tong University School of Medicine between January 2019 and May 2021 were included. After applying exclusion criteria, 1,555 patients were analyzed, including 1,196 (76.9%) patients with benign tumors and 359 (23.1%) patients with malignant tumors. The flowchart of enrollment is shown in Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref>. Pathological results of the patients are summarized in Table&#160;<xref rid="Tab1" ref-type="table">1</xref>, whereas demographic and clinical characteristics are presented in Table&#160;<xref rid="Tab2" ref-type="table">2</xref>.</p><p id="Par34">The dataset was divided according to an 8:1:1 ratio, resulting in a training set (containing 956 benign and 285 malignant cases; totaling 7,493 images; 80%), a validation set (consisting of 119 benign and 35 malignant cases; comprising 799 images; 10%), and a test set (comprising 121 benign and 39 malignant cases; encompassing 818 images; 10%). Demographic and clinical characteristics between the training, validation, and test sets were consistent, as detailed in Table&#160;<xref rid="Tab3" ref-type="table">3</xref>. There were no significant differences in age, CA125 levels, or other key clinical features, thus ensuring that the test set was representative of the patient population and reducing potential bias.</p><p id="Par35">Significant differences were observed between benign and malignant tumors with respect to clinical and ultrasound characteristics. The mean age of patients with malignant tumors was higher than that of patients with benign tumors, with a median age at diagnosis of 54.0 and 41.0 years, respectively (<italic toggle="yes">p</italic>&#8201;&lt;&#8201;0.001). Serum tumor markers showed significantly higher levels in patients with malignant tumors compared to those with benign tumors, as reflected by median values of CA125 (122.2 vs. 17.6, <italic toggle="yes">p</italic>&#8201;&lt;&#8201;0.001). Ultrasound features also differed significantly between benign and malignant adnexal tumors. Malignant tumors had larger diameters for both mass and solid components (74 vs. 55&#160;mm, <italic toggle="yes">p</italic>&#8201;&lt;&#8201;0.001; 50 vs. 24&#160;mm, <italic toggle="yes">p</italic>&#8201;&lt;&#8201;0.001) and more abundant blood flow (<italic toggle="yes">p</italic>&#8201;&lt;&#8201;0.001). There were also notable differences in tumor type between the two groups, with malignant tumors occurring more frequently in masses with solid component, while benign tumors were more likely to be simple cysts. Additionally, malignant tumors were frequently associated with pelvic fluid, ascites, or pelvic nodules (<italic toggle="yes">p</italic>&#8201;&lt;&#8201;0.001).</p><p id="Par36">
<fig id="Fig2" position="float" orientation="portrait"><label>Fig. 2</label><caption><p>Flowchart of enrollment in study cohort</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="d33e426" position="float" orientation="portrait" xlink:href="13048_2024_1544_Fig2_HTML.jpg"/></fig>
</p><p id="Par37">
<table-wrap id="Tab1" position="float" orientation="portrait"><label>Table 1</label><caption><p>Histopathological findings in 1555 women with adnexal mass</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1"/><th align="left" colspan="1" rowspan="1">Histologic Type</th><th align="left" colspan="1" rowspan="1">
<italic toggle="yes">N</italic>
</th><th align="left" colspan="1" rowspan="1">%</th></tr></thead><tbody><tr><td align="left" colspan="2" rowspan="1">Benign</td><td align="left" colspan="1" rowspan="1">1196</td><td align="left" colspan="1" rowspan="1">76.91</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Endometrioid Cystadenoma</td><td align="left" colspan="1" rowspan="1">420</td><td align="left" colspan="1" rowspan="1">27.01</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Teratoma</td><td align="left" colspan="1" rowspan="1">221</td><td align="left" colspan="1" rowspan="1">14.21</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Serous Cystadenoma</td><td align="left" colspan="1" rowspan="1">192</td><td align="left" colspan="1" rowspan="1">12.35</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Mucinous Cystadenoma</td><td align="left" colspan="1" rowspan="1">78</td><td align="left" colspan="1" rowspan="1">5.02</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Fibroma and Related Tumors</td><td align="left" colspan="1" rowspan="1">71</td><td align="left" colspan="1" rowspan="1">4.57</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Simple Cyst</td><td align="left" colspan="1" rowspan="1">67</td><td align="left" colspan="1" rowspan="1">4.31</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Mesosalpinx cyst</td><td align="left" colspan="1" rowspan="1">54</td><td align="left" colspan="1" rowspan="1">3.47</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Salpingitis</td><td align="left" colspan="1" rowspan="1">47</td><td align="left" colspan="1" rowspan="1">3.02</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Fibrothecoma</td><td align="left" colspan="1" rowspan="1">19</td><td align="left" colspan="1" rowspan="1">1.22</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Paraovarian Cyst</td><td align="left" colspan="1" rowspan="1">5</td><td align="left" colspan="1" rowspan="1">0.32</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Sertoli-Leydig Cell Tumor (High Grade)</td><td align="left" colspan="1" rowspan="1">5</td><td align="left" colspan="1" rowspan="1">0.32</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Benign Brenner Tumor</td><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">0.26</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Seromucinous Cystadenoma</td><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">0.26</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Other ovarian benign lesion</td><td align="left" colspan="1" rowspan="1">9</td><td align="left" colspan="1" rowspan="1">0.58</td></tr><tr><td align="left" colspan="2" rowspan="1">Borderline ovarian tumor</td><td align="left" colspan="1" rowspan="1">53</td><td align="left" colspan="1" rowspan="1">3.41</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Serous</td><td align="left" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">1.80</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Mucinous</td><td align="left" colspan="1" rowspan="1">21</td><td align="left" colspan="1" rowspan="1">1.35</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Endometrioid</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">0.13</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Brenner Tumor</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">0.13</td></tr><tr><td align="left" colspan="2" rowspan="1">Primary ovarian malignant</td><td align="left" colspan="1" rowspan="1">252</td><td align="left" colspan="1" rowspan="1">16.21</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Serous Adenocarcinoma</td><td align="left" colspan="1" rowspan="1">167</td><td align="left" colspan="1" rowspan="1">10.74</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Clear Cell Carcinoma</td><td align="left" colspan="1" rowspan="1">30</td><td align="left" colspan="1" rowspan="1">1.93</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Endometrioid Adenocarcinoma</td><td align="left" colspan="1" rowspan="1">25</td><td align="left" colspan="1" rowspan="1">1.61</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Mucinous Adenocarcinoma</td><td align="left" colspan="1" rowspan="1">9</td><td align="left" colspan="1" rowspan="1">0.58</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Granulosa Cell Tumor</td><td align="left" colspan="1" rowspan="1">9</td><td align="left" colspan="1" rowspan="1">0.58</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Carcinosarcoma</td><td align="left" colspan="1" rowspan="1">1</td><td align="left" colspan="1" rowspan="1">0.06</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Sarcoma</td><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">0.19</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Neuroendocrine Carcinoma</td><td align="left" colspan="1" rowspan="1">1</td><td align="left" colspan="1" rowspan="1">0.06</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Sertoli-Leydig Cell Tumor (Low Grade)</td><td align="left" colspan="1" rowspan="1">1</td><td align="left" colspan="1" rowspan="1">0.06</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Fibrosarcoma</td><td align="left" colspan="1" rowspan="1">1</td><td align="left" colspan="1" rowspan="1">0.06</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Malignant Teratoma</td><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">0.19</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Dysgerminoma</td><td align="left" colspan="1" rowspan="1">1</td><td align="left" colspan="1" rowspan="1">0.06</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">Yolk sac tumor</td><td align="left" colspan="1" rowspan="1">1</td><td align="left" colspan="1" rowspan="1">0.06</td></tr><tr><td align="left" colspan="2" rowspan="1">Ovarian metastasis</td><td align="left" colspan="1" rowspan="1">54</td><td align="left" colspan="1" rowspan="1">3.47</td></tr></tbody></table></table-wrap>
</p><p id="Par38">
<table-wrap id="Tab2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Demographic and Clinical Characteristics of patients with benign and malignant ovarian tumors (<italic toggle="yes">n</italic>&#8201;=&#8201;1555)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Characteristic</th><th align="left" colspan="1" rowspan="1">Benign (<italic toggle="yes">n</italic>&#8201;=&#8201;1196)</th><th align="left" colspan="1" rowspan="1">Malignant (<italic toggle="yes">n</italic>&#8201;=&#8201;359)</th><th align="left" colspan="1" rowspan="1"><italic toggle="yes">P</italic> value</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">Age (years)</td><td align="left" colspan="1" rowspan="1">41.0 (32.0&#8211;55.0)</td><td align="left" colspan="1" rowspan="1">54.0 (43.0&#8211;64.0)</td><td align="left" colspan="1" rowspan="1">&lt;&#8201;0.001</td></tr><tr><td align="left" colspan="1" rowspan="1">Menopausal Status</td><td align="left" colspan="1" rowspan="1">Pre/Post (845/351)</td><td align="left" colspan="1" rowspan="1">Pre/Post (159/200)</td><td align="left" colspan="1" rowspan="1">&lt;&#8201;0.001</td></tr><tr><td align="left" colspan="1" rowspan="1">CA125 (U/mL)</td><td align="left" colspan="1" rowspan="1">17.6 (10.1&#8211;40.0)</td><td align="left" colspan="1" rowspan="1">122.2 (23.4-791.5)</td><td align="left" colspan="1" rowspan="1">&lt;&#8201;0.001</td></tr><tr><td align="left" colspan="1" rowspan="1"><p>Maximum lesion</p><p>diameter (mm)*</p></td><td align="left" colspan="1" rowspan="1">55.0 (39.0&#8211;76.0)</td><td align="left" colspan="1" rowspan="1">74.0 (46.0-115.0)</td><td align="left" colspan="1" rowspan="1">&lt;&#8201;0.001</td></tr><tr><td align="left" colspan="1" rowspan="1">Solid Component</td><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">No. of solid components</td><td align="left" colspan="1" rowspan="1">124 (10.4)</td><td align="left" colspan="1" rowspan="1">165 (46.0)</td><td align="left" colspan="1" rowspan="1">&lt;&#8201;0.001</td></tr><tr><td align="left" colspan="1" rowspan="1">Maximum largest solid component diameter (mm)*</td><td align="left" colspan="1" rowspan="1">24.0 (12.0&#8211;39.0)</td><td align="left" colspan="1" rowspan="1">50.0 (33.0&#8211;78.0)</td><td align="left" colspan="1" rowspan="1">&lt;&#8201;0.001</td></tr><tr><td align="left" colspan="1" rowspan="1">Color Doppler score</td><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">No flow, score 1</td><td align="left" colspan="1" rowspan="1">725 (60.6)</td><td align="left" colspan="1" rowspan="1">38 (10.6)</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Minimal flow, score 2</td><td align="left" colspan="1" rowspan="1">322 (26.9)</td><td align="left" colspan="1" rowspan="1">60 (16.7)</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Moderate flow, score 3</td><td align="left" colspan="1" rowspan="1">79 (6.6)</td><td align="left" colspan="1" rowspan="1">57 (15.9)</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Very strong flow, score 4</td><td align="left" colspan="1" rowspan="1">70 (5.9)</td><td align="left" colspan="1" rowspan="1">204 (56.8)</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">External Contour</td><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Regular</td><td align="left" colspan="1" rowspan="1">187 (59.7)</td><td align="left" colspan="1" rowspan="1">134 (41.9)</td><td align="left" colspan="1" rowspan="1">&lt;&#8201;0.001</td></tr><tr><td align="left" colspan="1" rowspan="1">Irregular</td><td align="left" colspan="1" rowspan="1">126 (40.3)</td><td align="left" colspan="1" rowspan="1">186 (58.1)</td><td align="left" colspan="1" rowspan="1">&lt;&#8201;0.001</td></tr><tr><td align="left" colspan="1" rowspan="1">Internal Wall</td><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Smooth</td><td align="left" colspan="1" rowspan="1">546 (50.9)</td><td align="left" colspan="1" rowspan="1">17 (8.8)</td><td align="left" colspan="1" rowspan="1">&lt;&#8201;0.001</td></tr><tr><td align="left" colspan="1" rowspan="1">Irregular</td><td align="left" colspan="1" rowspan="1">526 (49.1)</td><td align="left" colspan="1" rowspan="1">177 (91.2)</td><td align="left" colspan="1" rowspan="1">&lt;&#8201;0.001</td></tr><tr><td align="left" colspan="1" rowspan="1">Ascites</td><td align="left" colspan="1" rowspan="1">12 (1.0)</td><td align="left" colspan="1" rowspan="1">96 (26.7)</td><td align="left" colspan="1" rowspan="1">&lt;&#8201;0.001</td></tr><tr><td align="left" colspan="1" rowspan="1">Pelvic Nodules</td><td align="left" colspan="1" rowspan="1">16 (1.3)</td><td align="left" colspan="1" rowspan="1">78 (21.7)</td><td align="left" colspan="1" rowspan="1">&lt;&#8201;0.001</td></tr></tbody></table></table-wrap>
</p><p id="Par39">
<table-wrap id="Tab3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Demographic and Clinical Characteristics of patients in training set, validation set and test set (<italic toggle="yes">n</italic>&#8201;=&#8201;1555)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Characteristic</th><th align="left" colspan="1" rowspan="1">Training Set (<italic toggle="yes">n</italic>&#8201;=&#8201;1241)</th><th align="left" colspan="2" rowspan="1">Validation Set (<italic toggle="yes">n</italic>&#8201;=&#8201;154)</th><th align="left" colspan="1" rowspan="1">Test Set (<italic toggle="yes">n</italic>&#8201;=&#8201;160)</th><th align="left" colspan="1" rowspan="1"><italic toggle="yes">P</italic> value</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">Benign/ Malignant</td><td align="left" colspan="1" rowspan="1">956/285</td><td align="left" colspan="1" rowspan="1">119/35</td><td align="left" colspan="2" rowspan="1">121/39</td><td align="left" colspan="1" rowspan="1">0.918</td></tr><tr><td align="left" colspan="1" rowspan="1">Age (years)</td><td align="left" colspan="1" rowspan="1">44.0 (33.0&#8211;57.0)</td><td align="left" colspan="1" rowspan="1">45.0 (34.0&#8211;58.0)</td><td align="left" colspan="2" rowspan="1">46.0 (33.8&#8211;63.0)</td><td align="left" colspan="1" rowspan="1">0.134</td></tr><tr><td align="left" colspan="1" rowspan="1">Menopausal Status (Pre/Post)</td><td align="left" colspan="1" rowspan="1">812/429</td><td align="left" colspan="1" rowspan="1">99/55</td><td align="left" colspan="2" rowspan="1">93/67</td><td align="left" colspan="1" rowspan="1">0.191</td></tr><tr><td align="left" colspan="1" rowspan="1">CA125 (U/mL)</td><td align="left" colspan="1" rowspan="1">22.0 (10.9&#8211;68.3)</td><td align="left" colspan="1" rowspan="1">20.8 (11.0&#8211;70.0)</td><td align="left" colspan="2" rowspan="1">19.2 (11.1&#8211;51.0)</td><td align="left" colspan="1" rowspan="1">0.484</td></tr><tr><td align="left" colspan="1" rowspan="1"><p>Maximum lesion</p><p>diameter (mm)*</p></td><td align="left" colspan="1" rowspan="1">58.0 (40.0&#8211;84.0)</td><td align="left" colspan="1" rowspan="1">53.0 (38.0-78.8)</td><td align="left" colspan="2" rowspan="1">56.5 (41.0-77.2)</td><td align="left" colspan="1" rowspan="1">0.805</td></tr><tr><td align="left" colspan="1" rowspan="1">Solid Component</td><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="2" rowspan="1"/><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">No. of solid components</td><td align="left" colspan="1" rowspan="1">225 (18.1)</td><td align="left" colspan="1" rowspan="1">29 (18.8)</td><td align="left" colspan="2" rowspan="1">35 (21.9)</td><td align="left" colspan="1" rowspan="1">0.172</td></tr><tr><td align="left" colspan="1" rowspan="1">Maximum largest solid component diameter (mm)*</td><td align="left" colspan="1" rowspan="1">36.5 (18.0&#8211;62.0)</td><td align="left" colspan="1" rowspan="1">34.0 (19.5&#8211;53.0)</td><td align="left" colspan="2" rowspan="1">38.5 (20.2&#8211;57.8)</td><td align="left" colspan="1" rowspan="1">0.963</td></tr><tr><td align="left" colspan="1" rowspan="1">Color Doppler score</td><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="2" rowspan="1"/><td align="left" colspan="1" rowspan="1">0.227</td></tr><tr><td align="left" colspan="1" rowspan="1">No flow, score 1</td><td align="left" colspan="1" rowspan="1">594 (47.9)</td><td align="left" colspan="1" rowspan="1">83 (53.9)</td><td align="left" colspan="2" rowspan="1">86 (53.8)</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Minimal flow, score 2</td><td align="left" colspan="1" rowspan="1">311 (25.1)</td><td align="left" colspan="1" rowspan="1">36 (23.4)</td><td align="left" colspan="2" rowspan="1">35 (21.9)</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Moderate flow, score 3</td><td align="left" colspan="1" rowspan="1">118 (9.5)</td><td align="left" colspan="1" rowspan="1">11 (7.1)</td><td align="left" colspan="2" rowspan="1">7 (4.4)</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Very strong flow, score 4</td><td align="left" colspan="1" rowspan="1">218 (17.6)</td><td align="left" colspan="1" rowspan="1">24 (15.6)</td><td align="left" colspan="2" rowspan="1">32 (20.0)</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">External Contour</td><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="2" rowspan="1"/><td align="left" colspan="1" rowspan="1">0.588</td></tr><tr><td align="left" colspan="1" rowspan="1">Regular</td><td align="left" colspan="1" rowspan="1">291 (54.0)</td><td align="left" colspan="1" rowspan="1">35 (58.3)</td><td align="left" colspan="2" rowspan="1">35 (54.7)</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Irregular</td><td align="left" colspan="1" rowspan="1">248 (46.0)</td><td align="left" colspan="1" rowspan="1">25 (41.7)</td><td align="left" colspan="2" rowspan="1">29 (45.3)</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Internal Wall</td><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="2" rowspan="1"/><td align="left" colspan="1" rowspan="1">0.208</td></tr><tr><td align="left" colspan="1" rowspan="1">Smooth</td><td align="left" colspan="1" rowspan="1">425 (41.8)</td><td align="left" colspan="1" rowspan="1">60 (48.0)</td><td align="left" colspan="2" rowspan="1">58(46.4)</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Irregular</td><td align="left" colspan="1" rowspan="1">591 (58.2)</td><td align="left" colspan="1" rowspan="1">65 (52.0)</td><td align="left" colspan="2" rowspan="1">67 (53.6)</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Ascites</td><td align="left" colspan="1" rowspan="1">91 (7.3)</td><td align="left" colspan="1" rowspan="1">8 (5.2)</td><td align="left" colspan="2" rowspan="1">9 (5.6)</td><td align="left" colspan="1" rowspan="1">0.484</td></tr><tr><td align="left" colspan="1" rowspan="1">Pelvic Nodules</td><td align="left" colspan="1" rowspan="1">80 (6.4)</td><td align="left" colspan="1" rowspan="1">7 (4.5)</td><td align="left" colspan="2" rowspan="1">7 (4.4)</td><td align="left" colspan="1" rowspan="1">0.417</td></tr></tbody></table></table-wrap>
</p></sec><sec id="Sec12"><title>Diagnostic performance of adnexal mass prediction models</title><p id="Par40">Table&#160;<xref rid="Tab4" ref-type="table">4</xref> compares the efficacy of different models, namely ResNet50, DenseNet, Vision Transformer, Swin Transformer, and SA, in identifying benign and malignant ovarian tumors (Figure <xref rid="Fig3" ref-type="fig">3</xref>). The evaluation metrics used include AUC, sensitivity, specificity, NPV, PPV, Youden index, cutoff value, +LR, -LR, and DOR. The figure depicts the comparison of AUCcurves for different machine learning models. The x-axis represents the false positive rate (FPR), and the y-axis represents the true positive rate (TPR).</p><p id="Par43">
<table-wrap id="Tab4" position="float" orientation="portrait"><label>Table 4</label><caption><p>Comparison of the efficacy of ResNet, DenseNet, Vision Transformer, Swin Transformer and SA in identifying benign and malignant ovarian tumors</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Model</th><th align="left" colspan="1" rowspan="1">AUC</th><th align="left" colspan="1" rowspan="1">Sensitivity</th><th align="left" colspan="1" rowspan="1">Specificity</th><th align="left" colspan="1" rowspan="1">NPV</th><th align="left" colspan="1" rowspan="1">PPV</th><th align="left" colspan="1" rowspan="1">Youden index</th><th align="left" colspan="1" rowspan="1">Cutoff</th><th align="left" colspan="1" rowspan="1">+LR</th><th align="left" colspan="1" rowspan="1">-LR</th><th align="left" colspan="1" rowspan="1">DOR</th><th align="left" colspan="1" rowspan="1"/></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">ResNet</td><td align="left" colspan="1" rowspan="1">0.91 (0.85 - 0.95)</td><td align="left" colspan="1" rowspan="1">82.1 (60.7 - 88.9)</td><td align="left" colspan="1" rowspan="1">93.4 (87.5 - 97.1)</td><td align="left" colspan="1" rowspan="1">99.6 (99.2 - 99.8)</td><td align="left" colspan="1" rowspan="1">20.3 (7.2 - 45.7)</td><td align="left" colspan="1" rowspan="1">0.75</td><td align="left" colspan="1" rowspan="1">&gt;0.58</td><td align="left" colspan="1" rowspan="1">11.73</td><td align="left" colspan="1" rowspan="1">0.25</td><td align="left" colspan="1" rowspan="1">46.92</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">DenseNet</td><td align="left" colspan="1" rowspan="1">0.91 (0.86 - 0.95)</td><td align="left" colspan="1" rowspan="1">84.6 (69.5 - 94.1)</td><td align="left" colspan="1" rowspan="1">92.6 (86.5 - 96.6)</td><td align="left" colspan="1" rowspan="1">99.7 (99.3 - 99.8)</td><td align="left" colspan="1" rowspan="1">26.0 (8.1 - 58.4)</td><td align="left" colspan="1" rowspan="1">0.77</td><td align="left" colspan="1" rowspan="1">&gt;0.25</td><td align="left" colspan="1" rowspan="1">11.47</td><td align="left" colspan="1" rowspan="1">0.17</td><td align="left" colspan="1" rowspan="1">67.47</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Vision Transformer</td><td align="left" colspan="1" rowspan="1">0.87 (0.81 - 0.92)</td><td align="left" colspan="1" rowspan="1">84.6 (69.5 - 94.1)</td><td align="left" colspan="1" rowspan="1">81.2 (73.1 - 87.7)</td><td align="left" colspan="1" rowspan="1">99.6 (99.2 - 99.8)</td><td align="left" colspan="1" rowspan="1">8.4 (4.5 - 15.1)</td><td align="left" colspan="1" rowspan="1">0.66</td><td align="left" colspan="1" rowspan="1">&gt;0.17</td><td align="left" colspan="1" rowspan="1">4.49</td><td align="left" colspan="1" rowspan="1">0.19</td><td align="left" colspan="1" rowspan="1">23.63</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Swin Transformer</td><td align="left" colspan="1" rowspan="1">0.92 (0.87 - 0.96)</td><td align="left" colspan="1" rowspan="1">87.2 (72.6 - 95.7)</td><td align="left" colspan="1" rowspan="1">94.3 (88.5 - 97.7)</td><td align="left" colspan="1" rowspan="1">99.7 (99.4 - 99.9)</td><td align="left" colspan="1" rowspan="1">23.7 (7.9 - 52.7)</td><td align="left" colspan="1" rowspan="1">0.81</td><td align="left" colspan="1" rowspan="1">&gt;0.33</td><td align="left" colspan="1" rowspan="1">15.19</td><td align="left" colspan="1" rowspan="1">0.14</td><td align="left" colspan="1" rowspan="1">108.5</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">SA</td><td align="left" colspan="1" rowspan="1">0.97 (0.93 - 0.99)</td><td align="left" colspan="1" rowspan="1">87.2 (72.6 - 95.7)</td><td align="left" colspan="1" rowspan="1">98.4 (94.2 - 99.8)</td><td align="left" colspan="1" rowspan="1">99.7 (99.4 - 99.9)</td><td align="left" colspan="1" rowspan="1">52.0 (8.7 - 92.5)</td><td align="left" colspan="1" rowspan="1">0.86</td><td align="left" colspan="1" rowspan="1">&gt;3</td><td align="left" colspan="1" rowspan="1">53.18</td><td align="left" colspan="1" rowspan="1">0.13</td><td align="left" colspan="1" rowspan="1">409.08</td><td align="left" colspan="1" rowspan="1"/></tr></tbody></table></table-wrap>
</p><p id="Par41">Among these models, ResNet50, DenseNet, Swin Transformer, and SA achieved high AUC values of 0.91, 0.91, 0.92, and 0.97, respectively. Vision Transformer had a slightly lower AUC of 0.87. In terms of sensitivity, Swin Transformer and SA performed the best sensitivity scores, with values of 87.2% for both models. Specificity was highest for SA at 98.4%, followed by Swin Transformer at 94.3%. Vision Transformer had the lowest specificity at 81.2%.</p><p id="Par42">When considering the NPV, all models performed similarly well, with values above 99.6%. However, there were notable differences in PPV. SA had the highest PPV at 52.0%, while Vision Transformer had the lowest at 8.4%. The Youden index, a measure of overall diagnostic performance, was highest for SA at 0.86. Cutoff values were determined for each model, with values ranging from &gt;&#8201;0.17 to &gt;&#8201;3. Additionally, +LR values ranged from 4.49 to 53.18, while -LR values ranged from 0.13 to 0.25. The DOR was highest for SA at 409.08.</p><p id="Par4223">Table&#160;<xref rid="Tab5" ref-type="table">5</xref> further compares the efficacy of models in identifying benign and malignant ovarian tumors, with and without the use of CA125, a biomarker for ovarian cancer (Figure <xref rid="Fig4" ref-type="fig">4</xref>). The evaluation metrics used are similar to those in Table <xref rid="Tab4" ref-type="table">4</xref>. The results showed that the addition of CA125 did not significantly improve the performance of the models in terms of AUC and sensitivity. However, there were slight improvements in PPV and DOR when CA125 was incorporated. Overall, the performance of the models remained consistent regardless of the presence of CA125.</p><p id="Par44">
<fig id="Fig3" position="float" orientation="portrait"><label>Fig. 3</label><caption><p>Comparison of the efficacy of ResNet, DenseNet, Vision Transformer, Swin Transformer and SA in identifying benign and malignant ovarian tumors</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="d33e1405" position="float" orientation="portrait" xlink:href="13048_2024_1544_Fig3_HTML.jpg"/></fig>
</p><p id="Par45">
<table-wrap id="Tab5" position="float" orientation="portrait"><label>Table 5</label><caption><p>Comparison of the efficacy of ResNet, DenseNet, Vision Transformer and Swin Transformer in identifying benign and malignant ovarian tumors with or without CA125</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1"/><th align="left" colspan="1" rowspan="1">AUC</th><th align="left" colspan="1" rowspan="1">Sensitivity</th><th align="left" colspan="1" rowspan="1">Specificity</th><th align="left" colspan="1" rowspan="1">NPV</th><th align="left" colspan="1" rowspan="1">PPV</th><th align="left" colspan="1" rowspan="1">Youden index</th><th align="left" colspan="1" rowspan="1">Cutoff value</th><th align="left" colspan="1" rowspan="1">DOR</th><th align="left" colspan="1" rowspan="1"><italic toggle="yes">P</italic> value</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">ResNet</td><td align="left" colspan="1" rowspan="1">0.91(0.85&#8211;0.95</td><td align="left" colspan="1" rowspan="1">82.1(60.7&#8211;88.9)</td><td align="left" colspan="1" rowspan="1">93.4(87.5&#8211;97.1)</td><td align="left" colspan="1" rowspan="1">99.6(99.2&#8211;99.8)</td><td align="left" colspan="1" rowspan="1">20.3(7.2&#8211;45.7)</td><td align="left" colspan="1" rowspan="1">0.75</td><td align="left" colspan="1" rowspan="1">&gt;&#8201;0.58</td><td align="left" colspan="1" rowspan="1">46.92</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">ResNet&#8201;+&#8201;CA125</td><td align="left" colspan="1" rowspan="1">0.90(0.84&#8211;0.94)</td><td align="left" colspan="1" rowspan="1">82.1(66.5&#8211;92.5)</td><td align="left" colspan="1" rowspan="1">93.4(87.5&#8211;97.1)</td><td align="left" colspan="1" rowspan="1">99.6(99.2&#8211;99.8)</td><td align="left" colspan="1" rowspan="1">20.3(7.2&#8211;45.7)</td><td align="left" colspan="1" rowspan="1">0.75</td><td align="left" colspan="1" rowspan="1">&gt;&#8201;0.38</td><td align="left" colspan="1" rowspan="1">65.84</td><td align="left" colspan="1" rowspan="1">0.29</td></tr><tr><td align="left" colspan="1" rowspan="1">DenseNet</td><td align="left" colspan="1" rowspan="1">0.91(0.86&#8211;0.95)</td><td align="left" colspan="1" rowspan="1">84.6(69.5&#8211;94.1)</td><td align="left" colspan="1" rowspan="1">92.6(86.5&#8211;96.6)</td><td align="left" colspan="1" rowspan="1">99.7(99.3&#8211;99.8)</td><td align="left" colspan="1" rowspan="1">26.0(8.1&#8211;58.4)</td><td align="left" colspan="1" rowspan="1">0.77</td><td align="left" colspan="1" rowspan="1">&gt;&#8201;0.25</td><td align="left" colspan="1" rowspan="1">67.47</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">DenseNet&#8201;+&#8201;CA125</td><td align="left" colspan="1" rowspan="1">0.91(0.85&#8211;0.95)</td><td align="left" colspan="1" rowspan="1">84.6(69.5&#8211;94.1)</td><td align="left" colspan="1" rowspan="1">95.9(90.7&#8211;98.7)</td><td align="left" colspan="1" rowspan="1">99.7(99.3&#8211;99.8)</td><td align="left" colspan="1" rowspan="1">29.6(8.4&#8211;65.9)</td><td align="left" colspan="1" rowspan="1">0.81</td><td align="left" colspan="1" rowspan="1">&gt;&#8201;0.18</td><td align="left" colspan="1" rowspan="1">129.06</td><td align="left" colspan="1" rowspan="1">0.53</td></tr><tr><td align="left" colspan="1" rowspan="1">Vision Transformer</td><td align="left" colspan="1" rowspan="1">0.87(0.81&#8211;0.92)</td><td align="left" colspan="1" rowspan="1">84.6(69.5&#8211;94.1)</td><td align="left" colspan="1" rowspan="1">81.2(73.1&#8211;87.7)</td><td align="left" colspan="1" rowspan="1">99.6(99.2&#8211;99.8)</td><td align="left" colspan="1" rowspan="1">8.4(4.5&#8211;15.1)</td><td align="left" colspan="1" rowspan="1">0.66</td><td align="left" colspan="1" rowspan="1">&gt;&#8201;0.17</td><td align="left" colspan="1" rowspan="1">23.63</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Vision Transformer&#8201;+&#8201;CA125</td><td align="left" colspan="1" rowspan="1">0.87(0.81&#8211;0.92)</td><td align="left" colspan="1" rowspan="1">84.6(69.5&#8211;94.1)</td><td align="left" colspan="1" rowspan="1">79.5(71.3&#8211;86.3)</td><td align="left" colspan="1" rowspan="1">99.6(99.2&#8211;99.8)</td><td align="left" colspan="1" rowspan="1">7.8(4.3&#8211;13.7)</td><td align="left" colspan="1" rowspan="1">0.64</td><td align="left" colspan="1" rowspan="1">&gt;&#8201;0.11</td><td align="left" colspan="1" rowspan="1">21.74</td><td align="left" colspan="1" rowspan="1">0.71</td></tr><tr><td align="left" colspan="1" rowspan="1">Swin Transformer</td><td align="left" colspan="1" rowspan="1">0.92(0.87&#8211;0.96)</td><td align="left" colspan="1" rowspan="1">87.2(72.6&#8211;95.7)</td><td align="left" colspan="1" rowspan="1">94.3(88.5&#8211;97.7)</td><td align="left" colspan="1" rowspan="1">99.7(99.4&#8211;99.9)</td><td align="left" colspan="1" rowspan="1">23.7(7.9&#8211;52.7)</td><td align="left" colspan="1" rowspan="1">0.81</td><td align="left" colspan="1" rowspan="1">&gt;&#8201;0.33</td><td align="left" colspan="1" rowspan="1">108.50</td><td align="left" colspan="1" rowspan="1"/></tr><tr><td align="left" colspan="1" rowspan="1">Swin Transformer&#8201;+&#8201;CA125</td><td align="left" colspan="1" rowspan="1">0.93(0.88&#8211;0.97)</td><td align="left" colspan="1" rowspan="1">87.2(72.6&#8211;95.7)</td><td align="left" colspan="1" rowspan="1">94.3(88.5&#8211;97.7)</td><td align="left" colspan="1" rowspan="1">99.7(99.4&#8211;99.9)</td><td align="left" colspan="1" rowspan="1">23.7(7.9&#8211;52.7)</td><td align="left" colspan="1" rowspan="1">0.81</td><td align="left" colspan="1" rowspan="1">&gt;&#8201;0.25</td><td align="left" colspan="1" rowspan="1">108.50</td><td align="left" colspan="1" rowspan="1">0.23</td></tr><tr><td align="left" colspan="1" rowspan="1">SA</td><td align="left" colspan="1" rowspan="1">0.97(0.93&#8211;0.99)</td><td align="left" colspan="1" rowspan="1">87.2(72.6&#8211;95.7)</td><td align="left" colspan="1" rowspan="1">98.4(94.2&#8211;99.8)</td><td align="left" colspan="1" rowspan="1">99.7(99.4&#8211;99.9)</td><td align="left" colspan="1" rowspan="1">52.0(8.7&#8211;92.5)</td><td align="left" colspan="1" rowspan="1">0.86</td><td align="left" colspan="1" rowspan="1">&gt;&#8201;3</td><td align="left" colspan="1" rowspan="1">409.08</td><td align="left" colspan="1" rowspan="1"/></tr></tbody></table></table-wrap>
</p><p id="Par46">
<fig id="Fig4" position="float" orientation="portrait"><label>Fig. 4</label><caption><p>Comparison of the AUC of ResNet&#8201;+&#8201;CA125, DenseNet&#8201;+&#8201;CA125, Vision Transformer&#8201;+&#8201;CA125, Swin Transformer&#8201;+&#8201;CA125 and SA in identifying benign and malignant ovarian tumors</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="d33e1644" position="float" orientation="portrait" xlink:href="13048_2024_1544_Fig4_HTML.jpg"/></fig>
</p></sec><sec id="Sec13"><title>Channel attention visualization analysis</title><p id="Par47">As illustrated in Fig.&#160;<xref rid="Fig5" ref-type="fig">5</xref>, the gradient-weighted class activation map are generated by using the gradients of the classification score with respect to the final convolutional feature map. In the Grad-CAM image, the activated (red) area is strongly considered in predicting final results, whereas the blue area is generally not considered in the final result. These findings were compared with justifications provided by clinicians. In cases where the diagnosis was correct, both the models and clinicians focused on the same regions of interest. Nonetheless, there were instances where both clinicians and DCNNs made incorrect diagnoses. We also compared the areas of interest identified by advanced Sonographers and machine learning models.</p><p id="Par48">We further analyzed six misdiagnosis cases as shown in Fig.&#160;<xref rid="Fig6" ref-type="fig">6</xref>. Case A was benign, but all four machine learning models predicted it as malignant. The postoperative pathology revealed it to be an endometriotic cyst with old hemorrhage and coffee-colored material, without nodules or papillary growth. The machine learning algorithms may have misinterpreted the old blood clot as a papillary or solid component, erroneously considering it a malignant feature. In Case B, despite being benign, DenseNet, Swin, and Vision Transformer models predicted it as malignant. The postoperative pathology confirmed it to be an endometriotic cyst. However, it differed from typical ground-glass appearance on ultrasound, showing uniform hyperechoic content within the cyst. Analyzing the class activation maps, we observed that the misjudgment models excessively focused on the hyperechoic area, potentially leading to misclassification.</p><p id="Par49">Similarly, in Case C, which was a scenario like Case A with an endometriotic cyst and old hemorrhage, the presence of bleeding clots resembling papillary projections resulted in misdiagnosis by two Transformer models. Case D involved pathological changes due to torsion of an adnexal cyst. Except for the DenseNet model, all other models incorrectly classified it as malignant. This may be attributed to the large size of the tumor, causing the models to miss capturing benign features accurately, leading to misclassification. Additionally, the extensive hemorrhagic necrosis resulting from a 1080&#176; torsion might have caused the models to overly focus on certain benign features and erroneously consider them malignant. Cases E and F were both mature cystic teratomas with neural glial components&#8212;a unique subtype of teratomas. Benign teratomas often exhibit characteristic ultrasonographic features, such as mixed echogenicity/white ball and stripes/shadowing [<xref ref-type="bibr" rid="CR27">27</xref>]. However, these two cases presented with similar solid components and/or thick septations.</p><p id="Par50">The models may have mistakenly classified them as malignant characteristics, potentially resulting in misdiagnosis.</p><p id="Par51">
<fig id="Fig5" position="float" orientation="portrait"><label>Fig. 5</label><caption><p>Visualization of channel attention module</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="d33e1673" position="float" orientation="portrait" xlink:href="13048_2024_1544_Fig5_HTML.jpg"/></fig>
</p><p id="Par52">
<fig id="Fig6" position="float" orientation="portrait"><label>Fig. 6</label><caption><p>CAM analysis of 6 cases <bold>(A-F).</bold> The grayscale ultrasound images are shown on the top left, while the Doppler ultrasound images are shown below. On the right side, clockwise from top left, are DenseNet, ResNet, Swin, and VisionTransformer</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="d33e1687" position="float" orientation="portrait" xlink:href="13048_2024_1544_Fig6_HTML.jpg"/></fig>
</p></sec></sec><sec id="Sec14" sec-type="discussion"><title>Discussion</title><p id="Par53">This study compared the diagnostic performance of various deep learning models in predicting the malignancy of adnexal masses on ultrasound images. Overall, all four models demonstrated promising results. AUC varies from 0.87 to 0.92. Different models have trade-offs between sensitivity, specificity, positive predictive value, negative predictive value, and positive/negative likelihood ratios. However, the Swin Transformer model demonstrated superior diagnostic performance in predicting malignancy in adnexal masses on ultrasound images. It achieved the highest overall accuracy, with a sensitivity of 87.2%, specificity of 94.3%, and an impressive AUC of 0.92, comparable to that of the expert. These superior results can be attributed to the unique features and capabilities of the Swin Transformer model. The Swin Transformer backbone employs shifted windows to extract features at five different scales for self-attention computation. Afterward, a feature pyramid network (FPN) is employed to merge the features from multiple scales. Lastly, a detection head is utilized to predict bounding boxes and their corresponding confidence scores [<xref ref-type="bibr" rid="CR28">28</xref>].</p><p id="Par54">Previously, most machine learning models used for assisting medical image diagnosis in the field of healthcare have been predominantly CNN-based, such as ResNet and DenseNet. Recently, swin Transformer has demonstrated promising results in applications in medical imaging such as differential diagnosis of thyroid nodule, and automated classification of cervical lymph-node-level from ultrasound [<xref ref-type="bibr" rid="CR29">29</xref>, <xref ref-type="bibr" rid="CR30">30</xref>]. However, the fields for assisting ovarian tumor ultrasound diagnosis mainly relied on CNNs, and the use of Swin Transformer model was not reported. ResNet and DenseNet have shown impressive performance in various tasks involving adnexal mass ultrasound image analysis. However, they suffer from the limitation of capturing long-range contextual dependencies due to the restricted receptive field of convolutional layers. In contrast, Transformer networks, including the Swin Transformer mentioned earlier, excel at capturing long-range contextual information. Transformers employ self-attention mechanisms to model the relationships among different positions within an input sequence or image, enabling them to capture both local and long-range dependencies more effectively. By leveraging self-attention, Transformer networks can aggregate information from different parts of an image and capture global contextual dependencies. This paper represents the first attempt to utilize Swin Transformer in this context, and it has achieved favorable diagnostic outcomes.</p><p id="Par55">It is worth noting that the inclusion of CA125 in the models did not significantly improve the diagnostic performance, which aligns with the findings of previous studies [<xref ref-type="bibr" rid="CR31">31</xref>]. This can be attributed to various factors, including the correlation between tumor markers and certain imaging features leading to information redundancy, insufficient data volume, reactive elevation of CA125 in benign adnexal tumors, and CA125&#8217;s primary indication of epithelial cell-related pathologies. When developing medical imaging diagnostic models, it is essential to consider these factors, integrate multiple sources of information, and utilize complementary clinical and imaging features to improve accuracy and performance.</p><p id="Par56">The utilization of Grad-CAM has provided valuable insights into the decision-making process of the models by generating class activation maps. These maps effectively highlight the regions in the image that exert the greatest influence on the classification decision. It has been observed that malignant tumors consistently exhibit a higher concentration of red pixels in key areas, such as the solid component. Conversely, benign tumors tend to have a greater number of blue pixels, suggesting a potential lack of distinct features for benign cases. Through the analysis of six cases, it was determined that the models perform well in identifying common tumor types. However, challenges arise when dealing with specific tumor types, such as mature cystic teratomas with neuronal glial components, or tumors presenting unusual characteristics like endometriotic cysts with hemorrhage. Inaccurate identification of certain tumor characteristics, such as misclassifying old hemorrhagic lesions as solid components, can result in misjudgment and potential misdiagnosis.</p><p id="Par57">To enhance the diagnostic efficacy of the models, additional training data that includes a diverse range of rare and unique tumor cases should be incorporated. By exposing the models to a wider variety of tumor characteristics and presentations, they can acquire a more comprehensive understanding and improve their ability to accurately diagnose such challenging cases. Continued research and refinement of the models can lead to enhanced diagnostic performance and facilitate more accurate identification of rare and complex tumor types.</p><p id="Par58">This study has several strengths. Firstly, a large number of patients were included, which allowed for a robust validation of the transformer model&#8217;s diagnostic accuracy in ovarian cancer diagnosis. The study also utilized a comprehensive dataset and analyzed a significant number of ultrasound images, contributing to the reliability of the findings. Moreover, the study adhered to strict evaluation protocols based on the IOTA consensus statement, ensuring standardized and consistent assessment of tumor morphology in the ultrasound images. Furthermore, CA125 levels were measured using the same methodology for all patients, increasing the study&#8217;s reliability. However, the study was conducted at a single center retrospectively, which introduces potential bias in terms of sample distribution and specific patient characteristics.</p><p id="Par59">Overall, this study demonstrates the potential of deep learning models, especially transformer models to accurately predict the malignancy of adnexal masses on ultrasound images.</p></sec></body><back><fn-group><fn><p><bold>Publisher&#8217;s note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><notes notes-type="author-contribution"><title>Author contributions</title><p>CH and FWW conceptualized and designed the study, supervised data collection and reviewed and revised the manuscript. HX collected data, carried out the initial analyses, drafted the initial manuscript, and revised the manuscript. BXH processed the data, utilized machine learning models, and revised the manuscript for machine learning models content. All authors approved the final manuscript as submitted and agree to be accountable for all aspects of the work.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>Sponsored by Medical Innovation Project of Shanghai Science and Technology Commission (20Y11914000), National Natural Science Foundation of China (grant number 82172601), Natural Science Foundation of Shanghai Science and Technology Commission (20ZR1433700).</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>The images used in this study are available from the corresponding author upon request. All data analyzed in this study are included in the published article.</p></notes><notes><title>Declarations</title><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par60">The authors declare no competing interests.</p></notes></notes><glossary><title>Abbreviations</title><def-list><def-item><term>ADNEX</term><def><p id="Par61">Assessment of Different NEoplasias in the adnexa</p></def></def-item><def-item><term>AUC</term><def><p id="Par62">Area Under the Curve</p></def></def-item><def-item><term>CA125</term><def><p id="Par63">Cancer Antigen 125</p></def></def-item><def-item><term>CI</term><def><p id="Par64">Confidence Interval</p></def></def-item><def-item><term>CNN</term><def><p id="Par65">Convolutional Neural Network</p></def></def-item><def-item><term>DenseNet</term><def><p id="Par66">Densely Connected Convolutional Network</p></def></def-item><def-item><term>DL</term><def><p id="Par67">Deep Learning</p></def></def-item><def-item><term>FPN</term><def><p id="Par68">Feature Pyramid Network</p></def></def-item><def-item><term>GCP</term><def><p id="Par69">Good Clinical Practice</p></def></def-item><def-item><term>GPU</term><def><p id="Par70">Graphics Processing Unit</p></def></def-item><def-item><term>HE4</term><def><p id="Par71">Human Epididymis Protein 4</p></def></def-item><def-item><term>IOTA</term><def><p id="Par72">International Ovarian Tumor Analysis</p></def></def-item><def-item><term>ML</term><def><p id="Par73">Machine Learning</p></def></def-item><def-item><term>NLP</term><def><p id="Par74">Natural Language Processing</p></def></def-item><def-item><term>NPV</term><def><p id="Par75">Negative Predictive Value</p></def></def-item><def-item><term>OC</term><def><p id="Par76">Ovarian Cancer</p></def></def-item><def-item><term>O-RADS</term><def><p id="Par77">Ovarian-Adnexal Reporting and Data System</p></def></def-item><def-item><term>PPV</term><def><p id="Par78">Positive Predictive Value</p></def></def-item><def-item><term>ResNet</term><def><p id="Par79">Residual Network</p></def></def-item><def-item><term>ROMA</term><def><p id="Par80">Risk of Ovarian Malignancy Algorithm</p></def></def-item><def-item><term>SA</term><def><p id="Par81">Subjective Assessment</p></def></def-item><def-item><term>SR</term><def><p id="Par82">Simple Rules</p></def></def-item><def-item><term>Swin Transformer</term><def><p id="Par83">Shifted Windows Transformer (a type of deep learning model)</p></def></def-item><def-item><term>TVUS</term><def><p id="Par84">Transvaginal Ultrasound</p></def></def-item><def-item><term>US</term><def><p id="Par85">Ultrasound</p></def></def-item><def-item><term>ViT</term><def><p id="Par86">Vision Transformer</p></def></def-item></def-list></glossary><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lim</surname><given-names>MC</given-names></name><name name-style="western"><surname>Chang</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Park</surname><given-names>B</given-names></name><name name-style="western"><surname>Yoo</surname><given-names>HJ</given-names></name><name name-style="western"><surname>Yoo</surname><given-names>CW</given-names></name><name name-style="western"><surname>Nam</surname><given-names>BH</given-names></name><etal/></person-group><article-title>&lt;ArticleTitle Language=&#8220;En&#8221;&gt;Survival after Hyperthermic Intraperitoneal Chemotherapy and primary or interval cytoreductive surgery in ovarian Cancer: a Randomized Clinical Trial</article-title><source>JAMA Surg</source><year>2022</year><volume>157</volume><issue>5</issue><fpage>374</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1001/jamasurg.2022.0143</pub-id><pub-id pub-id-type="pmid">35262624</pub-id><pub-id pub-id-type="pmcid">PMC8908225</pub-id></element-citation><mixed-citation id="mc-CR1" publication-type="journal">Lim MC, Chang SJ, Park B, Yoo HJ, Yoo CW, Nam BH, et al. Survival after Hyperthermic Intraperitoneal Chemotherapy and primary or interval cytoreductive surgery in ovarian Cancer: a Randomized Clinical Trial. JAMA Surg. 2022;157(5):374&#8211;83.<pub-id pub-id-type="pmid">35262624</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1001/jamasurg.2022.0143</pub-id><pub-id pub-id-type="pmcid">PMC8908225</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kuroki</surname><given-names>L</given-names></name><name name-style="western"><surname>Guntupalli</surname><given-names>SR</given-names></name></person-group><article-title>Treatment of epithelial ovarian cancer</article-title><source>BMJ (Clinical Res ed)</source><year>2020</year><volume>371</volume><fpage>m3773</fpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1136/bmj.m3773</pub-id><pub-id pub-id-type="pmid">33168565</pub-id></element-citation><mixed-citation id="mc-CR2" publication-type="journal">Kuroki L, Guntupalli SR. Treatment of epithelial ovarian cancer. BMJ (Clinical Res ed). 2020;371:m3773.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1136/bmj.m3773</pub-id><pub-id pub-id-type="pmid">33168565</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Froyman</surname><given-names>W</given-names></name><name name-style="western"><surname>Landolfo</surname><given-names>C</given-names></name><name name-style="western"><surname>De Cock</surname><given-names>B</given-names></name><name name-style="western"><surname>Wynants</surname><given-names>L</given-names></name><name name-style="western"><surname>Sladkevicius</surname><given-names>P</given-names></name><name name-style="western"><surname>Testa</surname><given-names>AC</given-names></name><etal/></person-group><article-title>Risk of complications in patients with conservatively managed ovarian tumours (IOTA5): a 2-year interim analysis of a multicentre, prospective, cohort study</article-title><source>Lancet Oncol</source><year>2019</year><volume>20</volume><issue>3</issue><fpage>448</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1016/S1470-2045(18)30837-4</pub-id><pub-id pub-id-type="pmid">30737137</pub-id></element-citation><mixed-citation id="mc-CR3" publication-type="journal">Froyman W, Landolfo C, De Cock B, Wynants L, Sladkevicius P, Testa AC, et al. Risk of complications in patients with conservatively managed ovarian tumours (IOTA5): a 2-year interim analysis of a multicentre, prospective, cohort study. Lancet Oncol. 2019;20(3):448&#8211;58.<pub-id pub-id-type="pmid">30737137</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/S1470-2045(18)30837-4</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="other">Brons PE, Nieuwenhuyzen-de Boer GM, Ramakers C, Willemsen S, Kengsakul M, van Beekhuizen HJ. Preoperative Cancer Antigen 125 Level as Predictor for Complete Cytoreduction in Ovarian Cancer: A Prospective Cohort Study and Systematic Review. Cancers. 2022;14(23).<pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/cancers14235734</pub-id><pub-id pub-id-type="pmcid">PMC9740757</pub-id><pub-id pub-id-type="pmid">36497218</pub-id></mixed-citation></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cramer</surname><given-names>DW</given-names></name><name name-style="western"><surname>Vitonis</surname><given-names>AF</given-names></name><name name-style="western"><surname>Sasamoto</surname><given-names>N</given-names></name><name name-style="western"><surname>Yamamoto</surname><given-names>H</given-names></name><name name-style="western"><surname>Fichorova</surname><given-names>RN</given-names></name></person-group><article-title>Epidemiologic and biologic correlates of serum HE4 and CA125 in women from the National Health and Nutritional Survey (NHANES)</article-title><source>Gynecol Oncol</source><year>2021</year><volume>161</volume><issue>1</issue><fpage>282</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1016/j.ygyno.2021.01.011</pub-id><pub-id pub-id-type="pmid">33504456</pub-id><pub-id pub-id-type="pmcid">PMC7994188</pub-id></element-citation><mixed-citation id="mc-CR5" publication-type="journal">Cramer DW, Vitonis AF, Sasamoto N, Yamamoto H, Fichorova RN. Epidemiologic and biologic correlates of serum HE4 and CA125 in women from the National Health and Nutritional Survey (NHANES). Gynecol Oncol. 2021;161(1):282&#8211;90.<pub-id pub-id-type="pmid">33504456</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.ygyno.2021.01.011</pub-id><pub-id pub-id-type="pmcid">PMC7994188</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Carvalho</surname><given-names>JP</given-names></name><name name-style="western"><surname>Moretti-Marques</surname><given-names>R</given-names></name><name name-style="western"><surname>Filho</surname><given-names>A</given-names></name></person-group><article-title>Adnexal mass: diagnosis and management. Revista brasileira de ginecologia e obstetricia: revista da Federacao Brasileira das Sociedades de</article-title><source>Ginecol e Obstet</source><year>2020</year><volume>42</volume><issue>7</issue><fpage>438</fpage><lpage>43</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1055/s-0040-1715547</pub-id><pub-id pub-id-type="pmcid">PMC10316833</pub-id><pub-id pub-id-type="pmid">32736396</pub-id></element-citation><mixed-citation id="mc-CR6" publication-type="journal">Carvalho JP, Moretti-Marques R, Filho A. Adnexal mass: diagnosis and management. Revista brasileira de ginecologia e obstetricia: revista da Federacao Brasileira das Sociedades de. Ginecol e Obstet. 2020;42(7):438&#8211;43.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1055/s-0040-1715547</pub-id><pub-id pub-id-type="pmcid">PMC10316833</pub-id><pub-id pub-id-type="pmid">32736396</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">Tavorait&#279; I, Kronlachner L, Opolskien&#279; G, Bartkevi&#269;ien&#279; D. Ultrasound Assessment of Adnexal Pathology: Standardized Methods and Different Levels of Experience. Med (Kaunas Lithuania). 2021;57(7).<pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/medicina57070708</pub-id><pub-id pub-id-type="pmcid">PMC8304887</pub-id><pub-id pub-id-type="pmid">34356989</pub-id></mixed-citation></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Timmerman</surname><given-names>D</given-names></name><name name-style="western"><surname>Van Calster</surname><given-names>B</given-names></name><name name-style="western"><surname>Testa</surname><given-names>AC</given-names></name><name name-style="western"><surname>Guerriero</surname><given-names>S</given-names></name><name name-style="western"><surname>Fischerova</surname><given-names>D</given-names></name><name name-style="western"><surname>Lissoni</surname><given-names>AA</given-names></name><etal/></person-group><article-title>Ovarian cancer prediction in adnexal masses using ultrasound-based logistic regression models: a temporal and external validation study by the IOTA group</article-title><source>Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol</source><year>2010</year><volume>36</volume><issue>2</issue><fpage>226</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1002/uog.7636</pub-id><pub-id pub-id-type="pmid">20455203</pub-id></element-citation><mixed-citation id="mc-CR8" publication-type="journal">Timmerman D, Van Calster B, Testa AC, Guerriero S, Fischerova D, Lissoni AA, et al. Ovarian cancer prediction in adnexal masses using ultrasound-based logistic regression models: a temporal and external validation study by the IOTA group. Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol. 2010;36(2):226&#8211;34.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/uog.7636</pub-id><pub-id pub-id-type="pmid">20455203</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Timmerman</surname><given-names>D</given-names></name><name name-style="western"><surname>Ameye</surname><given-names>L</given-names></name><name name-style="western"><surname>Fischerova</surname><given-names>D</given-names></name><name name-style="western"><surname>Epstein</surname><given-names>E</given-names></name><name name-style="western"><surname>Melis</surname><given-names>GB</given-names></name><name name-style="western"><surname>Guerriero</surname><given-names>S</given-names></name><etal/></person-group><article-title>Simple ultrasound rules to distinguish between benign and malignant adnexal masses before surgery: prospective validation by IOTA group</article-title><source>BMJ (Clinical Res ed)</source><year>2010</year><volume>341</volume><fpage>c6839</fpage><pub-id pub-id-type="doi">10.1136/bmj.c6839</pub-id><pub-id pub-id-type="pmcid">PMC3001703</pub-id><pub-id pub-id-type="pmid">21156740</pub-id></element-citation><mixed-citation id="mc-CR9" publication-type="journal">Timmerman D, Ameye L, Fischerova D, Epstein E, Melis GB, Guerriero S, et al. Simple ultrasound rules to distinguish between benign and malignant adnexal masses before surgery: prospective validation by IOTA group. BMJ (Clinical Res ed). 2010;341:c6839.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1136/bmj.c6839</pub-id><pub-id pub-id-type="pmcid">PMC3001703</pub-id><pub-id pub-id-type="pmid">21156740</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Van Calster</surname><given-names>B</given-names></name><name name-style="western"><surname>Van Hoorde</surname><given-names>K</given-names></name><name name-style="western"><surname>Valentin</surname><given-names>L</given-names></name><name name-style="western"><surname>Testa</surname><given-names>AC</given-names></name><name name-style="western"><surname>Fischerova</surname><given-names>D</given-names></name><name name-style="western"><surname>Van Holsbeke</surname><given-names>C</given-names></name><etal/></person-group><article-title>Evaluating the risk of ovarian cancer before surgery using the ADNEX model to differentiate between benign, borderline, early and advanced stage invasive, and secondary metastatic tumours: prospective multicentre diagnostic study</article-title><source>BMJ (Clinical Res ed)</source><year>2014</year><volume>349</volume><fpage>g5920</fpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1136/bmj.g5920</pub-id><pub-id pub-id-type="pmcid">PMC4198550</pub-id><pub-id pub-id-type="pmid">25320247</pub-id></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Van Calster B, Van Hoorde K, Valentin L, Testa AC, Fischerova D, Van Holsbeke C, et al. Evaluating the risk of ovarian cancer before surgery using the ADNEX model to differentiate between benign, borderline, early and advanced stage invasive, and secondary metastatic tumours: prospective multicentre diagnostic study. BMJ (Clinical Res ed). 2014;349:g5920.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1136/bmj.g5920</pub-id><pub-id pub-id-type="pmcid">PMC4198550</pub-id><pub-id pub-id-type="pmid">25320247</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Valentin</surname><given-names>L</given-names></name><name name-style="western"><surname>Ameye</surname><given-names>L</given-names></name><name name-style="western"><surname>Savelli</surname><given-names>L</given-names></name><name name-style="western"><surname>Fruscio</surname><given-names>R</given-names></name><name name-style="western"><surname>Leone</surname><given-names>FP</given-names></name><name name-style="western"><surname>Czekierdowski</surname><given-names>A</given-names></name><etal/></person-group><article-title>Adnexal masses difficult to classify as benign or malignant using subjective assessment of gray-scale and Doppler ultrasound findings: logistic regression models do not help</article-title><source>Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol</source><year>2011</year><volume>38</volume><issue>4</issue><fpage>456</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1002/uog.9030</pub-id><pub-id pub-id-type="pmid">21520475</pub-id></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Valentin L, Ameye L, Savelli L, Fruscio R, Leone FP, Czekierdowski A, et al. Adnexal masses difficult to classify as benign or malignant using subjective assessment of gray-scale and Doppler ultrasound findings: logistic regression models do not help. Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol. 2011;38(4):456&#8211;65.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/uog.9030</pub-id><pub-id pub-id-type="pmid">21520475</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>L&#243;pez-&#218;beda</surname><given-names>P</given-names></name><name name-style="western"><surname>Mart&#237;n-Noguerol</surname><given-names>T</given-names></name><name name-style="western"><surname>Luna</surname><given-names>A</given-names></name></person-group><article-title>Radiology, explicability and AI: closing the gap</article-title><source>Eur Radiol</source><year>2023</year><volume>33</volume><issue>12</issue><fpage>9466</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1007/s00330-023-09902-8</pub-id><pub-id pub-id-type="pmid">37410108</pub-id></element-citation><mixed-citation id="mc-CR12" publication-type="journal">L&#243;pez-&#218;beda P, Mart&#237;n-Noguerol T, Luna A. Radiology, explicability and AI: closing the gap. Eur Radiol. 2023;33(12):9466&#8211;8.<pub-id pub-id-type="pmid">37410108</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s00330-023-09902-8</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Christiansen</surname><given-names>F</given-names></name><name name-style="western"><surname>Epstein</surname><given-names>EL</given-names></name><name name-style="western"><surname>Smedberg</surname><given-names>E</given-names></name><name name-style="western"><surname>&#197;kerlund</surname><given-names>M</given-names></name><name name-style="western"><surname>Smith</surname><given-names>K</given-names></name><name name-style="western"><surname>Epstein</surname><given-names>E</given-names></name></person-group><article-title>Ultrasound image analysis using deep neural networks for discriminating between benign and malignant ovarian tumors: comparison with expert subjective assessment</article-title><source>Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol</source><year>2021</year><volume>57</volume><issue>1</issue><fpage>155</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1002/uog.23530</pub-id><pub-id pub-id-type="pmcid">PMC7839489</pub-id><pub-id pub-id-type="pmid">33142359</pub-id></element-citation><mixed-citation id="mc-CR13" publication-type="journal">Christiansen F, Epstein EL, Smedberg E, &#197;kerlund M, Smith K, Epstein E. Ultrasound image analysis using deep neural networks for discriminating between benign and malignant ovarian tumors: comparison with expert subjective assessment. Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol. 2021;57(1):155&#8211;63.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/uog.23530</pub-id><pub-id pub-id-type="pmcid">PMC7839489</pub-id><pub-id pub-id-type="pmid">33142359</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gao</surname><given-names>Y</given-names></name><name name-style="western"><surname>Zeng</surname><given-names>S</given-names></name><name name-style="western"><surname>Xu</surname><given-names>X</given-names></name><name name-style="western"><surname>Li</surname><given-names>H</given-names></name><name name-style="western"><surname>Yao</surname><given-names>S</given-names></name><name name-style="western"><surname>Song</surname><given-names>K</given-names></name><etal/></person-group><article-title>Deep learning-enabled pelvic ultrasound images for accurate diagnosis of ovarian cancer in China: a retrospective, multicentre, diagnostic study</article-title><source>Lancet Digit health</source><year>2022</year><volume>4</volume><issue>3</issue><fpage>e179</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1016/S2589-7500(21)00278-8</pub-id><pub-id pub-id-type="pmid">35216752</pub-id></element-citation><mixed-citation id="mc-CR14" publication-type="journal">Gao Y, Zeng S, Xu X, Li H, Yao S, Song K, et al. Deep learning-enabled pelvic ultrasound images for accurate diagnosis of ovarian cancer in China: a retrospective, multicentre, diagnostic study. Lancet Digit health. 2022;4(3):e179&#8211;87.<pub-id pub-id-type="pmid">35216752</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/S2589-7500(21)00278-8</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>H</given-names></name><name name-style="western"><surname>Yang</surname><given-names>BW</given-names></name><name name-style="western"><surname>Qian</surname><given-names>L</given-names></name><name name-style="western"><surname>Meng</surname><given-names>YS</given-names></name><name name-style="western"><surname>Bai</surname><given-names>XH</given-names></name><name name-style="western"><surname>Hong</surname><given-names>XW</given-names></name><etal/></person-group><article-title>Deep Learning Prediction of Ovarian Malignancy at US Compared with O-RADS and Expert Assessment</article-title><source>Radiology</source><year>2022</year><volume>304</volume><issue>1</issue><fpage>106</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1148/radiol.211367</pub-id><pub-id pub-id-type="pmid">35412367</pub-id></element-citation><mixed-citation id="mc-CR15" publication-type="journal">Chen H, Yang BW, Qian L, Meng YS, Bai XH, Hong XW, et al. Deep Learning Prediction of Ovarian Malignancy at US Compared with O-RADS and Expert Assessment. Radiology. 2022;304(1):106&#8211;13.<pub-id pub-id-type="pmid">35412367</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1148/radiol.211367</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">Parvaiz A, Khalid M, Zafar R, Ameer H, Ali M, Fraz M. Vision Transformers in Medical Computer Vision -- A Contemplative Retrospection2022.</mixed-citation></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Timmerman</surname><given-names>D</given-names></name><name name-style="western"><surname>Valentin</surname><given-names>L</given-names></name><name name-style="western"><surname>Bourne</surname><given-names>TH</given-names></name><name name-style="western"><surname>Collins</surname><given-names>WP</given-names></name><name name-style="western"><surname>Verrelst</surname><given-names>H</given-names></name><name name-style="western"><surname>Vergote</surname><given-names>I</given-names></name></person-group><article-title>Terms, definitions and measurements to describe the sonographic features of adnexal tumors: a consensus opinion from the International Ovarian Tumor Analysis (IOTA) Group</article-title><source>Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol</source><year>2000</year><volume>16</volume><issue>5</issue><fpage>500</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1046/j.1469-0705.2000.00287.x</pub-id><pub-id pub-id-type="pmid">11169340</pub-id></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Timmerman D, Valentin L, Bourne TH, Collins WP, Verrelst H, Vergote I. Terms, definitions and measurements to describe the sonographic features of adnexal tumors: a consensus opinion from the International Ovarian Tumor Analysis (IOTA) Group. Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol. 2000;16(5):500&#8211;5.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1046/j.1469-0705.2000.00287.x</pub-id><pub-id pub-id-type="pmid">11169340</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Meys</surname><given-names>EMJ</given-names></name><name name-style="western"><surname>Jeelof</surname><given-names>LS</given-names></name><name name-style="western"><surname>Achten</surname><given-names>NMJ</given-names></name><name name-style="western"><surname>Slangen</surname><given-names>BFM</given-names></name><name name-style="western"><surname>Lambrechts</surname><given-names>S</given-names></name><name name-style="western"><surname>Kruitwagen</surname><given-names>R</given-names></name><name name-style="western"><surname>Van Gorp</surname><given-names>T</given-names></name></person-group><article-title>Estimating risk of malignancy in adnexal masses: external validation of the ADNEX model and comparison with other frequently used ultrasound methods</article-title><source>Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol</source><year>2017</year><volume>49</volume><issue>6</issue><fpage>784</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1002/uog.17225</pub-id><pub-id pub-id-type="pmcid">PMC5488216</pub-id><pub-id pub-id-type="pmid">27514486</pub-id></element-citation><mixed-citation id="mc-CR18" publication-type="journal">Meys EMJ, Jeelof LS, Achten NMJ, Slangen BFM, Lambrechts S, Kruitwagen R, Van Gorp T. Estimating risk of malignancy in adnexal masses: external validation of the ADNEX model and comparison with other frequently used ultrasound methods. Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol. 2017;49(6):784&#8211;92.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/uog.17225</pub-id><pub-id pub-id-type="pmcid">PMC5488216</pub-id><pub-id pub-id-type="pmid">27514486</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">He K, Zhang X, Ren S, Sun J. Deep Residual Learning for Image Recognition. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2015:770-8.</mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Huang G, Liu Z, van der Maaten L, Weinberger K. Densely Connected Convolutional Networks2017.</mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Dosovitskiy A, Beyer L, Kolesnikov A, Weissenborn D, Zhai X, Unterthiner T et al. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. ArXiv. 2020;abs/2010.11929.</mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Liu Z, Lin Y, Cao Y, Hu H, Wei Y, Zhang Z, Lin S, Guo B. Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. 2021 IEEE/CVF International Conference on Computer Vision (ICCV). 2021:9992&#8211;10002.</mixed-citation></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Selvaraju</surname><given-names>RR</given-names></name><name name-style="western"><surname>Das</surname><given-names>A</given-names></name><name name-style="western"><surname>Vedantam</surname><given-names>R</given-names></name><name name-style="western"><surname>Cogswell</surname><given-names>M</given-names></name><name name-style="western"><surname>Parikh</surname><given-names>D</given-names></name><name name-style="western"><surname>Batra</surname><given-names>D</given-names></name></person-group><article-title>Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization</article-title><source>Int J Comput Vision</source><year>2016</year><volume>128</volume><fpage>336</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1007/s11263-019-01228-7</pub-id></element-citation><mixed-citation id="mc-CR23" publication-type="journal">Selvaraju RR, Das A, Vedantam R, Cogswell M, Parikh D, Batra D. Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization. Int J Comput Vision. 2016;128:336&#8211;59.</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Meinhold-Heerlein</surname><given-names>I</given-names></name><name name-style="western"><surname>Fotopoulou</surname><given-names>C</given-names></name><name name-style="western"><surname>Harter</surname><given-names>P</given-names></name><name name-style="western"><surname>Kurzeder</surname><given-names>C</given-names></name><name name-style="western"><surname>Mustea</surname><given-names>A</given-names></name><name name-style="western"><surname>Wimberger</surname><given-names>P</given-names></name><name name-style="western"><surname>Hauptmann</surname><given-names>S</given-names></name><name name-style="western"><surname>Sehouli</surname><given-names>J</given-names></name></person-group><article-title>The new WHO classification of ovarian, fallopian tube, and primary peritoneal cancer and its clinical implications</article-title><source>Arch Gynecol Obstet</source><year>2016</year><volume>293</volume><issue>4</issue><fpage>695</fpage><lpage>700</lpage><pub-id pub-id-type="doi">10.1007/s00404-016-4035-8</pub-id><pub-id pub-id-type="pmid">26894303</pub-id></element-citation><mixed-citation id="mc-CR24" publication-type="journal">Meinhold-Heerlein I, Fotopoulou C, Harter P, Kurzeder C, Mustea A, Wimberger P, Hauptmann S, Sehouli J. The new WHO classification of ovarian, fallopian tube, and primary peritoneal cancer and its clinical implications. Arch Gynecol Obstet. 2016;293(4):695&#8211;700.<pub-id pub-id-type="pmid">26894303</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s00404-016-4035-8</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Prat</surname><given-names>J</given-names></name></person-group><article-title>Staging classification for cancer of the ovary, fallopian tube, and peritoneum</article-title><source>Int J Gynaecol Obstet</source><year>2014</year><volume>124</volume><issue>1</issue><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1016/j.ijgo.2013.10.001</pub-id><pub-id pub-id-type="pmid">24219974</pub-id></element-citation><mixed-citation id="mc-CR25" publication-type="journal">Prat J. Staging classification for cancer of the ovary, fallopian tube, and peritoneum. Int J Gynaecol Obstet. 2014;124(1):1&#8211;5.<pub-id pub-id-type="pmid">24219974</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.ijgo.2013.10.001</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Piovano</surname><given-names>E</given-names></name><name name-style="western"><surname>Cavallero</surname><given-names>C</given-names></name><name name-style="western"><surname>Fuso</surname><given-names>L</given-names></name><name name-style="western"><surname>Viora</surname><given-names>E</given-names></name><name name-style="western"><surname>Ferrero</surname><given-names>A</given-names></name><name name-style="western"><surname>Gregori</surname><given-names>G</given-names></name><etal/></person-group><article-title>Diagnostic accuracy and cost-effectiveness of different strategies to triage women with adnexal masses: a prospective study</article-title><source>Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol</source><year>2017</year><volume>50</volume><issue>3</issue><fpage>395</fpage><lpage>403</lpage><pub-id pub-id-type="doi">10.1002/uog.17320</pub-id><pub-id pub-id-type="pmid">27706929</pub-id></element-citation><mixed-citation id="mc-CR26" publication-type="journal">Piovano E, Cavallero C, Fuso L, Viora E, Ferrero A, Gregori G, et al. Diagnostic accuracy and cost-effectiveness of different strategies to triage women with adnexal masses: a prospective study. Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol. 2017;50(3):395&#8211;403.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/uog.17320</pub-id><pub-id pub-id-type="pmid">27706929</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Timmerman</surname><given-names>D</given-names></name><name name-style="western"><surname>Planchamp</surname><given-names>F</given-names></name><name name-style="western"><surname>Bourne</surname><given-names>T</given-names></name><name name-style="western"><surname>Landolfo</surname><given-names>C</given-names></name><name name-style="western"><surname>du Bois</surname><given-names>A</given-names></name><name name-style="western"><surname>Chiva</surname><given-names>L</given-names></name><etal/></person-group><article-title>ESGO/ISUOG/IOTA/ESGE Consensus Statement on preoperative diagnosis of ovarian tumors</article-title><source>Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol</source><year>2021</year><volume>58</volume><issue>1</issue><fpage>148</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1002/uog.23635</pub-id><pub-id pub-id-type="pmid">33794043</pub-id></element-citation><mixed-citation id="mc-CR27" publication-type="journal">Timmerman D, Planchamp F, Bourne T, Landolfo C, du Bois A, Chiva L, et al. ESGO/ISUOG/IOTA/ESGE Consensus Statement on preoperative diagnosis of ovarian tumors. Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol. 2021;58(1):148&#8211;68.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/uog.23635</pub-id><pub-id pub-id-type="pmid">33794043</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Tian Y, Zhu J, Zhang L, Mou L, Zhu X, Shi Y et al. Swin Transformer-Based Model for Thyroid Nodule Detection in Ultrasound Images. J visualized experiments: JoVE. 2023(194).<pub-id pub-id-type="doi" assigning-authority="pmc">10.3791/64480</pub-id><pub-id pub-id-type="pmid">37154577</pub-id></mixed-citation></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>Y</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>J</given-names></name><name name-style="western"><surname>Luo</surname><given-names>Q</given-names></name><name name-style="western"><surname>Shen</surname><given-names>C</given-names></name><name name-style="western"><surname>Wang</surname><given-names>R</given-names></name><name name-style="western"><surname>Ding</surname><given-names>X</given-names></name></person-group><article-title>Automated classification of cervical lymph-node-level from ultrasound using Depthwise Separable Convolutional Swin Transformer</article-title><source>Comput Biol Med</source><year>2022</year><volume>148</volume><fpage>105821</fpage><pub-id pub-id-type="doi">10.1016/j.compbiomed.2022.105821</pub-id><pub-id pub-id-type="pmid">35853399</pub-id></element-citation><mixed-citation id="mc-CR29" publication-type="journal">Liu Y, Zhao J, Luo Q, Shen C, Wang R, Ding X. Automated classification of cervical lymph-node-level from ultrasound using Depthwise Separable Convolutional Swin Transformer. Comput Biol Med. 2022;148:105821.<pub-id pub-id-type="pmid">35853399</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.compbiomed.2022.105821</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>F</given-names></name><name name-style="western"><surname>Han</surname><given-names>H</given-names></name><name name-style="western"><surname>Wan</surname><given-names>P</given-names></name><name name-style="western"><surname>Liao</surname><given-names>H</given-names></name><name name-style="western"><surname>Liu</surname><given-names>C</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>D</given-names></name></person-group><article-title>Joint Segmentation and Differential Diagnosis of Thyroid Nodule in Contrast-Enhanced Ultrasound Images</article-title><source>IEEE Trans Bio Med Eng</source><year>2023</year><volume>70</volume><issue>9</issue><fpage>2722</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1109/TBME.2023.3262842</pub-id><pub-id pub-id-type="pmid">37027278</pub-id></element-citation><mixed-citation id="mc-CR30" publication-type="journal">Chen F, Han H, Wan P, Liao H, Liu C, Zhang D. Joint Segmentation and Differential Diagnosis of Thyroid Nodule in Contrast-Enhanced Ultrasound Images. IEEE Trans Bio Med Eng. 2023;70(9):2722&#8211;32.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TBME.2023.3262842</pub-id><pub-id pub-id-type="pmid">37027278</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>H</given-names></name><name name-style="western"><surname>Qian</surname><given-names>L</given-names></name><name name-style="western"><surname>Jiang</surname><given-names>M</given-names></name><name name-style="western"><surname>Du</surname><given-names>Q</given-names></name><name name-style="western"><surname>Yuan</surname><given-names>F</given-names></name><name name-style="western"><surname>Feng</surname><given-names>W</given-names></name></person-group><article-title>Performance of IOTA ADNEX model in evaluating adnexal masses in a gynecological oncology center in China</article-title><source>Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol</source><year>2019</year><volume>54</volume><issue>6</issue><fpage>815</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1002/uog.20363</pub-id><pub-id pub-id-type="pmid">31152572</pub-id></element-citation><mixed-citation id="mc-CR31" publication-type="journal">Chen H, Qian L, Jiang M, Du Q, Yuan F, Feng W. Performance of IOTA ADNEX model in evaluating adnexal masses in a gynecological oncology center in China. Ultrasound Obstet gynecology: official J Int Soc Ultrasound Obstet Gynecol. 2019;54(6):815&#8211;22.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/uog.20363</pub-id><pub-id pub-id-type="pmid">31152572</pub-id></mixed-citation></citation-alternatives></ref></ref-list></back></article></pmc-articleset>